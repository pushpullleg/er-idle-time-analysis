{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Insights Discovery\n",
    "## Meridian City Hospital ER Data\n",
    "\n",
    "**Team:** ACM  \n",
    "**Date:** 2024  \n",
    "**Focus:** Finding insights from cleaned and joined dataset\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Analysis Objectives\n",
    "1. Discover patterns and trends in ER operations\n",
    "2. Identify factors affecting patient outcomes\n",
    "3. Understand staffing impact on performance\n",
    "4. Find opportunities for improvement\n",
    "5. Generate actionable insights\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfaf Quick Navigation\n",
    "- **Section 1:** Load & Explore Data\n",
    "- **Section 2:** Key Metrics & KPIs\n",
    "- **Section 3:** Trends & Patterns\n",
    "- **Section 4:** Relationships & Correlations\n",
    "- **Section 5:** Segmentation Analysis\n",
    "- **Section 6:** Deep Dive Insights\n",
    "- **Section 7:** Summary & Recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load & Explore Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Initialize insights list\n",
    "insights = []\n",
    "\n",
    "print(\"\u2713 Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD CLEANED & JOINED DATASET\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Load from a single joined file (if you have one)\n",
    "# Uncomment and modify the path:\n",
    "df = pd.read_csv('joined_data.csv')\n",
    "\n",
    "# Option 2: Load cleaned files and join them (if needed)\n",
    "# Adjust paths and join keys based on your cleaned data structure\n",
    "\n",
    "# Example - Load cleaned files (adjust paths as needed):\n",
    "# df_visits = pd.read_csv('Cleaned/Hospital_visits_out.csv')\n",
    "# df_patients = pd.read_csv('Cleaned/Hospital_patients_out.csv')\n",
    "# df_outcomes = pd.read_csv('Cleaned/Hospital_outcome_out.csv')\n",
    "# df_facility = pd.read_csv('Cleaned/Hospital_facility_out.csv')\n",
    "# df_staffing = pd.read_csv('Cleaned/Hospital_Staffing_out.csv')\n",
    "# \n",
    "# # Join datasets (adjust join keys based on your data)\n",
    "# df = df_visits.merge(df_patients, on='PatientID', how='left')\n",
    "# df = df.merge(df_outcomes, on='VisitID', how='left')\n",
    "# df = df.merge(df_facility, on='FacilityID', how='left')\n",
    "# df = df.merge(df_staffing, on='FacilityID', how='left')\n",
    "\n",
    "# TEMPORARY: If you don't have the joined file yet, load one to test\n",
    "# Replace this with your actual joined file path\n",
    "df = pd.read_csv('joined_data.csv')  # Replace with your joined file\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET LOADED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Quick overview\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FIRST FEW ROWS\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal columns: {len(df.columns)}\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"  {i:2d}. {col:<40} ({dtype})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BASIC INFO\")\n",
    "print(\"=\" * 80)\n",
    "df.info()\n",
    "\n",
    "insights.append(f\"Dataset contains {df.shape[0]:,} records with {df.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Key Metrics & KPIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KEY METRICS & KPIs\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY METRICS & KPIs\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Identify key columns (adjust based on your actual column names)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "date_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numeric_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"Date columns: {len(date_cols)}\")\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "if len(numeric_cols) > 0:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"-\" * 80)\n",
    "    display(df[numeric_cols].describe().T)\n",
    "\n",
    "# Key metrics (customize based on your columns)\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"KEY METRICS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Example metrics (adjust column names based on your data)\n",
    "metrics = {}\n",
    "\n",
    "# Check for common hospital metrics\n",
    "if 'Patient Satisfaction' in df.columns:\n",
    "    metrics['Avg Patient Satisfaction'] = df['Patient Satisfaction'].mean()\n",
    "    metrics['Min Patient Satisfaction'] = df['Patient Satisfaction'].min()\n",
    "    metrics['Max Patient Satisfaction'] = df['Patient Satisfaction'].max()\n",
    "\n",
    "# Add more metrics based on your columns\n",
    "# if 'Wait Time' in df.columns:\n",
    "#     metrics['Avg Wait Time'] = df['Wait Time'].mean()\n",
    "# if 'Length of Stay' in df.columns:\n",
    "#     metrics['Avg Length of Stay'] = df['Length of Stay'].mean()\n",
    "\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "    insights.append(f\"{key}: {value:.2f}\")\n",
    "\n",
    "# Value counts for categorical columns (top categories)\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATEGORICAL DISTRIBUTIONS (TOP 5)\")\n",
    "print(\"-\" * 80)\n",
    "for col in categorical_cols[:5]:  # First 5 categorical columns\n",
    "    print(f\"\\n{col}:\")\n",
    "    value_counts = df[col].value_counts().head(5)\n",
    "    display(value_counts.to_frame('Count'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Trends & Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TIME-BASED TRENDS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TIME-BASED TRENDS & PATTERNS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find date columns and analyze trends\n",
    "date_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        # Try to detect date columns\n",
    "        sample = df[col].dropna().head(10)\n",
    "        if len(sample) > 0:\n",
    "            try:\n",
    "                pd.to_datetime(sample)\n",
    "                date_columns.append(col)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if len(date_columns) > 0:\n",
    "    print(f\"\\nFound date columns: {date_columns}\")\n",
    "    \n",
    "    # Analyze trends for first date column\n",
    "    date_col = date_columns[0]\n",
    "    print(f\"\\nAnalyzing trends by: {date_col}\")\n",
    "    \n",
    "    # Convert to datetime\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    \n",
    "    # Extract time components\n",
    "    df['Year'] = df[date_col].dt.year\n",
    "    df['Month'] = df[date_col].dt.month\n",
    "    df['DayOfWeek'] = df[date_col].dt.dayofweek\n",
    "    df['Hour'] = df[date_col].dt.hour if df[date_col].dt.hour.notna().any() else None\n",
    "    \n",
    "    # Monthly trends (if we have a metric)\n",
    "    if 'Patient Satisfaction' in df.columns:\n",
    "        monthly_satisfaction = df.groupby(['Year', 'Month'])['Patient Satisfaction'].mean()\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        monthly_satisfaction.plot(kind='line', marker='o')\n",
    "        plt.title('Monthly Patient Satisfaction Trend', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Year-Month', fontsize=12)\n",
    "        plt.ylabel('Average Satisfaction', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        insights.append(f\"Monthly patient satisfaction ranges from {monthly_satisfaction.min():.2f} to {monthly_satisfaction.max():.2f}\")\n",
    "    \n",
    "    # Day of week patterns\n",
    "    if 'DayOfWeek' in df.columns:\n",
    "        day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        day_of_week_counts = df['DayOfWeek'].value_counts().sort_index()\n",
    "        day_of_week_counts.index = [day_names[i] for i in day_of_week_counts.index]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        day_of_week_counts.plot(kind='bar', color='steelblue')\n",
    "        plt.title('Visits by Day of Week', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Day of Week', fontsize=12)\n",
    "        plt.ylabel('Number of Visits', fontsize=12)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        insights.append(f\"Busiest day: {day_of_week_counts.idxmax()} with {day_of_week_counts.max():,} visits\")\n",
    "else:\n",
    "    print(\"\\n\u26a0 No date columns detected. Skipping time-based analysis.\")\n",
    "    print(\"   If you have date columns, ensure they're in a recognizable format.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Relationships & Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CORRELATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RELATIONSHIPS & CORRELATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    # Correlation matrix\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    # Visualize correlation heatmap\n",
    "    plt.figure(figsize=(max(12, len(numeric_cols)), max(10, len(numeric_cols))))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "                cmap='coolwarm', center=0, square=True, linewidths=1,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix - Numerical Features', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find strong correlations\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"STRONG CORRELATIONS (|r| > 0.5)\")\n",
    "    print(\"-\" * 80)\n",
    "    strong_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.5:\n",
    "                strong_corr.append({\n",
    "                    'Feature 1': col1,\n",
    "                    'Feature 2': col2,\n",
    "                    'Correlation': corr_val\n",
    "                })\n",
    "                insights.append(f\"Strong correlation ({corr_val:.3f}) between {col1} and {col2}\")\n",
    "    \n",
    "    if strong_corr:\n",
    "        strong_corr_df = pd.DataFrame(strong_corr)\n",
    "        display(strong_corr_df.sort_values('Correlation', key=abs, ascending=False))\n",
    "    else:\n",
    "        print(\"No strong correlations found (|r| > 0.5)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CATEGORICAL RELATIONSHIPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATEGORICAL RELATIONSHIPS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Analyze relationships between categorical variables and numerical outcomes\n",
    "if 'Patient Satisfaction' in df.columns and len(categorical_cols) > 0:\n",
    "    print(\"\\nPatient Satisfaction by Category:\")\n",
    "    for col in categorical_cols[:3]:  # First 3 categorical columns\n",
    "        if df[col].nunique() < 20:  # Only if reasonable number of categories\n",
    "            satisfaction_by_cat = df.groupby(col)['Patient Satisfaction'].agg(['mean', 'count', 'std'])\n",
    "            satisfaction_by_cat = satisfaction_by_cat.sort_values('mean', ascending=False)\n",
    "            \n",
    "            print(f\"\\n{col}:\")\n",
    "            display(satisfaction_by_cat.head(10))\n",
    "            \n",
    "            # Visualize\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            satisfaction_by_cat['mean'].head(10).plot(kind='bar', color='coral')\n",
    "            plt.title(f'Average Patient Satisfaction by {col}', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel(col, fontsize=12)\n",
    "            plt.ylabel('Average Satisfaction', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            best_category = satisfaction_by_cat['mean'].idxmax()\n",
    "            worst_category = satisfaction_by_cat['mean'].idxmin()\n",
    "            insights.append(f\"Highest satisfaction in {col}: {best_category} ({satisfaction_by_cat.loc[best_category, 'mean']:.2f})\")\n",
    "            insights.append(f\"Lowest satisfaction in {col}: {worst_category} ({satisfaction_by_cat.loc[worst_category, 'mean']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Segmentation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SEGMENTATION & GROUPING ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SEGMENTATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Segment analysis - identify high/low performers\n",
    "if 'Patient Satisfaction' in df.columns:\n",
    "    # Create satisfaction segments\n",
    "    df['Satisfaction_Segment'] = pd.cut(\n",
    "        df['Patient Satisfaction'], \n",
    "        bins=[0, 2, 3, 4, 5], \n",
    "        labels=['Low (1-2)', 'Medium (3)', 'High (4)', 'Very High (5)']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"SATISFACTION SEGMENTS\")\n",
    "    print(\"-\" * 80)\n",
    "    segment_counts = df['Satisfaction_Segment'].value_counts()\n",
    "    display(segment_counts.to_frame('Count'))\n",
    "    \n",
    "    # Analyze what differentiates segments\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"SEGMENT CHARACTERISTICS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Compare segments across other variables\n",
    "    for col in numeric_cols[:5]:  # First 5 numerical columns\n",
    "        if col != 'Patient Satisfaction':\n",
    "            segment_means = df.groupby('Satisfaction_Segment')[col].mean()\n",
    "            print(f\"\\n{col} by Satisfaction Segment:\")\n",
    "            display(segment_means.to_frame('Mean'))\n",
    "    \n",
    "    insights.append(f\"Satisfaction distribution: {segment_counts.to_dict()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# OUTLIER ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"OUTLIER ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Identify outliers using IQR method for key numerical columns\n",
    "outlier_cols = numeric_cols[:5]  # Analyze first 5 numerical columns\n",
    "outlier_summary = []\n",
    "\n",
    "for col in outlier_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_pct = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        outlier_summary.append({\n",
    "            'Column': col,\n",
    "            'Outlier Count': outlier_count,\n",
    "            'Outlier %': f\"{outlier_pct:.2f}%\",\n",
    "            'Lower Bound': f\"{lower_bound:.2f}\",\n",
    "            'Upper Bound': f\"{upper_bound:.2f}\"\n",
    "        })\n",
    "        \n",
    "        if outlier_pct > 5:\n",
    "            insights.append(f\"\u26a0 {col}: {outlier_pct:.1f}% outliers detected\")\n",
    "\n",
    "if outlier_summary:\n",
    "    outlier_df = pd.DataFrame(outlier_summary)\n",
    "    display(outlier_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Deep Dive Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEEP DIVE: CUSTOM ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DEEP DIVE INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# 6.1 DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"6.1 DISTRIBUTION ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Visualize distributions of key numerical variables\n",
    "key_vars = numeric_cols[:6]  # First 6 numerical columns\n",
    "n_cols = 3\n",
    "n_rows = (len(key_vars) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten() if len(key_vars) > 1 else [axes]\n",
    "\n",
    "for idx, col in enumerate(key_vars):\n",
    "    ax = axes[idx]\n",
    "    df[col].hist(bins=50, ax=ax, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(col, fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_val = df[col].mean()\n",
    "    median_val = df[col].median()\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "    ax.axvline(median_val, color='green', linestyle='--', label=f'Median: {median_val:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(len(key_vars), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 6.2 COMPARATIVE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"6.2 COMPARATIVE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare top vs bottom performers (if we have a target metric)\n",
    "if 'Patient Satisfaction' in df.columns:\n",
    "    # Top 20% vs Bottom 20%\n",
    "    threshold_high = df['Patient Satisfaction'].quantile(0.8)\n",
    "    threshold_low = df['Patient Satisfaction'].quantile(0.2)\n",
    "    \n",
    "    high_satisfaction = df[df['Patient Satisfaction'] >= threshold_high]\n",
    "    low_satisfaction = df[df['Patient Satisfaction'] <= threshold_low]\n",
    "    \n",
    "    print(f\"\\nHigh Satisfaction (\u2265{threshold_high:.1f}): {len(high_satisfaction):,} records\")\n",
    "    print(f\"Low Satisfaction (\u2264{threshold_low:.1f}): {len(low_satisfaction):,} records\")\n",
    "    \n",
    "    # Compare key metrics\n",
    "    comparison_cols = [col for col in numeric_cols if col != 'Patient Satisfaction'][:5]\n",
    "    \n",
    "    comparison_data = []\n",
    "    for col in comparison_cols:\n",
    "        comparison_data.append({\n",
    "            'Metric': col,\n",
    "            'High Satisfaction': high_satisfaction[col].mean(),\n",
    "            'Low Satisfaction': low_satisfaction[col].mean(),\n",
    "            'Difference': high_satisfaction[col].mean() - low_satisfaction[col].mean()\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Identify key differentiators\n",
    "    comparison_df['Abs Difference'] = comparison_df['Difference'].abs()\n",
    "    top_differentiators = comparison_df.nlargest(3, 'Abs Difference')\n",
    "    print(\"\\nTop Differentiators between High and Low Satisfaction:\")\n",
    "    for _, row in top_differentiators.iterrows():\n",
    "        insights.append(\n",
    "            f\"Key difference: {row['Metric']} - \"\n",
    "            f\"High: {row['High Satisfaction']:.2f}, Low: {row['Low Satisfaction']:.2f} \"\n",
    "            f\"(Diff: {row['Difference']:.2f})\"\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# 6.3 PATTERN DISCOVERY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"6.3 PATTERN DISCOVERY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Look for interesting patterns\n",
    "print(\"\\n\ud83d\udca1 Custom Analysis Areas:\")\n",
    "print(\"   - Peak hours/days for different metrics\")\n",
    "print(\"   - Facility/location performance differences\")\n",
    "print(\"   - Staffing impact on outcomes\")\n",
    "print(\"   - Patient demographics and outcomes\")\n",
    "print(\"   - Seasonal/cyclical patterns\")\n",
    "\n",
    "# Add your custom analysis here based on your specific columns\n",
    "# Example:\n",
    "# if 'Facility' in df.columns and 'Patient Satisfaction' in df.columns:\n",
    "#     facility_performance = df.groupby('Facility')['Patient Satisfaction'].agg(['mean', 'count'])\n",
    "#     facility_performance = facility_performance.sort_values('mean', ascending=False)\n",
    "#     print(\"\\nFacility Performance:\")\n",
    "#     display(facility_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Summary & Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSIGHTS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\ud83d\udcca DATASET OVERVIEW\")\n",
    "print(f\"   \u2022 Total records: {df.shape[0]:,}\")\n",
    "print(f\"   \u2022 Total features: {df.shape[1]}\")\n",
    "print(f\"   \u2022 Numerical features: {len(numeric_cols)}\")\n",
    "print(f\"   \u2022 Categorical features: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\n\ud83d\udd0d KEY INSIGHTS DISCOVERED:\")\n",
    "print(\"-\" * 80)\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"   {i}. {insight}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Generate recommendations based on insights\n",
    "if 'Patient Satisfaction' in df.columns:\n",
    "    if df['Patient Satisfaction'].mean() < 3.5:\n",
    "        recommendations.append(\"\u26a0\ufe0f Patient satisfaction is below average - investigate root causes\")\n",
    "    \n",
    "    # Check for satisfaction variations\n",
    "    if 'Satisfaction_Segment' in df.columns:\n",
    "        low_satisfaction_pct = (df['Satisfaction_Segment'] == 'Low (1-2)').sum() / len(df) * 100\n",
    "        if low_satisfaction_pct > 10:\n",
    "            recommendations.append(f\"\u26a0\ufe0f {low_satisfaction_pct:.1f}% of patients have low satisfaction - prioritize improvement\")\n",
    "\n",
    "# Add more recommendations based on your analysis\n",
    "if len(outlier_summary) > 0:\n",
    "    high_outlier_cols = [row['Column'] for row in outlier_summary if float(row['Outlier %'].rstrip('%')) > 10]\n",
    "    if high_outlier_cols:\n",
    "        recommendations.append(f\"\u26a0\ufe0f High outlier rates in: {', '.join(high_outlier_cols)} - investigate data quality or process issues\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 RECOMMENDATIONS:\")\n",
    "print(\"-\" * 80)\n",
    "if recommendations:\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"   {i}. {rec}\")\n",
    "else:\n",
    "    print(\"   (Add custom recommendations based on your analysis)\")\n",
    "\n",
    "# ============================================================================\n",
    "# NEXT STEPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "next_steps = [\n",
    "    \"Review insights with team\",\n",
    "    \"Validate findings with domain experts\",\n",
    "    \"Prioritize areas for improvement\",\n",
    "    \"Develop action plans for key recommendations\",\n",
    "    \"Create visualizations for presentation\",\n",
    "    \"Prepare data for modeling (if needed)\"\n",
    "]\n",
    "\n",
    "print(\"\\n\ud83d\udccb SUGGESTED NEXT STEPS:\")\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPORTING INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "insights_report = f\"\"\"\n",
    "EDA INSIGHTS REPORT - Meridian City Hospital ER\n",
    "===============================================\n",
    "Generated: {timestamp}\n",
    "Dataset: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\n",
    "\n",
    "KEY INSIGHTS\n",
    "------------\n",
    "\"\"\"\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    insights_report += f\"{i}. {insight}\\n\"\n",
    "\n",
    "insights_report += f\"\"\"\n",
    "\n",
    "RECOMMENDATIONS\n",
    "---------------\n",
    "\"\"\"\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    insights_report += f\"{i}. {rec}\\n\"\n",
    "\n",
    "insights_report += f\"\"\"\n",
    "\n",
    "NEXT STEPS\n",
    "----------\n",
    "\"\"\"\n",
    "\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    insights_report += f\"{i}. {step}\\n\"\n",
    "\n",
    "# Write to file\n",
    "output_file = 'eda_insights_report.txt'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(insights_report)\n",
    "\n",
    "print(f\"\u2713 Insights exported to: {output_file}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\u2705 EDA COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}