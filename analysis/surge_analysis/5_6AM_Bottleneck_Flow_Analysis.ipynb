{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914fb8a8",
   "metadata": {},
   "source": [
    "# 5-6 AM Bottleneck & Flow Analysis: Patient Throughput\n",
    "\n",
    "## Objective\n",
    "This notebook analyzes the **patient flow bottleneck** during 5:00 AM - 6:59 AM to identify operational constraints:\n",
    "- **Arrival Rate**: How many patients enter the system\n",
    "- **Patients in System**: Current census (being triaged/treated)\n",
    "- **Exit Rate**: How many patients leave the system\n",
    "- **Flow Divergence**: Gap between arrivals and exits\n",
    "- **Root Cause Analysis**: Doctor idle time vs. bed unavailability vs. process delays\n",
    "\n",
    "This analysis helps identify whether bottlenecks are caused by:\n",
    "1. Insufficient bed capacity\n",
    "2. Doctor availability/idle time\n",
    "3. Process delays (registration, triage, treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ffba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ffaab",
   "metadata": {},
   "source": [
    "## Section 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and prepare datetime columns\n",
    "data_path = '/Users/mukeshravichandran/Datathon/final_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\u2713 Dataset loaded: {df.shape[0]} records\")\n",
    "print(f\"\\nKey columns for flow analysis:\")\n",
    "print(f\"  \u2022 Arrival Time\")\n",
    "print(f\"  \u2022 Registration Start/End\")\n",
    "print(f\"  \u2022 Triage Start/End\")\n",
    "print(f\"  \u2022 Doctor Seen\")\n",
    "print(f\"  \u2022 Exit Time\")\n",
    "print(f\"  \u2022 Nurses On Duty\")\n",
    "print(f\"  \u2022 Doctors On Duty\")\n",
    "\n",
    "# Convert all time columns to datetime\n",
    "time_columns = ['Arrival Time', 'Registration Start', 'Registration End', \n",
    "                'Triage Start', 'Triage End', 'Doctor Seen', 'Exit Time']\n",
    "\n",
    "for col in time_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Extract hour from Arrival Time\n",
    "df['Arrival_Hour'] = df['Arrival Time'].dt.hour\n",
    "df['Exit_Hour'] = df['Exit Time'].dt.hour\n",
    "df['Date'] = df['Arrival Time'].dt.date\n",
    "\n",
    "print(f\"\\n\u2713 DateTime conversion complete\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Total records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5befde3",
   "metadata": {},
   "source": [
    "## Section 2: Filter 5-6 AM Arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc901f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 5-6 AM arrivals only\n",
    "early_arrivals = df[(df['Arrival_Hour'] >= 5) & (df['Arrival_Hour'] <= 6)].copy()\n",
    "\n",
    "print(f\"\u2713 Filtered for 5:00 AM - 6:59 AM arrivals\")\n",
    "print(f\"\\nArrival Statistics:\")\n",
    "print(f\"  Total 5-6 AM arrivals: {len(early_arrivals)}\")\n",
    "print(f\"  Percentage of all visits: {100*len(early_arrivals)/len(df):.2f}%\")\n",
    "print(f\"\\nBreakdown by arrival hour:\")\n",
    "print(early_arrivals['Arrival_Hour'].value_counts().sort_index())\n",
    "print(f\"\\nBreakdown by date:\")\n",
    "print(f\"  Unique dates: {early_arrivals['Date'].nunique()}\")\n",
    "print(f\"  Date range: {early_arrivals['Date'].min()} to {early_arrivals['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8450da5",
   "metadata": {},
   "source": [
    "## Section 3: Calculate Flow Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key flow metrics\n",
    "print(f\"\\n\ud83d\udcca FLOW ANALYSIS: 5-6 AM ARRIVALS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# 1. ARRIVAL RATE\n",
    "arrivals_per_day = early_arrivals.groupby('Date').size()\n",
    "print(f\"1\ufe0f\u20e3  ARRIVAL RATE\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Daily average arrivals: {arrivals_per_day.mean():.2f}\")\n",
    "print(f\"  Peak day arrivals: {arrivals_per_day.max()}\")\n",
    "print(f\"  Slowest day arrivals: {arrivals_per_day.min()}\")\n",
    "print(f\"  Standard deviation: {arrivals_per_day.std():.2f}\")\n",
    "\n",
    "# 2. EXIT RATE (patients who exit during 5-6 AM)\n",
    "exits_5_6am = df[(df['Exit_Hour'] >= 5) & (df['Exit_Hour'] <= 6)].copy()\n",
    "exits_per_day = exits_5_6am.groupby(exits_5_6am['Exit Time'].dt.date).size()\n",
    "print(f\"\\n2\ufe0f\u20e3  EXIT RATE (patients exiting 5-6 AM)\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Daily average exits: {exits_per_day.mean():.2f}\")\n",
    "print(f\"  Peak day exits: {exits_per_day.max()}\")\n",
    "print(f\"  Slowest day exits: {exits_per_day.min()}\")\n",
    "print(f\"  Standard deviation: {exits_per_day.std():.2f}\")\n",
    "\n",
    "# 3. DIVERGENCE (Arrivals vs Exits)\n",
    "print(f\"\\n3\ufe0f\u20e3  FLOW DIVERGENCE (Arrivals - Exits)\")\n",
    "print(f\"{'-'*80}\")\n",
    "divergence = arrivals_per_day.mean() - exits_per_day.mean()\n",
    "print(f\"  Average divergence: {divergence:.2f} patients/day\")\n",
    "if divergence > 0:\n",
    "    print(f\"  \u26a0\ufe0f  MORE ARRIVALS than exits \u2192 Patients accumulating in system\")\n",
    "else:\n",
    "    print(f\"  \u2713 More exits than arrivals \u2192 Good flow\")\n",
    "\n",
    "# 4. PATIENTS IN SYSTEM (at 5-6 AM)\n",
    "# Calculate LOS (Length of Stay) for 5-6 AM arrivals\n",
    "early_arrivals['LOS_minutes'] = (early_arrivals['Exit Time'] - early_arrivals['Arrival Time']).dt.total_seconds() / 60\n",
    "early_arrivals['LOS_hours'] = early_arrivals['LOS_minutes'] / 60\n",
    "\n",
    "print(f\"\\n4\ufe0f\u20e3  PATIENT FLOW DURATION (5-6 AM Arrivals)\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Avg Length of Stay: {early_arrivals['LOS_minutes'].mean():.0f} minutes ({early_arrivals['LOS_hours'].mean():.2f} hours)\")\n",
    "print(f\"  Median LOS: {early_arrivals['LOS_minutes'].median():.0f} minutes\")\n",
    "print(f\"  Max LOS: {early_arrivals['LOS_minutes'].max():.0f} minutes\")\n",
    "print(f\"  Min LOS: {early_arrivals['LOS_minutes'].min():.0f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dff153",
   "metadata": {},
   "source": [
    "## Section 4: Process Bottleneck Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25be54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate individual process times\n",
    "early_arrivals['Registration_Time'] = (early_arrivals['Registration End'] - early_arrivals['Registration Start']).dt.total_seconds() / 60\n",
    "early_arrivals['Triage_Time'] = (early_arrivals['Triage End'] - early_arrivals['Triage Start']).dt.total_seconds() / 60\n",
    "early_arrivals['Wait_After_Triage'] = (early_arrivals['Doctor Seen'] - early_arrivals['Triage End']).dt.total_seconds() / 60\n",
    "early_arrivals['Doctor_Time'] = (early_arrivals['Exit Time'] - early_arrivals['Doctor Seen']).dt.total_seconds() / 60\n",
    "\n",
    "print(f\"\\n\ud83d\udccb PROCESS BOTTLENECK ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Process time breakdown\n",
    "processes = {\n",
    "    'Registration': early_arrivals['Registration_Time'],\n",
    "    'Triage': early_arrivals['Triage_Time'],\n",
    "    'Wait (Triage\u2192Doctor)': early_arrivals['Wait_After_Triage'],\n",
    "    'Doctor/Treatment': early_arrivals['Doctor_Time']\n",
    "}\n",
    "\n",
    "print(f\"AVERAGE TIME BY PROCESS STEP (minutes):\")\n",
    "print(f\"{'-'*80}\")\n",
    "process_summary = []\n",
    "for process_name, process_times in processes.items():\n",
    "    avg_time = process_times.mean()\n",
    "    pct_of_total = (avg_time / early_arrivals['LOS_minutes'].mean()) * 100\n",
    "    process_summary.append({\n",
    "        'Process': process_name,\n",
    "        'Avg_Time_Min': avg_time,\n",
    "        'Median_Time_Min': process_times.median(),\n",
    "        'Max_Time_Min': process_times.max(),\n",
    "        'Pct_of_Total': pct_of_total\n",
    "    })\n",
    "    print(f\"{process_name:25s}: {avg_time:6.1f} min (median: {process_times.median():6.1f}, max: {process_times.max():6.1f}) \u2192 {pct_of_total:5.1f}% of LOS\")\n",
    "\n",
    "process_df = pd.DataFrame(process_summary)\n",
    "print(f\"\\n{process_df.to_string(index=False)}\")\n",
    "\n",
    "# Identify bottleneck (longest process)\n",
    "bottleneck_process = process_df.loc[process_df['Avg_Time_Min'].idxmax()]\n",
    "print(f\"\\n\ud83d\udd34 PRIMARY BOTTLENECK: {bottleneck_process['Process']}\")\n",
    "print(f\"   Average time: {bottleneck_process['Avg_Time_Min']:.1f} minutes ({bottleneck_process['Pct_of_Total']:.1f}% of total LOS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fc60f",
   "metadata": {},
   "source": [
    "## Section 5: Severity Analysis - Is Doctor Time Driven by Patient Acuity?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n2\ufe0f\u20e3  SEVERITY IMPACT ON DOCTOR TIME:\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "\n",
    "# Identify if high severity patients are actually spending more time\n",
    "for severity in severity_by_time.index:\n",
    "    count = severity_by_time.loc[severity, 'Patient_Count']\n",
    "    avg_time = severity_by_time.loc[severity, 'Avg_Doctor_Time_Min']\n",
    "    pct = severity_by_time.loc[severity, 'Pct_of_Total']\n",
    "    severity_label = f\"ESI-{int(severity)}\"\n",
    "    print(f\"{severity_label:15s}: {avg_time:6.1f} min/patient | {int(count):4.0f} patients ({pct:5.1f}%) | Total time in system: {avg_time*count:8.1f} min\")\n",
    "\n",
    "# Calculate weighted average\n",
    "weighted_avg_doctor_time = (severity_by_time['Avg_Doctor_Time_Min'] * severity_by_time['Patient_Count']).sum() / len(early_arrivals)\n",
    "print(f\"\\n{'WEIGHTED AVERAGE':15s}: {weighted_avg_doctor_time:6.1f} min/patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\u2713 RECOMMENDATION:\")\n",
    "print(f\"  Add ~2-3 more doctors during 5-6 AM peak to handle the combined volume \u00d7 acuity load\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928246ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Doctor Time by Severity - The Root Cause Breakdown\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Chart 1: Doctor Time by Severity Level\n",
    "ax1 = axes[0, 0]\n",
    "esi_levels = [f\"ESI-{int(i)}\" for i in severity_by_time.index]\n",
    "doctor_times = severity_by_time['Avg_Doctor_Time_Min'].values\n",
    "colors_esi = ['#D63031', '#FF6B35', '#F7B731', '#5F27CD']\n",
    "bars1 = ax1.bar(esi_levels, doctor_times, color=colors_esi, edgecolor='black', linewidth=2)\n",
    "for bar, val in zip(bars1, doctor_times):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, val + 3, f'{val:.0f}m', ha='center', fontweight='bold', fontsize=11)\n",
    "ax1.axhline(weighted_avg_doctor_time, color='red', linestyle='--', linewidth=2.5, label=f'Avg: {weighted_avg_doctor_time:.0f}m')\n",
    "ax1.set_ylabel('Average Doctor Time (minutes)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Doctor Time by Severity Level\\n(Higher severity = Longer doctor visits)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Chart 2: Patient Volume by Severity (Pie chart)\n",
    "ax2 = axes[0, 1]\n",
    "volumes = severity_by_time['Patient_Count'].values\n",
    "labels_pie = [f\"ESI-{int(i)}\\n{int(volumes[j])} patients\\n({severity_by_time.loc[i, 'Pct_of_Total']:.1f}%)\" \n",
    "              for j, i in enumerate(severity_by_time.index)]\n",
    "ax2.pie(volumes, labels=labels_pie, colors=colors_esi, autopct='', startangle=90, \n",
    "        textprops={'fontsize': 10, 'fontweight': 'bold'}, explode=(0.05, 0.05, 0.05, 0.05))\n",
    "ax2.set_title('Patient Volume Distribution by Severity\\n(ESI-3 dominates: 50% of arrivals)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Chart 3: Total Doctor-Time Burden (Volume \u00d7 Acuity)\n",
    "ax3 = axes[1, 0]\n",
    "total_times = severity_by_time['Total_Doctor_Time_Minutes'].values\n",
    "bars3 = ax3.bar(esi_levels, total_times, color=colors_esi, edgecolor='black', linewidth=2)\n",
    "for bar, val in zip(bars3, total_times):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, val + 1500, f'{int(val):,}m', ha='center', fontweight='bold', fontsize=10)\n",
    "ax3.set_ylabel('Total Doctor-Time Needed (minutes)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Total Doctor-Time Burden by Severity\\n(Volume \u00d7 Acuity: ESI-3 is the largest burden)', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Chart 4: The Staffing Gap\n",
    "ax4 = axes[1, 1]\n",
    "available_time = early_arrivals['Doctors On Duty'].mean() * 60  # minutes available per hour\n",
    "needed_time = total_all_doctor_time\n",
    "shortfall = needed_time - available_time\n",
    "\n",
    "ax4.barh(['Doctor-Time\\nAvailable', 'Doctor-Time\\nNeeded'], [available_time, needed_time], \n",
    "         color=['#2ECC71', '#E74C3C'], edgecolor='black', linewidth=2)\n",
    "ax4.text(available_time/2, 0, f'{available_time:.0f} min\\n({early_arrivals[\"Doctors On Duty\"].mean():.1f} docs)', \n",
    "         ha='center', va='center', fontweight='bold', fontsize=11, color='white')\n",
    "ax4.text(needed_time/2, 1, f'{int(needed_time):,} min\\nSHORTFALL:\\n{int(shortfall):,} min', \n",
    "         ha='center', va='center', fontweight='bold', fontsize=11, color='white')\n",
    "ax4.set_xlabel('Doctor-Time (minutes per hour)', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('The Staffing Gap: Why the Bottleneck Exists\\n(Not enough doctors for the volume)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlim(0, needed_time * 1.1)\n",
    "\n",
    "plt.suptitle('Severity Analysis: What\\'s Causing the Doctor/Treatment Bottleneck?\\n5-6 AM Window', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/severity_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Severity analysis visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b3d6c",
   "metadata": {},
   "source": [
    "## EXECUTIVE SUMMARY: Severity Analysis Findings\n",
    "\n",
    "### Your Questions - Answered \u2713\n",
    "\n",
    "**Q1: Is doctor delay caused by HIGH SEVERITY PATIENTS?**\n",
    "\n",
    "**A: PARTIALLY YES - Severity does impact doctor time, but it's not the PRIMARY driver**\n",
    "- ESI-1 (Immediate) patients spend 151 minutes with doctors\n",
    "- ESI-3 (Urgent) patients spend 99 minutes with doctors\n",
    "- **BUT**: The correlation is weak (-0.61) \u2192 Volume matters more than acuity\n",
    "\n",
    "---\n",
    "\n",
    "**Q2: Which severity group actually spends MORE time with doctor?**\n",
    "\n",
    "**A: The data shows a clear severity gradient:**\n",
    "| Severity Level | Avg Doctor Time | Patients | % of Total |\n",
    "|---|---|---|---|\n",
    "| **ESI-1 (Immediate)** | **151.3 min** | 78 | 6.4% |\n",
    "| **ESI-2 (Emergent)** | **132.1 min** | 330 | 27.1% |\n",
    "| **ESI-3 (Urgent)** | **98.6 min** | 610 | 50.0% |\n",
    "| **ESI-4 (Less Urgent)** | **82.1 min** | 201 | 16.5% |\n",
    "\n",
    "**YES**: Higher severity = significantly more doctor time (39% difference between ESI-1 and ESI-4)\n",
    "\n",
    "---\n",
    "\n",
    "**Q3: Is THIS severity group large during 5-6 AM?**\n",
    "\n",
    "**A: NO - The large group is ESI-3 (Urgent), NOT the high-severity ESI-1**\n",
    "- **ESI-3 dominates**: 50% of all 5-6 AM arrivals (610 patients)\n",
    "- **ESI-3 total burden**: 60,146 minutes (45.6% of ALL doctor time)\n",
    "- **ESI-1 is tiny**: Only 6.4% of arrivals (78 patients)\n",
    "\n",
    "---\n",
    "\n",
    "### The Real Problem: VOLUME \u00d7 ACUITY Mismatch\n",
    "\n",
    "```\n",
    "Total Doctor-Time Available per hour:  ~94 minutes (at 1.5 doctors on duty)\n",
    "Total Doctor-Time NEEDED:             132,042 minutes\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "SHORTFALL:                            131,948 minutes \u26a0\ufe0f\n",
    "```\n",
    "\n",
    "The bottleneck is caused by:\n",
    "1. **HIGH VOLUME of ESI-3 patients** (50% of arrivals)\n",
    "2. **MODERATE time each ESI-3 spends** (~99 min with doctor)\n",
    "3. **INSUFFICIENT STAFFING** to handle this combined load\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "\u2705 **Add 2-3 more doctors during 5-6 AM peak hours**\n",
    "- This will reduce wait times and help patients flow through faster\n",
    "- Focus on ESI-3 patient throughput (the bottleneck driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Severity Analysis to CSV\n",
    "severity_export = pd.DataFrame({\n",
    "    'Severity_Level': [f\"ESI-{int(i)}\" for i in severity_by_time.index],\n",
    "    'Patient_Count': severity_by_time['Patient_Count'].values.astype(int),\n",
    "    'Percent_of_Total': severity_by_time['Pct_of_Total'].values.round(1),\n",
    "    'Avg_Doctor_Time_Minutes': severity_by_time['Avg_Doctor_Time_Min'].values.round(1),\n",
    "    'Total_Doctor_Time_Minutes': (severity_by_time['Total_Doctor_Time_Minutes']).values.astype(int),\n",
    "    'Percent_of_Total_Doctor_Time': (severity_by_time['Total_Doctor_Time_Minutes'].values / severity_by_time['Total_Doctor_Time_Minutes'].sum() * 100).round(1)\n",
    "})\n",
    "\n",
    "severity_export = severity_export.sort_values('Total_Doctor_Time_Minutes', ascending=False)\n",
    "severity_export.to_csv('/Users/mukeshravichandran/Datathon/5to7_Surge/severity_analysis.csv', index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SEVERITY ANALYSIS - FINAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(severity_export.to_string(index=False))\n",
    "print(\"\\n\u2713 Exported to: severity_analysis.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"KEY STATISTICS:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total Patients (5-6 AM arrivals): {len(early_arrivals):,}\")\n",
    "print(f\"Largest Group: ESI-3 (50.0% of arrivals)\")\n",
    "print(f\"Total Doctor-Time Required: {int(severity_by_time['Total_Doctor_Time_Minutes'].sum()):,} minutes\")\n",
    "print(f\"Average Doctors Available: {early_arrivals['Doctors On Duty'].mean():.1f} doctors\")\n",
    "print(f\"Doctor-Time Deficit: {int(severity_by_time['Total_Doctor_Time_Minutes'].sum() - early_arrivals['Doctors On Duty'].mean()*60):,} minutes\")\n",
    "print(f\"\\n\u2713 Analysis Complete! Check: severity_analysis.png for visualization\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b59cb0",
   "metadata": {},
   "source": [
    "## Section 6: Pipeline Analysis - Patients ALREADY in System During 5-6 AM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01684fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL CORRECTION: Include patients from EARLIER arrivals still in system\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PIPELINE ANALYSIS: CORRECTED DOCTOR DEMAND\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"\u26a0\ufe0f  CRITICAL INSIGHT: Patients arriving BEFORE 5-6 AM are still consuming doctor time!\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "\n",
    "# Step 1: Find ALL patients who are being seen by doctor DURING 5-6 AM window\n",
    "# This includes:\n",
    "#   A) Patients who arrived 5-6 AM and saw doctor 5-6 AM\n",
    "#   B) Patients who arrived BEFORE 5 AM but see doctor DURING 5-6 AM\n",
    "\n",
    "df_with_hours = df.copy()\n",
    "df_with_hours['Arrival_Hour'] = df_with_hours['Arrival Time'].dt.hour\n",
    "df_with_hours['Doctor_Seen_Hour'] = df_with_hours['Doctor Seen'].dt.hour\n",
    "df_with_hours['Exit_Hour'] = df_with_hours['Exit Time'].dt.hour\n",
    "\n",
    "# Calculate doctor time (if not already done)\n",
    "df_with_hours['Doctor_Time'] = (df_with_hours['Exit Time'] - df_with_hours['Doctor Seen']).dt.total_seconds() / 60\n",
    "\n",
    "# Find all patients whose doctor visit OVERLAPS with 5-6 AM window\n",
    "# A patient is \"in doctor visit during 5-6 AM\" if:\n",
    "#   - Doctor Seen time is <= 6:59 AM AND\n",
    "#   - Exit Time is > 5:00 AM (doctor visit extends into 5-6 AM window)\n",
    "\n",
    "from datetime import time\n",
    "\n",
    "# Create reference times\n",
    "time_5am = pd.Timestamp('1970-01-01 05:00:00').time()\n",
    "time_7am = pd.Timestamp('1970-01-01 07:00:00').time()\n",
    "\n",
    "patients_doctor_during_5_6 = df_with_hours[\n",
    "    (df_with_hours['Doctor Seen'].dt.time <= time_7am) &\n",
    "    (df_with_hours['Exit Time'].dt.time >= time_5am) &\n",
    "    (df_with_hours['Doctor_Time'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"1\ufe0f\u20e3  PATIENTS WITH DOCTOR VISITS DURING 5-6 AM:\")\n",
    "print(f\"{'-'*80}\")\n",
    "\n",
    "# Categorize them\n",
    "arrivals_5_6_sees_doctor_5_6 = patients_doctor_during_5_6[\n",
    "    (patients_doctor_during_5_6['Arrival_Hour'] >= 5) & \n",
    "    (patients_doctor_during_5_6['Arrival_Hour'] <= 6)\n",
    "].copy()\n",
    "\n",
    "arrivals_before_5_sees_doctor_5_6 = patients_doctor_during_5_6[\n",
    "    (patients_doctor_during_5_6['Arrival_Hour'] < 5)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nGroup A: Arrived 5-6 AM, saw doctor during 5-6 AM:\")\n",
    "print(f\"  Count: {len(arrivals_5_6_sees_doctor_5_6)} patients\")\n",
    "print(f\"  Avg doctor time: {arrivals_5_6_sees_doctor_5_6['Doctor_Time'].mean():.1f} minutes\")\n",
    "\n",
    "print(f\"\\nGroup B: Arrived BEFORE 5 AM, saw doctor DURING 5-6 AM (BACKLOG):\")\n",
    "print(f\"  Count: {len(arrivals_before_5_sees_doctor_5_6)} patients\")\n",
    "print(f\"  Avg doctor time: {arrivals_before_5_sees_doctor_5_6['Doctor_Time'].mean():.1f} minutes\")\n",
    "\n",
    "print(f\"\\nTotal patients consuming doctor time during 5-6 AM:\")\n",
    "print(f\"  {len(patients_doctor_during_5_6)} patients\")\n",
    "\n",
    "print(f\"\\n\\n2\ufe0f\u20e3  DOCTOR-TIME DEMAND BREAKDOWN:\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "\n",
    "group_a_burden = (arrivals_5_6_sees_doctor_5_6['Doctor_Time'].sum())\n",
    "group_b_burden = (arrivals_before_5_sees_doctor_5_6['Doctor_Time'].sum())\n",
    "total_burden_corrected = group_a_burden + group_b_burden\n",
    "\n",
    "print(f\"Group A (arrived 5-6 AM):\")\n",
    "print(f\"  Patients: {len(arrivals_5_6_sees_doctor_5_6)}\")\n",
    "print(f\"  Total doctor-time: {int(group_a_burden):,} minutes ({group_a_burden/total_burden_corrected*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nGroup B (arrived BEFORE 5 AM, backlog):\")\n",
    "print(f\"  Patients: {len(arrivals_before_5_sees_doctor_5_6)}\")\n",
    "print(f\"  Total doctor-time: {int(group_b_burden):,} minutes ({group_b_burden/total_burden_corrected*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTOTAL doctor-time needed during 5-6 AM window:\")\n",
    "print(f\"  {int(total_burden_corrected):,} minutes\")\n",
    "\n",
    "available_doctor_time = early_arrivals['Doctors On Duty'].mean() * 60\n",
    "shortfall_corrected = total_burden_corrected - available_doctor_time\n",
    "\n",
    "print(f\"\\nDoctor-time AVAILABLE (1.6 docs \u00d7 60 min): {int(available_doctor_time)} minutes\")\n",
    "print(f\"Shortfall: {int(shortfall_corrected):,} minutes\")\n",
    "\n",
    "print(f\"\\n\\n3\ufe0f\u20e3  BACKLOG IMPACT - THE CRITICAL FINDING:\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "\n",
    "pct_backlog = (len(arrivals_before_5_sees_doctor_5_6) / len(patients_doctor_during_5_6)) * 100\n",
    "print(f\"\ud83d\udd34 BACKLOG FROM EARLIER ARRIVALS: {len(arrivals_before_5_sees_doctor_5_6)} patients ({pct_backlog:.1f}%)\")\n",
    "print(f\"   These patients are DELAYING the new 5-6 AM arrivals!\")\n",
    "\n",
    "print(f\"\\nThis means:\")\n",
    "print(f\"  \u2022 Only {len(arrivals_5_6_sees_doctor_5_6)} out of {len(patients_doctor_during_5_6)} patients getting doctor time are 5-6 AM arrivals\")\n",
    "print(f\"  \u2022 {int(group_b_burden):,} of the {int(total_burden_corrected):,} available doctor-minutes are consumed by overnight backlog\")\n",
    "print(f\"  \u2022 This WORSENS the bottleneck for 5-6 AM patients\")\n",
    "\n",
    "print(f\"\\n\\n4\ufe0f\u20e3  REVISED CONCLUSION:\")\n",
    "print(f\"{'-'*80}\\n\")\n",
    "print(f\"The 5-6 AM bottleneck is WORSE than initially analyzed because:\")\n",
    "print(f\"  \u2713 New 5-6 AM patients arrive: {len(early_arrivals)} patients\")\n",
    "print(f\"  \u2713 Backlog from earlier arrivals: {len(arrivals_before_5_sees_doctor_5_6)} patients still being seen\")\n",
    "print(f\"  \u2713 Total demand for doctor time: {len(patients_doctor_during_5_6)} patients\")\n",
    "print(f\"  \u2713 Doctor-time needed: {int(total_burden_corrected):,} minutes\")\n",
    "print(f\"  \u2713 Available: {int(available_doctor_time)} minutes\")\n",
    "print(f\"  \u2713 Shortfall: {int(shortfall_corrected):,} minutes\")\n",
    "print(f\"\\n\ud83c\udfaf The backlog ({len(arrivals_before_5_sees_doctor_5_6)} patients from earlier) means doctors are STILL BUSY\")\n",
    "print(f\"   when new morning surge arrives, creating a perfect storm!\")\n",
    "print(f\"   Doctors are trying to handle BOTH overnight backlog AND morning surge simultaneously.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c31241",
   "metadata": {},
   "source": [
    "## Section 7: Complete System Snapshot - Where Is Everyone During 5-6 AM?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE SYSTEM SNAPSHOT: Where is EVERYONE during 5-6 AM?\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"COMPLETE SYSTEM SNAPSHOT: PATIENT PIPELINE AT 5:00 AM - 6:59 AM\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# Define cutoff time: 6:59 AM (as just time, not datetime)\n",
    "cutoff_time_value = pd.Timestamp('1970-01-01 06:59:59')\n",
    "ref_5am_time = pd.Timestamp('1970-01-01 05:00:00')\n",
    "\n",
    "# Find all patients who had ANY part of their journey during 5-6 AM\n",
    "# = Arrived by 6:59 AM AND (Haven't exited OR exited after 5:00 AM)\n",
    "\n",
    "patients_in_system_5_6 = df[\n",
    "    (df['Arrival Time'].dt.time <= cutoff_time_value.time()) &\n",
    "    ((df['Exit Time'].isna()) | (df['Exit Time'].dt.time >= ref_5am_time.time()))\n",
    "].copy()\n",
    "\n",
    "print(f\"1\ufe0f\u20e3  TOTAL PATIENTS IN SYSTEM during 5-6 AM window: {len(patients_in_system_5_6)} patients\")\n",
    "print(f\"    (Arrived by 6:59 AM AND either still in system or exited at/after 5:00 AM)\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "# Categorize by arrival time\n",
    "patients_in_system_5_6['Arrival_Hour'] = patients_in_system_5_6['Arrival Time'].dt.hour\n",
    "before_5am = patients_in_system_5_6[patients_in_system_5_6['Arrival_Hour'] < 5]\n",
    "arrived_5_6am = patients_in_system_5_6[(patients_in_system_5_6['Arrival_Hour'] >= 5) & (patients_in_system_5_6['Arrival_Hour'] <= 6)]\n",
    "\n",
    "print(f\"Patients by Arrival Time (counting those present during 5-6 AM window):\")\n",
    "print(f\"  \u2022 Arrived BEFORE 5 AM:  {len(before_5am):5d} patients ({len(before_5am)/len(patients_in_system_5_6)*100:5.1f}%)\")\n",
    "print(f\"  \u2022 Arrived 5-6 AM:       {len(arrived_5_6am):5d} patients ({len(arrived_5_6am)/len(patients_in_system_5_6)*100:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n\\n2\ufe0f\u20e3  PATIENT STATUS - WHERE ARE THEY IN THE PIPELINE AT 6:59 AM?\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "# CORRECTED logic using TIME comparison (not datetime)\n",
    "# - WITH DOCTOR: Doctor_Seen time <= 6:59 AM AND (Exit is NULL or Exit time > 6:59 AM)\n",
    "# - EXITED: Exit Time time <= 6:59 AM\n",
    "# - NOT_YET_WITH_DOCTOR: Doctor_Seen is NULL or time > 6:59 AM\n",
    "\n",
    "def get_patient_status_corrected(row):\n",
    "    \"\"\"\n",
    "    Determine where patient is in their journey at 6:59 AM.\n",
    "    Compare using TIME values only (ignoring date differences)\n",
    "    \n",
    "    Key logic:\n",
    "    - If Exit Time (time portion) <= 6:59 AM: EXITED (regardless of why)\n",
    "    - If Doctor Seen (time portion) <= 6:59 AM AND (Exit is NULL or Exit time > 6:59 AM): WITH_DOCTOR\n",
    "    - If Doctor Seen (time portion) > 6:59 AM or NULL: Check earlier stages\n",
    "    \"\"\"\n",
    "    exit_time = row['Exit Time']\n",
    "    doctor_seen = row['Doctor Seen']\n",
    "    triage_end = row['Triage End']\n",
    "    triage_start = row['Triage Start']\n",
    "    reg_end = row['Registration End']\n",
    "    reg_start = row['Registration Start']\n",
    "    \n",
    "    # Extract time portions\n",
    "    exit_time_only = exit_time.time() if pd.notna(exit_time) else None\n",
    "    doctor_seen_only = doctor_seen.time() if pd.notna(doctor_seen) else None\n",
    "    triage_end_only = triage_end.time() if pd.notna(triage_end) else None\n",
    "    triage_start_only = triage_start.time() if pd.notna(triage_start) else None\n",
    "    reg_end_only = reg_end.time() if pd.notna(reg_end) else None\n",
    "    reg_start_only = reg_start.time() if pd.notna(reg_start) else None\n",
    "    \n",
    "    cutoff = cutoff_time_value.time()  # 6:59:59\n",
    "    \n",
    "    # FIRST check: Did they exit by 6:59 AM? (using time only)\n",
    "    if exit_time_only is not None and exit_time_only <= cutoff:\n",
    "        return 'EXITED_BY_659'\n",
    "    \n",
    "    # SECOND check: Are they with doctor? (Saw doctor by 6:59 AND haven't exited yet)\n",
    "    if doctor_seen_only is not None and doctor_seen_only <= cutoff:\n",
    "        return 'WITH_DOCTOR'\n",
    "    \n",
    "    # THIRD check: Post-triage waiting for doctor\n",
    "    if triage_end_only is not None and triage_end_only <= cutoff:\n",
    "        return 'WAITING_FOR_DOCTOR'\n",
    "    \n",
    "    # FOURTH check: Currently in triage\n",
    "    if triage_start_only is not None and triage_start_only <= cutoff:\n",
    "        return 'IN_TRIAGE'\n",
    "    \n",
    "    # FIFTH check: Post-registration, not yet triaged\n",
    "    if reg_end_only is not None and reg_end_only <= cutoff:\n",
    "        return 'POST_REGISTRATION'\n",
    "    \n",
    "    # SIXTH check: In registration\n",
    "    if reg_start_only is not None and reg_start_only <= cutoff:\n",
    "        return 'IN_REGISTRATION'\n",
    "    \n",
    "    # SEVENTH: Just arrived or about to start\n",
    "    return 'JUST_ARRIVED'\n",
    "\n",
    "patients_in_system_5_6['Status_at_659'] = patients_in_system_5_6.apply(get_patient_status_corrected, axis=1)\n",
    "\n",
    "status_dist = patients_in_system_5_6['Status_at_659'].value_counts()\n",
    "print(f\"Patient Status Distribution (at 6:59 AM, counting only up to that time):\")\n",
    "status_order = ['JUST_ARRIVED', 'IN_REGISTRATION', 'POST_REGISTRATION', 'IN_TRIAGE', 'WAITING_FOR_DOCTOR', 'WITH_DOCTOR', 'EXITED_BY_659']\n",
    "for status in status_order:\n",
    "    count = status_dist.get(status, 0)\n",
    "    if count > 0:\n",
    "        pct = (count / len(patients_in_system_5_6)) * 100\n",
    "        print(f\"  \u2022 {status:25s}: {count:5d} patients ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n\\n3\ufe0f\u20e3  BREAKDOWN BY ARRIVAL COHORT & STATUS\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "for cohort_name, cohort_df in [('BEFORE 5 AM', before_5am), ('5-6 AM ARRIVALS', arrived_5_6am)]:\n",
    "    if len(cohort_df) > 0:\n",
    "        cohort_df['Status_at_659'] = cohort_df.apply(get_patient_status_corrected, axis=1)\n",
    "        print(f\"\\n{cohort_name} (n={len(cohort_df)}):\")\n",
    "        status_counts = cohort_df['Status_at_659'].value_counts()\n",
    "        \n",
    "        for status in status_order:\n",
    "            count = status_counts.get(status, 0)\n",
    "            if count > 0:\n",
    "                pct = (count / len(cohort_df)) * 100\n",
    "                print(f\"    {status:25s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n\\n4\ufe0f\u20e3  NOW BY SEVERITY LEVEL - WHO'S IN WHAT STAGE?\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "# For each severity level\n",
    "for severity in sorted(patients_in_system_5_6['Triage Level'].dropna().unique()):\n",
    "    severity_patients = patients_in_system_5_6[patients_in_system_5_6['Triage Level'] == severity]\n",
    "    severity_patients['Status_at_659'] = severity_patients.apply(get_patient_status_corrected, axis=1)\n",
    "    print(f\"\\nESI-{int(severity)} ({len(severity_patients)} patients total):\")\n",
    "    \n",
    "    status_dist = severity_patients['Status_at_659'].value_counts()\n",
    "    \n",
    "    for status in status_order:\n",
    "        count = status_dist.get(status, 0)\n",
    "        if count > 0:\n",
    "            pct = (count / len(severity_patients)) * 100\n",
    "            print(f\"    \u2022 {status:25s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n\\n5\ufe0f\u20e3  SEVERITY \u00d7 ARRIVAL TIME \u00d7 STATUS - FULL BREAKDOWN\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "patients_in_system_5_6['Arrival_Cohort'] = patients_in_system_5_6['Arrival_Hour'].apply(\n",
    "    lambda x: 'Before 5 AM' if x < 5 else '5-6 AM'\n",
    ")\n",
    "\n",
    "for cohort in ['Before 5 AM', '5-6 AM']:\n",
    "    cohort_data = patients_in_system_5_6[patients_in_system_5_6['Arrival_Cohort'] == cohort]\n",
    "    if len(cohort_data) > 0:\n",
    "        print(f\"\\n{cohort.upper()}:\")\n",
    "        for severity in sorted(cohort_data['Triage Level'].dropna().unique()):\n",
    "            subset = cohort_data[cohort_data['Triage Level'] == severity]\n",
    "            subset['Status_at_659'] = subset.apply(get_patient_status_corrected, axis=1)\n",
    "            \n",
    "            print(f\"  ESI-{int(severity)} ({len(subset)} patients):\")\n",
    "            status_counts = subset['Status_at_659'].value_counts()\n",
    "            for status in status_order:\n",
    "                count = status_counts.get(status, 0)\n",
    "                if count > 0:\n",
    "                    pct = (count / len(subset)) * 100\n",
    "                    print(f\"    {status:25s}: {count:3d} ({pct:4.1f}%)\")\n",
    "\n",
    "print(f\"\\n\\n6\ufe0f\u20e3  CRITICAL FINDINGS: WHERE IS THE BOTTLENECK?\")\n",
    "print(f\"{'-'*100}\\n\")\n",
    "\n",
    "# Identify bottleneck\n",
    "waiting_for_doctor = patients_in_system_5_6[patients_in_system_5_6['Status_at_659'] == 'WAITING_FOR_DOCTOR']\n",
    "with_doctor = patients_in_system_5_6[patients_in_system_5_6['Status_at_659'] == 'WITH_DOCTOR']\n",
    "exited = patients_in_system_5_6[patients_in_system_5_6['Status_at_659'] == 'EXITED_BY_659']\n",
    "in_triage = patients_in_system_5_6[patients_in_system_5_6['Status_at_659'] == 'IN_TRIAGE']\n",
    "\n",
    "print(f\"Patients WAITING FOR DOCTOR (post-triage): {len(waiting_for_doctor):4d} ({len(waiting_for_doctor)/len(patients_in_system_5_6)*100:5.1f}%) \u2190 PRIMARY BOTTLENECK\")\n",
    "if len(waiting_for_doctor) > 0:\n",
    "    print(f\"  Average wait after triage: {waiting_for_doctor['WaitTime after Triage'].mean():.0f} minutes\")\n",
    "    print(f\"  By severity:\")\n",
    "    for sev in sorted(waiting_for_doctor['Triage Level'].dropna().unique()):\n",
    "        sev_waiting = waiting_for_doctor[waiting_for_doctor['Triage Level'] == sev]\n",
    "        print(f\"    ESI-{int(sev)}: {len(sev_waiting):3d} patients (avg wait: {sev_waiting['WaitTime after Triage'].mean():.0f} min)\")\n",
    "\n",
    "print(f\"\\nPatients WITH DOCTOR (saw doctor, not yet exited): {len(with_doctor):4d} ({len(with_doctor)/len(patients_in_system_5_6)*100:5.1f}%)\")\n",
    "print(f\"  By severity:\")\n",
    "for sev in sorted(with_doctor['Triage Level'].dropna().unique()):\n",
    "    sev_with_doc = with_doctor[with_doctor['Triage Level'] == sev]\n",
    "    print(f\"    ESI-{int(sev)}: {len(sev_with_doc):3d} patients\")\n",
    "\n",
    "print(f\"\\nPatients who EXITED by 6:59 AM: {len(exited):4d} ({len(exited)/len(patients_in_system_5_6)*100:5.1f}%)\")\n",
    "print(f\"  (Includes admitted, transferred, discharged - all left ED system)\")\n",
    "\n",
    "print(f\"\\nPatients IN TRIAGE: {len(in_triage):4d} ({len(in_triage)/len(patients_in_system_5_6)*100:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c84bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization: Complete System Snapshot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Complete System Snapshot at 5-6 AM: Where Is Every Patient?', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "# Panel 1: Status Distribution - Overall\n",
    "ax = axes[0, 0]\n",
    "status_order = ['JUST_ARRIVED', 'IN_REGISTRATION', 'POST_REGISTRATION', 'IN_TRIAGE', 'WAITING_FOR_DOCTOR', 'WITH_DOCTOR', 'WITH_DOCTOR_OR_POST', 'DISCHARGED']\n",
    "status_counts = patients_in_system_5_6['Status_at_659'].value_counts().reindex(status_order, fill_value=0)\n",
    "status_labels = ['Just\\nArrived', 'In\\nRegistration', 'Post\\nRegistration', 'In\\nTriage', 'Waiting for\\nDoctor', 'With\\nDoctor', 'With Dr\\n(or post)', 'Discharged']\n",
    "\n",
    "colors_status = ['#FF6B6B', '#FFA500', '#FFD700', '#87CEEB', '#FF4444', '#FF0000', '#8B0000', '#90EE90']\n",
    "bars = ax.bar(range(len(status_counts)), status_counts.values, color=colors_status)\n",
    "ax.set_xticks(range(len(status_counts)))\n",
    "ax.set_xticklabels(status_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_title('Panel 1: Patient Status Distribution', fontweight='bold', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    if height > 0:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Panel 2: Status by Arrival Cohort\n",
    "ax = axes[0, 1]\n",
    "cohort_status = pd.crosstab(patients_in_system_5_6['Arrival_Cohort'], patients_in_system_5_6['Status_at_659'])\n",
    "cohort_status_reordered = cohort_status.reindex(columns=[s for s in status_order if s in cohort_status.columns], fill_value=0)\n",
    "\n",
    "cohort_status_reordered.plot(kind='bar', ax=ax, color=colors_status[:len(cohort_status_reordered.columns)], width=0.7)\n",
    "ax.set_title('Panel 2: Status by Arrival Cohort', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_xlabel('Arrival Time', fontweight='bold')\n",
    "ax.legend(title='Status', labels=status_labels[:len(cohort_status_reordered.columns)], bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Panel 3: Severity Distribution in System\n",
    "ax = axes[1, 0]\n",
    "severity_counts = patients_in_system_5_6['Triage Level'].value_counts().sort_index()\n",
    "colors_severity = ['#FF0000', '#FFA500', '#FFD700', '#90EE90']\n",
    "labels_severity = [f'ESI-{int(s)}' for s in severity_counts.index]\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(severity_counts.values, labels=labels_severity, autopct='%1.1f%%',\n",
    "                                    colors=colors_severity[:len(severity_counts)], startangle=90)\n",
    "ax.set_title('Panel 3: Patient Severity Level Distribution', fontweight='bold', fontsize=12)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "# Panel 4: Status by Severity (stacked bar)\n",
    "ax = axes[1, 1]\n",
    "severity_status = pd.crosstab(patients_in_system_5_6['Triage Level'], patients_in_system_5_6['Status_at_659'])\n",
    "severity_status_reordered = severity_status.reindex(columns=[s for s in status_order if s in severity_status.columns], fill_value=0)\n",
    "\n",
    "severity_status_reordered.plot(kind='bar', stacked=True, ax=ax, color=colors_status[:len(severity_status_reordered.columns)], width=0.6)\n",
    "ax.set_title('Panel 4: Patient Status by Severity Level', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_xlabel('ESI Level', fontweight='bold')\n",
    "severity_labels = [f'ESI-{int(s)}' for s in severity_status_reordered.index]\n",
    "ax.set_xticklabels(severity_labels, rotation=0)\n",
    "ax.legend(title='Status', labels=status_labels[:len(severity_status_reordered.columns)], bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('complete_system_snapshot.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\u2705 Complete System Snapshot visualization saved: complete_system_snapshot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export Complete System Snapshot Data\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"EXPORTING COMPLETE SYSTEM SNAPSHOT DATA\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# 1. Create comprehensive breakdown table\n",
    "snapshot_export = []\n",
    "\n",
    "for cohort in ['Before 5 AM', '5-6 AM']:\n",
    "    for severity in sorted(patients_in_system_5_6['Triage Level'].dropna().unique()):\n",
    "        for status in ['JUST_ARRIVED', 'IN_REGISTRATION', 'POST_REGISTRATION', 'IN_TRIAGE', 'WAITING_FOR_DOCTOR', 'WITH_DOCTOR', 'WITH_DOCTOR_OR_POST', 'DISCHARGED']:\n",
    "            subset = patients_in_system_5_6[\n",
    "                (patients_in_system_5_6['Arrival_Cohort'] == cohort) &\n",
    "                (patients_in_system_5_6['Triage Level'] == severity) &\n",
    "                (patients_in_system_5_6['Status_at_659'] == status)\n",
    "            ]\n",
    "            \n",
    "            if len(subset) > 0:\n",
    "                snapshot_export.append({\n",
    "                    'Arrival_Cohort': cohort,\n",
    "                    'Severity': f'ESI-{int(severity)}',\n",
    "                    'Pipeline_Status': status,\n",
    "                    'Patient_Count': len(subset),\n",
    "                    'Avg_Wait_After_Triage_Min': subset['WaitTime after Triage'].mean() if 'WaitTime after Triage' in subset.columns else None,\n",
    "                    'Avg_Doctor_Time_Min': subset['DoctorTime'].mean() if 'DoctorTime' in subset.columns else None,\n",
    "                })\n",
    "\n",
    "snapshot_df = pd.DataFrame(snapshot_export)\n",
    "snapshot_df = snapshot_df.sort_values(['Arrival_Cohort', 'Severity', 'Pipeline_Status'])\n",
    "\n",
    "# Export to CSV\n",
    "snapshot_df.to_csv('complete_system_snapshot.csv', index=False)\n",
    "print(f\"\u2705 Exported: complete_system_snapshot.csv ({len(snapshot_df)} rows)\")\n",
    "print(f\"\\nPreview of exported data:\")\n",
    "print(snapshot_df.to_string(index=False))\n",
    "\n",
    "# 2. Create summary statistics\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(f\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "for cohort in ['Before 5 AM', '5-6 AM']:\n",
    "    cohort_data = patients_in_system_5_6[patients_in_system_5_6['Arrival_Cohort'] == cohort]\n",
    "    \n",
    "    for severity in sorted(cohort_data['Triage Level'].dropna().unique()):\n",
    "        severity_data = cohort_data[cohort_data['Triage Level'] == severity]\n",
    "        \n",
    "        waiting = severity_data[severity_data['Status_at_659'] == 'WAITING_FOR_DOCTOR']\n",
    "        with_doc = severity_data[severity_data['Status_at_659'].isin(['WITH_DOCTOR', 'WITH_DOCTOR_OR_POST'])]\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'Arrival_Cohort': cohort,\n",
    "            'Severity': f'ESI-{int(severity)}',\n",
    "            'Total_Patients': len(severity_data),\n",
    "            'Waiting_for_Doctor': len(waiting),\n",
    "            'With_Doctor': len(with_doc),\n",
    "            'Avg_Wait_After_Triage': waiting['WaitTime after Triage'].mean() if len(waiting) > 0 else 0,\n",
    "            'Max_Wait_After_Triage': waiting['WaitTime after Triage'].max() if len(waiting) > 0 else 0,\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv('system_snapshot_summary.csv', index=False)\n",
    "print(f\"\u2705 Exported: system_snapshot_summary.csv\")\n",
    "print(f\"\\n{summary_df.to_string(index=False)}\")\n",
    "\n",
    "print(f\"\\n\\n{'='*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 8: DETAILED EXITED BREAKDOWN - WHO LEFT THE SYSTEM AND HOW?\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"SECTION 8: EXITED PATIENTS BREAKDOWN - WHERE DID THEY GO?\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# Find all patients who exited by 6:59 AM\n",
    "cutoff_time_value = pd.Timestamp('1970-01-01 06:59:00').time()\n",
    "exited_patients = df[\n",
    "    (df['Exit Time'].notna()) &\n",
    "    (df['Exit Time'].dt.time <= cutoff_time_value)\n",
    "].copy()\n",
    "\n",
    "# Calculate doctor time for exited patients\n",
    "exited_patients['Doctor_Time'] = (exited_patients['Exit Time'] - exited_patients['Doctor Seen']).dt.total_seconds() / 60\n",
    "exited_patients['Wait_After_Triage'] = (exited_patients['Doctor Seen'] - exited_patients['Triage End']).dt.total_seconds() / 60\n",
    "\n",
    "print(f\"TOTAL PATIENTS WHO EXITED BY 6:59 AM: {len(exited_patients)}\\n\")\n",
    "\n",
    "# Breakdown by exit reason (Disposition)\n",
    "if 'Disposition' in exited_patients.columns:\n",
    "    exit_reasons = exited_patients['Disposition'].value_counts()\n",
    "    print(\"BREAKDOWN BY EXIT REASON (Disposition):\")\n",
    "    print(\"-\" * 60)\n",
    "    for reason, count in exit_reasons.items():\n",
    "        pct = (count / len(exited_patients)) * 100\n",
    "        print(f\"  {reason:30s}: {count:4d} patients ({pct:5.1f}%)\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  'Disposition' column not found\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Breakdown by severity for those who exited\n",
    "print(\"EXITED PATIENTS BY SEVERITY:\")\n",
    "print(\"-\" * 60)\n",
    "exit_severity = exited_patients['Triage Level'].value_counts().sort_index()\n",
    "for sev, count in exit_severity.items():\n",
    "    pct = (count / len(exited_patients)) * 100\n",
    "    print(f\"  ESI-{int(sev)}: {count:4d} patients ({pct:5.1f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Average times for those who exited\n",
    "print(\"AVERAGE WAIT TIMES FOR PATIENTS WHO EXITED BY 6:59 AM:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'Wait_After_Triage' in exited_patients.columns:\n",
    "    avg_wait = exited_patients['Wait_After_Triage'].mean()\n",
    "    max_wait = exited_patients['Wait_After_Triage'].max()\n",
    "    print(f\"  {'Wait After Triage':25s}: Avg = {avg_wait:6.1f} min, Max = {max_wait:6.1f} min\")\n",
    "\n",
    "if 'Doctor_Time' in exited_patients.columns:\n",
    "    avg_doc = exited_patients['Doctor_Time'].mean()\n",
    "    max_doc = exited_patients['Doctor_Time'].max()\n",
    "    print(f\"  {'Doctor Time':25s}: Avg = {avg_doc:6.1f} min, Max = {max_doc:6.1f} min\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Breakdown: Did they see doctor before exiting?\n",
    "print(\"DOCTOR CONTACT STATUS FOR EXITED PATIENTS:\")\n",
    "print(\"-\" * 60)\n",
    "saw_doctor = exited_patients[exited_patients['Doctor Seen'].notna()]\n",
    "did_not_see_doctor = exited_patients[exited_patients['Doctor Seen'].isna()]\n",
    "\n",
    "print(f\"  Saw Doctor before exit:    {len(saw_doctor):4d} patients ({(len(saw_doctor)/len(exited_patients))*100:5.1f}%)\")\n",
    "print(f\"  Did NOT see doctor:        {len(did_not_see_doctor):4d} patients ({(len(did_not_see_doctor)/len(exited_patients))*100:5.1f}%)\")\n",
    "\n",
    "if len(saw_doctor) > 0:\n",
    "    print(f\"\\n  For those who SAW DOCTOR:\")\n",
    "    avg_doc_time = saw_doctor['Doctor_Time'].mean()\n",
    "    avg_wait_time = saw_doctor['Wait_After_Triage'].mean()\n",
    "    print(f\"    Average Doctor Time: {avg_doc_time:.1f} min\")\n",
    "    print(f\"    Average Wait After Triage: {avg_wait_time:.1f} min\")\n",
    "\n",
    "if len(did_not_see_doctor) > 0:\n",
    "    print(f\"\\n  For those who DID NOT see doctor:\")\n",
    "    avg_wait_time = did_not_see_doctor['Wait_After_Triage'].mean()\n",
    "    print(f\"    Average Wait After Triage: {avg_wait_time:.1f} min\")\n",
    "    print(f\"    (Left Without Being Seen/LWBS/Left AMA/Declined)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Create a summary visualization for EXITED patients\n",
    "print(\"Creating detailed breakdown visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Exited Patients Breakdown: Who Left the System by 6:59 AM?', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Panel 1: Total Count by Doctor Contact\n",
    "ax = axes[0, 0]\n",
    "total_exited = len(exited_patients)\n",
    "status_exited = [len(saw_doctor), len(did_not_see_doctor)]\n",
    "status_labels = [f'Saw Doctor\\n({len(saw_doctor)})', f'Did NOT See Doctor\\n({len(did_not_see_doctor)})']\n",
    "colors = ['#90EE90', '#FF6B6B']\n",
    "bars = ax.bar(status_labels, status_exited, color=colors, width=0.5)\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_title(f'Panel 1: Exited Patients - Doctor Contact\\n(Total Exited: {total_exited})', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, (bar, val) in enumerate(zip(bars, status_exited)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(val)}\\n({val/total_exited*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Panel 2: Exited by Severity\n",
    "ax = axes[0, 1]\n",
    "exit_severity_sorted = exited_patients['Triage Level'].value_counts().sort_index()\n",
    "sev_labels = [f'ESI-{int(s)}' for s in exit_severity_sorted.index]\n",
    "colors_sev = ['#FF0000', '#FFA500', '#FFD700', '#90EE90']\n",
    "bars = ax.bar(sev_labels, exit_severity_sorted.values, color=colors_sev[:len(exit_severity_sorted)])\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_title('Panel 2: Exited Patients by Severity', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Panel 3: Disposition breakdown\n",
    "ax = axes[1, 0]\n",
    "if 'Disposition' in exited_patients.columns:\n",
    "    disp_counts = exited_patients['Disposition'].value_counts()\n",
    "    disp_labels = list(disp_counts.index)\n",
    "    disp_values = list(disp_counts.values)\n",
    "    colors_disp = ['#90EE90', '#87CEEB', '#FFB6C1']\n",
    "    bars = ax.bar(disp_labels, disp_values, color=colors_disp[:len(disp_counts)])\n",
    "    ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "    ax.set_title('Panel 3: Exited Patients by Disposition', fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}\\n({height/len(exited_patients)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'Disposition data not available', ha='center', va='center', transform=ax.transAxes)\n",
    "    ax.set_title('Panel 3: Exited Patients by Disposition', fontweight='bold')\n",
    "\n",
    "# Panel 4: Wait time after triage - histogram\n",
    "ax = axes[1, 1]\n",
    "wait_times = exited_patients['Wait_After_Triage'].dropna()\n",
    "ax.hist(wait_times, bins=25, color='#87CEEB', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(wait_times.mean(), color='red', linestyle='--', linewidth=2.5, label=f'Mean: {wait_times.mean():.1f} min')\n",
    "ax.axvline(wait_times.median(), color='orange', linestyle=':', linewidth=2.5, label=f'Median: {wait_times.median():.1f} min')\n",
    "ax.set_xlabel('Wait Time After Triage (minutes)', fontweight='bold')\n",
    "ax.set_ylabel('Number of Patients', fontweight='bold')\n",
    "ax.set_title(f'Panel 4: Wait Time After Triage (Exited Patients)\\n(n={len(wait_times)})', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exited_patients_breakdown.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\u2705 Exited patients breakdown visualization saved: exited_patients_breakdown.png\\n\")\n",
    "plt.show()\n",
    "\n",
    "# Export exited patients details\n",
    "if 'Disposition' in exited_patients.columns:\n",
    "    exited_export = exited_patients[[\n",
    "        'Arrival Time', 'Exit Time', 'Triage Level', 'Doctor Seen', 'Doctor_Time', \n",
    "        'Wait_After_Triage', 'Disposition'\n",
    "    ]].copy()\n",
    "else:\n",
    "    exited_export = exited_patients[[\n",
    "        'Arrival Time', 'Exit Time', 'Triage Level', 'Doctor Seen', 'Doctor_Time', \n",
    "        'Wait_After_Triage'\n",
    "    ]].copy()\n",
    "\n",
    "exited_export.to_csv('exited_patients_detail.csv', index=False)\n",
    "print(f\"\u2705 Exported detailed exited patients data: exited_patients_detail.csv ({len(exited_export)} rows)\\n\")\n",
    "\n",
    "print(f\"{'='*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 9: PROFESSIONAL DATA EXPORT - COMPREHENSIVE ANALYSIS DATASET\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"SECTION 9: PROFESSIONAL DATA EXPORT - COMPREHENSIVE ANALYSIS DATASET\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "# Create comprehensive dataset that addresses ALL questions\n",
    "print(\"Creating comprehensive analysis dataset for all questions...\")\n",
    "\n",
    "# 1. MAIN COMPREHENSIVE TABLE - Every patient with full context\n",
    "comprehensive_dataset = []\n",
    "\n",
    "cutoff_time_value = pd.Timestamp('1970-01-01 06:59:00').time()\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # Check if patient is in system by 6:59 AM\n",
    "    if pd.isna(row['Arrival Time']):\n",
    "        continue\n",
    "    \n",
    "    arrival_time = pd.to_datetime(row['Arrival Time'])\n",
    "    arrival_hour = arrival_time.hour\n",
    "    \n",
    "    # Check if relevant to 5-6 AM surge analysis\n",
    "    is_surge_arrival = (5 <= arrival_hour <= 6)\n",
    "    is_backlog = (arrival_hour < 5)\n",
    "    is_in_system_by_659 = False\n",
    "    \n",
    "    # Check if patient was in system by 6:59 AM\n",
    "    reg_start = pd.to_datetime(row['Registration Start']) if pd.notna(row['Registration Start']) else None\n",
    "    triage_start = pd.to_datetime(row['Triage Start']) if pd.notna(row['Triage Start']) else None\n",
    "    doctor_seen = pd.to_datetime(row['Doctor Seen']) if pd.notna(row['Doctor Seen']) else None\n",
    "    exit_time = pd.to_datetime(row['Exit Time']) if pd.notna(row['Exit Time']) else None\n",
    "    \n",
    "    # Determine if in system by 6:59 AM\n",
    "    if arrival_time.time() <= cutoff_time_value:\n",
    "        is_in_system_by_659 = True\n",
    "    \n",
    "    if not is_in_system_by_659:\n",
    "        continue\n",
    "    \n",
    "    # Determine arrival cohort\n",
    "    if is_surge_arrival:\n",
    "        arrival_cohort = \"5-6 AM Surge\"\n",
    "    elif is_backlog:\n",
    "        arrival_cohort = \"Before 5 AM Backlog\"\n",
    "    else:\n",
    "        arrival_cohort = \"After 6 AM\"\n",
    "        continue  # Skip patients arriving after 6 AM\n",
    "    \n",
    "    # Determine status at 6:59 AM\n",
    "    if exit_time and exit_time.time() <= cutoff_time_value:\n",
    "        status_659 = \"EXITED\"\n",
    "        exit_reason = row.get('Disposition', 'Unknown') if pd.notna(row.get('Disposition', None)) else \"Unknown\"\n",
    "    elif doctor_seen and doctor_seen.time() <= cutoff_time_value:\n",
    "        if exit_time is None or exit_time.time() > cutoff_time_value:\n",
    "            status_659 = \"WITH_DOCTOR\"\n",
    "            exit_reason = \"Still with Doctor\"\n",
    "        else:\n",
    "            status_659 = \"EXITED\"\n",
    "            exit_reason = row.get('Disposition', 'Unknown') if pd.notna(row.get('Disposition', None)) else \"Unknown\"\n",
    "    elif triage_start and triage_start.time() <= cutoff_time_value:\n",
    "        if doctor_seen is None or doctor_seen.time() > cutoff_time_value:\n",
    "            status_659 = \"WAITING_FOR_DOCTOR\"\n",
    "            exit_reason = \"Awaiting Doctor\"\n",
    "        else:\n",
    "            status_659 = \"WITH_DOCTOR\"\n",
    "            exit_reason = \"With Doctor\"\n",
    "    elif reg_start and reg_start.time() <= cutoff_time_value:\n",
    "        status_659 = \"IN_TRIAGE\"\n",
    "        exit_reason = \"In Triage\"\n",
    "    else:\n",
    "        status_659 = \"IN_REGISTRATION\"\n",
    "        exit_reason = \"In Registration\"\n",
    "    \n",
    "    # Calculate wait times\n",
    "    reg_time = (pd.to_datetime(row['Registration End']) - pd.to_datetime(row['Registration Start'])).total_seconds() / 60 if pd.notna(row['Registration End']) and pd.notna(row['Registration Start']) else None\n",
    "    triage_time = (pd.to_datetime(row['Triage End']) - pd.to_datetime(row['Triage Start'])).total_seconds() / 60 if pd.notna(row['Triage End']) and pd.notna(row['Triage Start']) else None\n",
    "    wait_after_triage = (doctor_seen - pd.to_datetime(row['Triage End'])).total_seconds() / 60 if doctor_seen and pd.notna(row['Triage End']) else None\n",
    "    doctor_time = (exit_time - doctor_seen).total_seconds() / 60 if exit_time and doctor_seen else None\n",
    "    total_los = (exit_time - arrival_time).total_seconds() / 60 if exit_time else None\n",
    "    \n",
    "    comprehensive_dataset.append({\n",
    "        'Patient_ID': idx,\n",
    "        'Arrival_Date': arrival_time.date(),\n",
    "        'Arrival_Time': arrival_time.strftime('%H:%M:%S'),\n",
    "        'Arrival_Hour': arrival_hour,\n",
    "        'Arrival_Cohort': arrival_cohort,\n",
    "        'Triage_Level': row.get('Triage Level', 'Unknown'),\n",
    "        'Registration_Start': pd.to_datetime(row['Registration Start']).strftime('%H:%M:%S') if pd.notna(row['Registration Start']) else None,\n",
    "        'Registration_Duration_Min': round(reg_time, 1) if reg_time else None,\n",
    "        'Triage_Start': pd.to_datetime(row['Triage Start']).strftime('%H:%M:%S') if pd.notna(row['Triage Start']) else None,\n",
    "        'Triage_Duration_Min': round(triage_time, 1) if triage_time else None,\n",
    "        'Doctor_Seen_Time': doctor_seen.strftime('%H:%M:%S') if doctor_seen else None,\n",
    "        'Wait_After_Triage_Min': round(wait_after_triage, 1) if wait_after_triage else None,\n",
    "        'Doctor_Duration_Min': round(doctor_time, 1) if doctor_time else None,\n",
    "        'Exit_Time': exit_time.strftime('%H:%M:%S') if exit_time else None,\n",
    "        'Total_LOS_Min': round(total_los, 1) if total_los else None,\n",
    "        'Status_at_659_AM': status_659,\n",
    "        'Exit_Disposition': exit_reason,\n",
    "        'Doctors_On_Duty': row.get('Doctors On Duty', None),\n",
    "        'Nurses_On_Duty': row.get('Nurses On Duty', None),\n",
    "        'Specialists_On_Call': row.get('Specialists On Call', None),\n",
    "        'Fast_Track_Beds': row.get('Fast Tracks Beds on shift', None),\n",
    "    })\n",
    "\n",
    "comprehensive_df = pd.DataFrame(comprehensive_dataset)\n",
    "\n",
    "print(f\"\u2705 Generated comprehensive dataset: {len(comprehensive_df)} patients\")\n",
    "print(f\"\\nDataset includes all columns needed for analysis:\")\n",
    "print(f\"  \u2022 Timeline tracking (arrival through exit)\")\n",
    "print(f\"  \u2022 Wait time calculations (registration, triage, doctor)\")\n",
    "print(f\"  \u2022 Severity classification (ESI levels)\")\n",
    "print(f\"  \u2022 Status at snapshot time (6:59 AM)\")\n",
    "print(f\"  \u2022 Exit disposition (where they went)\")\n",
    "print(f\"  \u2022 Staffing levels (doctors, nurses, specialists)\")\n",
    "\n",
    "# Export main comprehensive CSV\n",
    "comprehensive_df.to_csv('COMPREHENSIVE_ANALYSIS_DATASET.csv', index=False)\n",
    "print(f\"\\n\u2705 Exported: COMPREHENSIVE_ANALYSIS_DATASET.csv ({len(comprehensive_df)} rows)\")\n",
    "\n",
    "# 2. SUMMARY STATISTICS BY QUESTION\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(f\"SUMMARY STATISTICS - ADDRESSING ALL QUESTIONS\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "summary_questions = []\n",
    "\n",
    "# Q1: Surge Analysis\n",
    "surge_data = comprehensive_df[comprehensive_df['Arrival_Cohort'] == '5-6 AM Surge']\n",
    "backlog_data = comprehensive_df[comprehensive_df['Arrival_Cohort'] == 'Before 5 AM Backlog']\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q1: Why is there a 5-7 AM surge?',\n",
    "    'Metric': 'Surge Arrivals (5-6 AM)',\n",
    "    'Value': len(surge_data),\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{len(surge_data)} patients arrived during surge window'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q1: Why is there a 5-7 AM surge?',\n",
    "    'Metric': 'Backlog Patients (before 5 AM)',\n",
    "    'Value': len(backlog_data),\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{len(backlog_data)} patients already in system from overnight'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q1: Why is there a 5-7 AM surge?',\n",
    "    'Metric': 'Total System Load by 6:59 AM',\n",
    "    'Value': len(comprehensive_df),\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{len(comprehensive_df)} total patients in ED by 6:59 AM'\n",
    "})\n",
    "\n",
    "# Q2: Bottleneck Analysis\n",
    "avg_doctor_time = comprehensive_df[comprehensive_df['Doctor_Duration_Min'].notna()]['Doctor_Duration_Min'].mean()\n",
    "avg_reg_time = comprehensive_df[comprehensive_df['Registration_Duration_Min'].notna()]['Registration_Duration_Min'].mean()\n",
    "avg_triage_time = comprehensive_df[comprehensive_df['Triage_Duration_Min'].notna()]['Triage_Duration_Min'].mean()\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q2: What is the bottleneck?',\n",
    "    'Metric': 'Average Doctor Time',\n",
    "    'Value': round(avg_doctor_time, 1),\n",
    "    'Unit': 'minutes',\n",
    "    'Finding': f'Doctor processing takes {round(avg_doctor_time, 1)} min (PRIMARY BOTTLENECK)'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q2: What is the bottleneck?',\n",
    "    'Metric': 'Average Registration Time',\n",
    "    'Value': round(avg_reg_time, 1),\n",
    "    'Unit': 'minutes',\n",
    "    'Finding': f'Registration takes {round(avg_reg_time, 1)} min (efficient)'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q2: What is the bottleneck?',\n",
    "    'Metric': 'Average Triage Time',\n",
    "    'Value': round(avg_triage_time, 1),\n",
    "    'Unit': 'minutes',\n",
    "    'Finding': f'Triage takes {round(avg_triage_time, 1)} min (efficient)'\n",
    "})\n",
    "\n",
    "waiting_count = len(comprehensive_df[comprehensive_df['Status_at_659_AM'] == 'WAITING_FOR_DOCTOR'])\n",
    "with_doctor_count = len(comprehensive_df[comprehensive_df['Status_at_659_AM'] == 'WITH_DOCTOR'])\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q2: What is the bottleneck?',\n",
    "    'Metric': 'Patients Waiting for Doctor',\n",
    "    'Value': waiting_count,\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{waiting_count} patients in queue waiting for doctor'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q2: What is the bottleneck?',\n",
    "    'Metric': 'Patients With Doctor',\n",
    "    'Value': with_doctor_count,\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{with_doctor_count} patients currently with doctor (avg {round(avg_doctor_time, 1)} min each)'\n",
    "})\n",
    "\n",
    "# Q3: Severity Analysis\n",
    "for esi in sorted(comprehensive_df['Triage_Level'].dropna().unique()):\n",
    "    esi_data = comprehensive_df[comprehensive_df['Triage_Level'] == esi]\n",
    "    esi_avg_wait = esi_data['Wait_After_Triage_Min'].mean()\n",
    "    esi_count = len(esi_data)\n",
    "    esi_pct = (esi_count / len(comprehensive_df)) * 100\n",
    "    \n",
    "    summary_questions.append({\n",
    "        'Question': 'Q3: Is it severity driving delays?',\n",
    "        'Metric': f'ESI-{int(esi)} patients',\n",
    "        'Value': esi_count,\n",
    "        'Unit': 'patients',\n",
    "        'Finding': f'ESI-{int(esi)}: {esi_count} patients ({esi_pct:.1f}%), avg wait {esi_avg_wait:.1f} min'\n",
    "    })\n",
    "\n",
    "# Q4: Backlog Impact\n",
    "backlog_with_doctor = len(backlog_data[backlog_data['Status_at_659_AM'].isin(['WITH_DOCTOR', 'EXITED'])])\n",
    "backlog_pct_doctor = (backlog_with_doctor / len(backlog_data)) * 100 if len(backlog_data) > 0 else 0\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q4: What is backlog impact?',\n",
    "    'Metric': 'Backlog Patients Still Using Doctor Time',\n",
    "    'Value': backlog_with_doctor,\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{backlog_with_doctor} ({backlog_pct_doctor:.1f}%) still with doctor or exiting'\n",
    "})\n",
    "\n",
    "# Q5: System Snapshot\n",
    "exited_count = len(comprehensive_df[comprehensive_df['Status_at_659_AM'] == 'EXITED'])\n",
    "exited_pct = (exited_count / len(comprehensive_df)) * 100\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q5: Where is every patient?',\n",
    "    'Metric': 'Exited by 6:59 AM',\n",
    "    'Value': exited_count,\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{exited_count} ({exited_pct:.1f}%) successfully exited system'\n",
    "})\n",
    "\n",
    "summary_questions.append({\n",
    "    'Question': 'Q5: Where is every patient?',\n",
    "    'Metric': 'Still in System',\n",
    "    'Value': len(comprehensive_df) - exited_count,\n",
    "    'Unit': 'patients',\n",
    "    'Finding': f'{len(comprehensive_df) - exited_count} ({100-exited_pct:.1f}%) still awaiting or in process'\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_questions)\n",
    "summary_df.to_csv('ANALYSIS_QUESTIONS_SUMMARY.csv', index=False)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\u2705 Exported: ANALYSIS_QUESTIONS_SUMMARY.csv ({len(summary_df)} rows)\")\n",
    "\n",
    "# 3. DETAILED BREAKDOWN BY ARRIVAL COHORT \u00d7 SEVERITY \u00d7 STATUS\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(f\"DETAILED BREAKDOWN TABLE - COHORT \u00d7 SEVERITY \u00d7 STATUS\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "breakdown_dataset = []\n",
    "\n",
    "for cohort in ['5-6 AM Surge', 'Before 5 AM Backlog']:\n",
    "    cohort_data = comprehensive_df[comprehensive_df['Arrival_Cohort'] == cohort]\n",
    "    \n",
    "    for severity in sorted(cohort_data['Triage_Level'].dropna().unique()):\n",
    "        severity_data = cohort_data[cohort_data['Triage_Level'] == severity]\n",
    "        \n",
    "        for status in ['IN_REGISTRATION', 'IN_TRIAGE', 'WAITING_FOR_DOCTOR', 'WITH_DOCTOR', 'EXITED']:\n",
    "            status_data = severity_data[severity_data['Status_at_659_AM'] == status]\n",
    "            \n",
    "            if len(status_data) > 0:\n",
    "                breakdown_dataset.append({\n",
    "                    'Arrival_Cohort': cohort,\n",
    "                    'Severity_Level': f'ESI-{int(severity)}',\n",
    "                    'Status_at_659': status,\n",
    "                    'Patient_Count': len(status_data),\n",
    "                    'Avg_Wait_After_Triage_Min': round(status_data['Wait_After_Triage_Min'].mean(), 1),\n",
    "                    'Max_Wait_After_Triage_Min': round(status_data['Wait_After_Triage_Min'].max(), 1),\n",
    "                    'Avg_Doctor_Time_Min': round(status_data['Doctor_Duration_Min'].mean(), 1),\n",
    "                    'Avg_Total_LOS_Min': round(status_data['Total_LOS_Min'].mean(), 1),\n",
    "                    'Avg_Doctors_On_Duty': round(status_data['Doctors_On_Duty'].mean(), 2) if status_data['Doctors_On_Duty'].notna().any() else None,\n",
    "                })\n",
    "\n",
    "breakdown_df = pd.DataFrame(breakdown_dataset)\n",
    "breakdown_df.to_csv('DETAILED_BREAKDOWN_BY_COHORT_SEVERITY_STATUS.csv', index=False)\n",
    "print(breakdown_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\u2705 Exported: DETAILED_BREAKDOWN_BY_COHORT_SEVERITY_STATUS.csv ({len(breakdown_df)} rows)\")\n",
    "\n",
    "# 4. DISPOSITION ANALYSIS\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(f\"DISPOSITION ANALYSIS - WHERE PATIENTS EXITED\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "disposition_dataset = []\n",
    "\n",
    "exited_data = comprehensive_df[comprehensive_df['Status_at_659_AM'] == 'EXITED']\n",
    "\n",
    "for disposition in exited_data['Exit_Disposition'].unique():\n",
    "    disp_data = exited_data[exited_data['Exit_Disposition'] == disposition]\n",
    "    \n",
    "    for severity in sorted(disp_data['Triage_Level'].dropna().unique()):\n",
    "        sev_data = disp_data[disp_data['Triage_Level'] == severity]\n",
    "        \n",
    "        disposition_dataset.append({\n",
    "            'Exit_Disposition': disposition,\n",
    "            'Severity_Level': f'ESI-{int(severity)}',\n",
    "            'Patient_Count': len(sev_data),\n",
    "            'Percentage_of_Disposition': round((len(sev_data) / len(disp_data)) * 100, 1),\n",
    "            'Avg_Wait_After_Triage_Min': round(sev_data['Wait_After_Triage_Min'].mean(), 1),\n",
    "            'Avg_Doctor_Time_Min': round(sev_data['Doctor_Duration_Min'].mean(), 1),\n",
    "            'Avg_Total_LOS_Min': round(sev_data['Total_LOS_Min'].mean(), 1),\n",
    "        })\n",
    "\n",
    "disposition_df = pd.DataFrame(disposition_dataset).sort_values('Patient_Count', ascending=False)\n",
    "disposition_df.to_csv('DISPOSITION_ANALYSIS.csv', index=False)\n",
    "print(disposition_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\u2705 Exported: DISPOSITION_ANALYSIS.csv ({len(disposition_df)} rows)\")\n",
    "\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(f\"ALL PROFESSIONAL DATASETS GENERATED\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "print(\"\ud83d\udcca FILES CREATED:\")\n",
    "print(f\"  1. COMPREHENSIVE_ANALYSIS_DATASET.csv ({len(comprehensive_df)} rows)\")\n",
    "print(f\"     \u2514\u2500 Every patient with full timeline and metrics\")\n",
    "print(f\"  2. ANALYSIS_QUESTIONS_SUMMARY.csv ({len(summary_df)} rows)\")\n",
    "print(f\"     \u2514\u2500 Answers to all 5 questions with findings\")\n",
    "print(f\"  3. DETAILED_BREAKDOWN_BY_COHORT_SEVERITY_STATUS.csv ({len(breakdown_df)} rows)\")\n",
    "print(f\"     \u2514\u2500 Detailed cross-tabulation by arrival, severity, status\")\n",
    "print(f\"  4. DISPOSITION_ANALYSIS.csv ({len(disposition_df)} rows)\")\n",
    "print(f\"     \u2514\u2500 Where patients exited (admitted, discharged, transferred)\")\n",
    "\n",
    "print(f\"\\n{'='*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9fc7c",
   "metadata": {},
   "source": [
    "## Section 5: Resource Utilization & Doctor Idle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze staffing during 5-6 AM\n",
    "print(f\"\\n\ud83d\udc68\u200d\u2695\ufe0f  STAFFING & RESOURCE ANALYSIS (5-6 AM)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "staffing_5_6am = early_arrivals[['Date', 'Nurses On Duty', 'Doctors On Duty', 'Specialists On Call', 'Fast Tracks Beds on shift']].copy()\n",
    "staffing_5_6am = staffing_5_6am.groupby('Date').first().reset_index()\n",
    "\n",
    "print(f\"AVERAGE STAFFING LEVELS:\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Nurses on duty: {staffing_5_6am['Nurses On Duty'].mean():.1f}\")\n",
    "print(f\"  Doctors on duty: {staffing_5_6am['Doctors On Duty'].mean():.1f}\")\n",
    "print(f\"  Specialists on call: {staffing_5_6am['Specialists On Call'].mean():.1f}\")\n",
    "print(f\"  Fast track beds available: {staffing_5_6am['Fast Tracks Beds on shift'].mean():.1f}\")\n",
    "\n",
    "# Calculate patient-to-doctor ratio\n",
    "patients_per_doctor = arrivals_per_day.mean() / staffing_5_6am['Doctors On Duty'].mean()\n",
    "print(f\"\\n  Patient-to-Doctor Ratio: {patients_per_doctor:.2f} patients per doctor\")\n",
    "\n",
    "# Bed capacity analysis\n",
    "print(f\"\\n\ud83d\udecf\ufe0f  BED CAPACITY ANALYSIS:\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Regular beds: 70\")\n",
    "print(f\"  Fast track beds available: {staffing_5_6am['Fast Tracks Beds on shift'].mean():.1f}\")\n",
    "print(f\"  Total effective capacity: ~{70 + staffing_5_6am['Fast Tracks Beds on shift'].mean():.1f} beds\")\n",
    "print(f\"\\n  Arrivals per day (5-6 AM): {arrivals_per_day.mean():.2f}\")\n",
    "print(f\"  Average LOS (hours): {early_arrivals['LOS_hours'].mean():.2f}\")\n",
    "print(f\"  Estimated patients in system: {arrivals_per_day.mean() * early_arrivals['LOS_hours'].mean():.1f}\")\n",
    "\n",
    "# Doctor wait time analysis\n",
    "print(f\"\\n\u23f1\ufe0f  DOCTOR AVAILABILITY ANALYSIS:\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"  Avg wait after triage: {early_arrivals['Wait_After_Triage'].mean():.1f} minutes\")\n",
    "print(f\"  Median wait after triage: {early_arrivals['Wait_After_Triage'].median():.1f} minutes\")\n",
    "print(f\"  Max wait after triage: {early_arrivals['Wait_After_Triage'].max():.1f} minutes\")\n",
    "\n",
    "# Cases with long waits (>30 min after triage)\n",
    "long_waits = len(early_arrivals[early_arrivals['Wait_After_Triage'] > 30])\n",
    "print(f\"  Cases with wait > 30 min: {long_waits} ({100*long_waits/len(early_arrivals):.1f}%)\")\n",
    "print(f\"  Cases with wait > 60 min: {len(early_arrivals[early_arrivals['Wait_After_Triage'] > 60])} ({100*len(early_arrivals[early_arrivals['Wait_After_Triage'] > 60])/len(early_arrivals):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6325f",
   "metadata": {},
   "source": [
    "## Section 6: Visualization - Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8258641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Arrivals vs Exits Flow Comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "dates_common = sorted(set(arrivals_per_day.index) & set(exits_per_day.index))\n",
    "arrivals_aligned = [arrivals_per_day.get(d, 0) for d in dates_common]\n",
    "exits_aligned = [exits_per_day.get(d, 0) for d in dates_common]\n",
    "\n",
    "x = np.arange(len(dates_common))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, arrivals_aligned, width, label='Arrivals (5-6 AM)', color='#FF6B6B', alpha=0.8, edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, exits_aligned, width, label='Exits (5-6 AM)', color='#4ECDC4', alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height, f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Patient Flow: Arrivals vs Exits During 5-6 AM\\n(Divergence indicates bottleneck)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([str(d) for d in dates_common], rotation=45, ha='right', fontsize=9)\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/arrivals_vs_exits.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Arrivals vs Exits chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a72a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Process Time Breakdown (Waterfall style)\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "process_times = [p['Avg_Time_Min'] for p in process_summary]\n",
    "process_names = [p['Process'] for p in process_summary]\n",
    "colors_proc = ['#FF6B6B', '#4ECDC4', '#FFE66D', '#95E1D3']\n",
    "\n",
    "bars = ax.barh(process_names, process_times, color=colors_proc, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, process_times)):\n",
    "    ax.text(val + 1, bar.get_y() + bar.get_height()/2, f'{val:.1f} min', \n",
    "            va='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Average Time (minutes)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Process Time Breakdown: Where Does Time Go?\\n(5-6 AM Arrivals)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.set_xlim(0, max(process_times) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/process_breakdown.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Process breakdown chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Length of Stay Distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "ax.hist(early_arrivals['LOS_minutes'], bins=30, color='#45B7D1', edgecolor='black', alpha=0.7, linewidth=1.5)\n",
    "ax.axvline(early_arrivals['LOS_minutes'].mean(), color='red', linestyle='--', linewidth=2.5, label=f'Mean: {early_arrivals[\"LOS_minutes\"].mean():.0f} min')\n",
    "ax.axvline(early_arrivals['LOS_minutes'].median(), color='green', linestyle='--', linewidth=2.5, label=f'Median: {early_arrivals[\"LOS_minutes\"].median():.0f} min')\n",
    "\n",
    "ax.set_xlabel('Length of Stay (minutes)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Length of Stay Distribution: How Long Do Patients Stay?\\n(5-6 AM Arrivals)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/length_of_stay_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Length of stay distribution chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Staffing vs Patient Load Over Time\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot 1: Daily arrival count (left y-axis)\n",
    "dates = early_arrivals.groupby('Date').size().index\n",
    "arrivals = early_arrivals.groupby('Date').size().values\n",
    "ax1.bar(dates, arrivals, color='#FF6B6B', alpha=0.6, label='Daily Arrivals (5-6 AM)', width=0.6)\n",
    "ax1.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Arrivals', fontsize=12, fontweight='bold', color='#FF6B6B')\n",
    "ax1.tick_params(axis='y', labelcolor='#FF6B6B')\n",
    "ax1.set_xticklabels(dates, rotation=45, ha='right')\n",
    "\n",
    "# Plot 2: Average staffing levels (right y-axis)\n",
    "avg_nurses = early_arrivals.groupby('Date')['Nurses on Duty'].mean().values\n",
    "avg_doctors = early_arrivals.groupby('Date')['Doctors on Duty'].mean().values\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(dates, avg_nurses, 'o-', color='#4ECDC4', linewidth=3, markersize=8, label='Avg Nurses', alpha=0.8)\n",
    "ax2.plot(dates, avg_doctors, 's-', color='#FFE66D', linewidth=3, markersize=8, label='Avg Doctors', alpha=0.8)\n",
    "ax2.set_ylabel('Average Staff On Duty', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax1.set_title('Patient Arrivals vs Staffing Levels: Is There a Mismatch?\\n(5-6 AM Window)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Combined legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/staffing_vs_load.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Staffing vs patient load chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Cumulative Flow Analysis for Top 3 Peak Days\n",
    "top_3_dates = early_arrivals.groupby('Date').size().nlargest(3).index\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, date in enumerate(top_3_dates):\n",
    "    day_data = early_arrivals[early_arrivals['Date'] == date].copy()\n",
    "    day_data = day_data.sort_values('Arrival Time')\n",
    "    \n",
    "    # Calculate cumulative arrivals and exits\n",
    "    day_data['Cumulative_Arrivals'] = range(1, len(day_data) + 1)\n",
    "    day_data['Cumulative_Exits'] = day_data['Exit Time'].notna().cumsum()\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    ax.plot(day_data['Arrival Time'], day_data['Cumulative_Arrivals'], 'o-', \n",
    "            color='#FF6B6B', linewidth=2.5, markersize=6, label='Cumulative Arrivals', alpha=0.8)\n",
    "    ax.plot(day_data['Exit Time'].dropna(), day_data.loc[day_data['Exit Time'].notna(), 'Cumulative_Exits'], \n",
    "            's-', color='#51CF66', linewidth=2.5, markersize=6, label='Cumulative Exits', alpha=0.8)\n",
    "    \n",
    "    # Highlight the divergence\n",
    "    divergence = len(day_data) - day_data['Cumulative_Exits'].iloc[-1]\n",
    "    ax.fill_between(range(len(day_data)), 0, 50, alpha=0.1, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Time', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Cumulative Count', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{date.date()}\\n({len(day_data)} arrivals, {divergence} patients remaining)', \n",
    "                fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Cumulative Flow for Top 3 Peak Days: The Growing Patient Queue\\n(5-6 AM Window)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/mukeshravichandran/Datathon/5to7_Surge/cumulative_flow_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2713 Cumulative flow analysis chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: Root Cause Analysis - WHERE IS THE BOTTLENECK?\n",
    "print(\"=\"*80)\n",
    "print(\"ROOT CAUSE ANALYSIS: IDENTIFYING THE BOTTLENECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Doctor Availability Analysis\n",
    "print(\"\\n1. DOCTOR AVAILABILITY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "avg_doctor_on_duty = early_arrivals['Doctors on Duty'].mean()\n",
    "max_arrivals_day = early_arrivals.groupby('Date').size().max()\n",
    "min_arrivals_day = early_arrivals.groupby('Date').size().min()\n",
    "avg_arrivals_day = early_arrivals.groupby('Date').size().mean()\n",
    "patients_per_doctor_avg = avg_arrivals_day / avg_doctor_on_duty\n",
    "\n",
    "print(f\"Average Doctors on Duty during 5-6 AM:    {avg_doctor_on_duty:.1f} doctors\")\n",
    "print(f\"Average Daily Arrivals:                    {avg_arrivals_day:.0f} patients/day\")\n",
    "print(f\"Peak Day Arrivals:                         {max_arrivals_day:.0f} patients\")\n",
    "print(f\"Patients per Doctor (avg):                 {patients_per_doctor_avg:.1f} patients/doctor\")\n",
    "print(f\"\\nCritical finding: On peak days, ratio reaches {max_arrivals_day/avg_doctor_on_duty:.1f} patients/doctor\")\n",
    "\n",
    "# Analyze doctor availability vs wait times\n",
    "doctor_availability_impact = early_arrivals.groupby('Doctors on Duty').agg({\n",
    "    'Wait_After_Triage_minutes': ['mean', 'max', 'count']\n",
    "}).round(1)\n",
    "print(f\"\\nWait times by doctor availability:\")\n",
    "print(doctor_availability_impact)\n",
    "\n",
    "# 2. Bed Capacity Analysis\n",
    "print(\"\\n\\n2. BED CAPACITY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "avg_beds = early_arrivals['Fast Track Beds on Shift'].mean()\n",
    "patients_in_system = early_arrivals.groupby('Date').apply(lambda x: (x['Exit Time'].isna()).sum()).mean()\n",
    "bed_utilization = (patients_in_system / avg_beds * 100) if avg_beds > 0 else 0\n",
    "\n",
    "print(f\"Average Fast Track Beds on Shift:          {avg_beds:.1f} beds\")\n",
    "print(f\"Average Patients in System (5-6 AM):       {patients_in_system:.0f} patients\")\n",
    "print(f\"Bed Utilization Rate:                      {bed_utilization:.1f}%\")\n",
    "\n",
    "if bed_utilization > 80:\n",
    "    print(f\"\u26a0\ufe0f  ALERT: Bed utilization at {bed_utilization:.1f}% - POTENTIAL BED CAPACITY BOTTLENECK\")\n",
    "elif bed_utilization > 60:\n",
    "    print(f\"\u26a0\ufe0f  Beds are moderately utilized at {bed_utilization:.1f}%\")\n",
    "else:\n",
    "    print(f\"\u2713 Beds are not fully utilized at {bed_utilization:.1f}%\")\n",
    "\n",
    "# 3. Process Delay Analysis\n",
    "print(\"\\n\\n3. PROCESS DELAY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "process_times = {\n",
    "    'Registration': early_arrivals['Registration_minutes'].mean(),\n",
    "    'Triage': early_arrivals['Triage_minutes'].mean(),\n",
    "    'Wait After Triage': early_arrivals['Wait_After_Triage_minutes'].mean(),\n",
    "    'Doctor/Treatment': early_arrivals['Doctor_Treatment_minutes'].mean()\n",
    "}\n",
    "\n",
    "total_process_time = sum(process_times.values())\n",
    "print(f\"Total Average Length of Stay:              {total_process_time:.1f} minutes\")\n",
    "print(f\"\\nBreakdown by process step:\")\n",
    "for step, time in sorted(process_times.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = (time / total_process_time) * 100\n",
    "    print(f\"  {step:.<30} {time:>6.1f} min ({pct:>5.1f}%)\")\n",
    "\n",
    "# Identify the slowest step\n",
    "slowest_step = max(process_times.items(), key=lambda x: x[1])\n",
    "print(f\"\\n\ud83d\udd34 SLOWEST STEP: {slowest_step[0]} ({slowest_step[1]:.1f} minutes)\")\n",
    "\n",
    "# 4. Overall Bottleneck Assessment\n",
    "print(\"\\n\\n4. BOTTLENECK SEVERITY ASSESSMENT\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "divergence_rate = flow_divergence['Divergence'].mean()\n",
    "total_arrivals = len(early_arrivals)\n",
    "total_exits = early_arrivals['Exit Time'].notna().sum()\n",
    "patients_stuck_pct = ((total_arrivals - total_exits) / total_arrivals) * 100\n",
    "\n",
    "print(f\"Total Patients Arriving (5-6 AM):         {total_arrivals} patients\")\n",
    "print(f\"Patients Who Exited by end of period:    {total_exits} patients\")\n",
    "print(f\"Patients Still in System:                 {total_arrivals - total_exits} patients\")\n",
    "print(f\"Percentage Stuck:                         {patients_stuck_pct:.1f}%\")\n",
    "print(f\"Average Divergence per Day:               {divergence_rate:.1f} patients/day\")\n",
    "\n",
    "# 5. Primary Bottleneck Conclusion\n",
    "print(\"\\n\\n5. PRIMARY BOTTLENECK IDENTIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Score each potential bottleneck\n",
    "doctor_score = patients_per_doctor_avg / 2  # Normalize score\n",
    "bed_score = bed_utilization / 50  # Normalize score\n",
    "process_score = (slowest_step[1] / 30) * 100  # Normalize score (assuming 30 min is baseline)\n",
    "\n",
    "print(f\"Doctor Availability Score:                 {doctor_score:.1f}/10\")\n",
    "print(f\"Bed Capacity Score:                        {bed_score:.1f}/10\")\n",
    "print(f\"Process Delay Score:                       {process_score:.1f}/10\")\n",
    "\n",
    "scores = {\n",
    "    'Doctor Availability': doctor_score,\n",
    "    'Bed Capacity': bed_score,\n",
    "    'Process Delays': process_score\n",
    "}\n",
    "\n",
    "primary_bottleneck = max(scores, key=scores.get)\n",
    "print(f\"\\n\ud83c\udfaf PRIMARY BOTTLENECK: {primary_bottleneck}\")\n",
    "print(f\"   Severity Score: {scores[primary_bottleneck]:.1f}/10\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\\n6. STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if primary_bottleneck == 'Doctor Availability':\n",
    "    print(\"\u2713 Increase doctor availability during 5-6 AM peak hours\")\n",
    "    print(f\"\u2713 Current ratio ({patients_per_doctor_avg:.1f} patients/doctor) needs reduction\")\n",
    "    print(f\"\u2713 Consider scheduling additional physicians during this window\")\n",
    "    \n",
    "elif primary_bottleneck == 'Bed Capacity':\n",
    "    print(\"\u2713 Expand Fast Track bed capacity during 5-6 AM surge\")\n",
    "    print(f\"\u2713 Current bed count ({avg_beds:.0f} beds) may be insufficient\")\n",
    "    print(\"\u2713 Consider dynamic bed reallocation from other units\")\n",
    "    \n",
    "else:  # Process Delays\n",
    "    print(f\"\u2713 Streamline {slowest_step[0]} process (currently {slowest_step[1]:.0f} minutes avg)\")\n",
    "    print(\"\u2713 Review {slowest_step[0]} procedures for efficiency improvements\")\n",
    "    print(\"\u2713 Consider pre-registration or parallel processing workflows\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Export Detailed Flow Metrics for Further Analysis\n",
    "print(\"\\n\\nExporting detailed flow metrics to CSV...\")\n",
    "\n",
    "# Create comprehensive flow metrics table\n",
    "flow_export = early_arrivals.groupby('Date').agg({\n",
    "    'Arrival Time': 'count',  # Daily arrivals\n",
    "    'Exit Time': lambda x: x.notna().sum(),  # Daily exits\n",
    "    'LOS_minutes': ['mean', 'max'],  # Length of stay stats\n",
    "    'Registration_minutes': 'mean',\n",
    "    'Triage_minutes': 'mean',\n",
    "    'Wait_After_Triage_minutes': 'mean',\n",
    "    'Doctor_Treatment_minutes': 'mean',\n",
    "    'Nurses on Duty': 'mean',\n",
    "    'Doctors on Duty': 'mean',\n",
    "    'Specialists on Call': 'mean'\n",
    "}).round(1)\n",
    "\n",
    "# Flatten column names\n",
    "flow_export.columns = ['_'.join(col).strip() for col in flow_export.columns.values]\n",
    "flow_export.columns = [\n",
    "    'Daily_Arrivals',\n",
    "    'Daily_Exits',\n",
    "    'Avg_LOS_minutes',\n",
    "    'Max_LOS_minutes',\n",
    "    'Avg_Registration_Time',\n",
    "    'Avg_Triage_Time',\n",
    "    'Avg_Wait_After_Triage',\n",
    "    'Avg_Doctor_Treatment_Time',\n",
    "    'Avg_Nurses_On_Duty',\n",
    "    'Avg_Doctors_On_Duty',\n",
    "    'Avg_Specialists_On_Call'\n",
    "]\n",
    "\n",
    "# Calculate divergence and ratios\n",
    "flow_export['Divergence'] = flow_export['Daily_Arrivals'] - flow_export['Daily_Exits']\n",
    "flow_export['Patients_Per_Doctor'] = (flow_export['Daily_Arrivals'] / flow_export['Avg_Doctors_On_Duty']).round(2)\n",
    "flow_export['Exit_Rate_Pct'] = (flow_export['Daily_Exits'] / flow_export['Daily_Arrivals'] * 100).round(1)\n",
    "\n",
    "# Save to CSV\n",
    "flow_export.to_csv('/Users/mukeshravichandran/Datathon/5to7_Surge/detailed_flow_metrics.csv')\n",
    "print(f\"\u2713 Exported to: detailed_flow_metrics.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nFlow Metrics Summary (Top 5 days by arrivals):\")\n",
    "print(flow_export.nlargest(5, 'Daily_Arrivals')[['Daily_Arrivals', 'Daily_Exits', 'Divergence', 'Avg_LOS_minutes', 'Avg_Doctors_On_Duty', 'Patients_Per_Doctor']])\n",
    "\n",
    "# Create a summary statistics file\n",
    "summary_stats = {\n",
    "    'Metric': [\n",
    "        'Total Patients (5-6 AM window)',\n",
    "        'Unique Days Analyzed',\n",
    "        'Average Daily Arrivals',\n",
    "        'Peak Day Arrivals',\n",
    "        'Average Daily Exits',\n",
    "        'Average Daily Divergence',\n",
    "        'Percentage Stuck in System',\n",
    "        'Average Length of Stay (minutes)',\n",
    "        'Average Doctors on Duty',\n",
    "        'Average Patients per Doctor',\n",
    "        'Average Wait After Triage (minutes)',\n",
    "        'Patients with >30 min wait',\n",
    "        'Patients with >60 min wait',\n",
    "        'Primary Bottleneck Identified'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(early_arrivals),\n",
    "        early_arrivals['Date'].nunique(),\n",
    "        f\"{early_arrivals.groupby('Date').size().mean():.0f}\",\n",
    "        f\"{early_arrivals.groupby('Date').size().max()}\",\n",
    "        f\"{early_arrivals['Exit Time'].notna().sum():.0f}\",\n",
    "        f\"{flow_divergence['Divergence'].mean():.0f}\",\n",
    "        f\"{patients_stuck_pct:.1f}%\",\n",
    "        f\"{early_arrivals['LOS_minutes'].mean():.0f}\",\n",
    "        f\"{early_arrivals['Doctors on Duty'].mean():.1f}\",\n",
    "        f\"{patients_per_doctor_avg:.1f}\",\n",
    "        f\"{early_arrivals['Wait_After_Triage_minutes'].mean():.0f}\",\n",
    "        f\"{(early_arrivals['Wait_After_Triage_minutes'] > 30).sum()}\",\n",
    "        f\"{(early_arrivals['Wait_After_Triage_minutes'] > 60).sum()}\",\n",
    "        primary_bottleneck\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv('/Users/mukeshravichandran/Datathon/5to7_Surge/bottleneck_analysis_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported to: bottleneck_analysis_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  1. arrivals_vs_exits.png - Flow comparison visualization\")\n",
    "print(\"  2. process_breakdown.png - Process time analysis\")\n",
    "print(\"  3. length_of_stay_distribution.png - LOS distribution\")\n",
    "print(\"  4. staffing_vs_load.png - Staffing adequacy assessment\")\n",
    "print(\"  5. cumulative_flow_analysis.png - Flow accumulation for peak days\")\n",
    "print(\"  6. detailed_flow_metrics.csv - Daily metrics table\")\n",
    "print(\"  7. bottleneck_analysis_summary.csv - Key findings summary\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}