{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ER Operations Analysis: Patient Flow & Throughput Optimization\n",
    "## Meridian City Hospital - Delay Analysis & Solutions\n",
    "\n",
    "**Team:** ACM  \n",
    "**Date:** 2024  \n",
    "**Objective:** Identify primary causes of delays and propose actionable solutions to improve ER throughput, staffing efficiency, and operational performance\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfaf Analysis Objectives\n",
    "\n",
    "1. **Patient Flow Analysis** - Understand patient journey through ER\n",
    "2. **Delay Identification** - Identify bottlenecks and delay causes\n",
    "3. **Throughput Optimization** - Analyze processing times and efficiency\n",
    "4. **Staffing Efficiency** - Evaluate staffing impact on operations\n",
    "5. **Operational Performance** - Assess overall ER performance metrics\n",
    "6. **Actionable Insights** - Propose data-driven solutions\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Key Questions to Answer\n",
    "\n",
    "- What are the primary delay points in patient flow?\n",
    "- How do wait times vary by time of day, day of week, or season?\n",
    "- What is the impact of staffing levels on throughput?\n",
    "- Which factors correlate most strongly with delays?\n",
    "- How can we optimize resource allocation?\n",
    "- What are the bottlenecks in the ER process?\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\uddfa\ufe0f Analysis Roadmap\n",
    "\n",
    "1. **Data Loading & Exploration** - Load and understand the data\n",
    "2. **Patient Flow Mapping** - Map patient journey through ER\n",
    "3. **Delay Analysis** - Identify and quantify delays\n",
    "4. **Time-Based Patterns** - Analyze temporal patterns\n",
    "5. **Staffing Impact** - Evaluate staffing efficiency\n",
    "6. **Bottleneck Identification** - Find process bottlenecks\n",
    "7. **Root Cause Analysis** - Identify primary delay causes\n",
    "8. **Solutions & Recommendations** - Propose actionable solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Loading & Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Initialize findings\n",
    "findings = {\n",
    "    'delays': [],\n",
    "    'bottlenecks': [],\n",
    "    'insights': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "print(\"\u2713 Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD CLEANED & JOINED DATASET\n",
    "# ============================================================================\n",
    "\n",
    "# Update this path to your joined/cleaned dataset\n",
    "df = pd.read_csv('joined_data.csv')  # UPDATE THIS PATH\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET LOADED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Shape: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FIRST FEW ROWS\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head())\n",
    "\n",
    "# Column information\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal columns: {len(df.columns)}\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    print(f\"  {i:2d}. {col:<40} ({dtype})\")\n",
    "\n",
    "# Identify key columns for ER operations analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IDENTIFYING KEY COLUMNS FOR ER OPERATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Time-related columns\n",
    "time_cols = [col for col in df.columns if any(term in col.lower() for term in \n",
    "              ['time', 'date', 'arrival', 'triage', 'discharge', 'wait', 'duration', 'length'])]\n",
    "print(f\"\\nTime-related columns: {time_cols}\")\n",
    "\n",
    "# Patient flow columns\n",
    "flow_cols = [col for col in df.columns if any(term in col.lower() for term in \n",
    "             ['status', 'stage', 'phase', 'disposition', 'triage', 'priority', 'severity'])]\n",
    "print(f\"Patient flow columns: {flow_cols}\")\n",
    "\n",
    "# Staffing columns\n",
    "staffing_cols = [col for col in df.columns if any(term in col.lower() for term in \n",
    "                 ['staff', 'nurse', 'doctor', 'physician', 'provider', 'personnel'])]\n",
    "print(f\"Staffing columns: {staffing_cols}\")\n",
    "\n",
    "# Numerical columns for analysis\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumerical columns: {len(numeric_cols)}\")\n",
    "print(f\"Categorical columns: {len(df.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "\n",
    "findings['insights'].append(f\"Dataset loaded: {df.shape[0]:,} records with {df.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Patient Flow Mapping & Timeline Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PATIENT FLOW MAPPING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PATIENT FLOW MAPPING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter out non-time columns from time_cols (like 'Triage Level', 'Arrival To Exit')\n",
    "actual_time_cols = [col for col in time_cols \n",
    "                    if col not in ['Triage Level', 'Arrival To Exit'] \n",
    "                    and ('time' in col.lower() or 'date' in col.lower() or 'start' in col.lower() or 'end' in col.lower())]\n",
    "\n",
    "print(f\"\\nTime columns to convert: {actual_time_cols}\")\n",
    "\n",
    "# Convert date/time columns to datetime\n",
    "for col in actual_time_cols:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            converted_count = df[col].notna().sum()\n",
    "            print(f\"\u2713 Converted {col} to datetime ({converted_count:,} valid values)\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u2717 Could not convert {col}: {e}\")\n",
    "\n",
    "# Identify timeline columns more accurately\n",
    "arrival_col = None\n",
    "discharge_col = None  # Also called Exit Time\n",
    "triage_start_col = None\n",
    "triage_end_col = None\n",
    "\n",
    "# Try to identify these columns automatically\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    # Arrival column\n",
    "    if ('arrival' in col_lower and 'time' in col_lower) and arrival_col is None:\n",
    "        arrival_col = col\n",
    "    # Discharge/Exit column\n",
    "    if ('exit' in col_lower and 'time' in col_lower) or ('discharge' in col_lower) or ('departure' in col_lower):\n",
    "        discharge_col = col\n",
    "    # Triage columns\n",
    "    if 'triage start' in col_lower:\n",
    "        triage_start_col = col\n",
    "    if 'triage end' in col_lower:\n",
    "        triage_end_col = col\n",
    "\n",
    "print(f\"\\nIdentified timeline columns:\")\n",
    "print(f\"  Arrival: {arrival_col}\")\n",
    "print(f\"  Exit/Discharge: {discharge_col}\")\n",
    "print(f\"  Triage Start: {triage_start_col}\")\n",
    "print(f\"  Triage End: {triage_end_col}\")\n",
    "\n",
    "# Calculate Length of Stay - Use existing 'Arrival To Exit' if available, or calculate from times\n",
    "if 'Arrival To Exit' in df.columns and df['Arrival To Exit'].dtype in [np.number]:\n",
    "    # Use existing duration column (appears to be in minutes based on column name)\n",
    "    print(\"\\n\u2713 Using existing 'Arrival To Exit' column for length of stay\")\n",
    "    df['Length_of_Stay_Minutes'] = df['Arrival To Exit']\n",
    "    df['Length_of_Stay_Hours'] = df['Length_of_Stay_Minutes'] / 60\n",
    "    \n",
    "elif arrival_col and discharge_col and df[arrival_col].dtype == 'datetime64[ns]' and df[discharge_col].dtype == 'datetime64[ns]':\n",
    "    # Calculate from datetime columns\n",
    "    print(\"\\n\u2713 Calculating length of stay from arrival and exit times\")\n",
    "    df['Length_of_Stay_Minutes'] = (df[discharge_col] - df[arrival_col]).dt.total_seconds() / 60\n",
    "    df['Length_of_Stay_Hours'] = df['Length_of_Stay_Minutes'] / 60\n",
    "else:\n",
    "    print(\"\\n\u26a0 Could not calculate length of stay - missing required time columns\")\n",
    "    if arrival_col is None:\n",
    "        print(\"   Missing: Arrival time column\")\n",
    "    if discharge_col is None:\n",
    "        print(\"   Missing: Exit/Discharge time column\")\n",
    "\n",
    "# Display length of stay statistics if available\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"LENGTH OF STAY STATISTICS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    valid_los = df['Length_of_Stay_Hours'].dropna()\n",
    "    if len(valid_los) > 0:\n",
    "        print(f\"Mean: {valid_los.mean():.2f} hours\")\n",
    "        print(f\"Median: {valid_los.median():.2f} hours\")\n",
    "        print(f\"Min: {valid_los.min():.2f} hours\")\n",
    "        print(f\"Max: {valid_los.max():.2f} hours\")\n",
    "        print(f\"75th percentile: {valid_los.quantile(0.75):.2f} hours\")\n",
    "        print(f\"90th percentile: {valid_los.quantile(0.90):.2f} hours\")\n",
    "        print(f\"Valid records: {len(valid_los):,} / {len(df):,}\")\n",
    "        \n",
    "        # Visualize distribution\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        valid_los.hist(bins=50, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(valid_los.mean(), color='red', linestyle='--', \n",
    "                    label=f'Mean: {valid_los.mean():.2f}h', linewidth=2)\n",
    "        plt.axvline(valid_los.median(), color='green', linestyle='--', \n",
    "                    label=f'Median: {valid_los.median():.2f}h', linewidth=2)\n",
    "        plt.xlabel('Length of Stay (Hours)', fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "        plt.title('Distribution of ER Length of Stay', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        findings['insights'].append(f\"Average ER length of stay: {valid_los.mean():.2f} hours (median: {valid_los.median():.2f}h)\")\n",
    "    else:\n",
    "        print(\"\u26a0 No valid length of stay data available\")\n",
    "\n",
    "# Extract time components for analysis from arrival time\n",
    "if arrival_col and arrival_col in df.columns:\n",
    "    if df[arrival_col].dtype == 'datetime64[ns]':\n",
    "        df['Arrival_Hour'] = df[arrival_col].dt.hour\n",
    "        df['Arrival_DayOfWeek'] = df[arrival_col].dt.dayofweek\n",
    "        df['Arrival_Month'] = df[arrival_col].dt.month\n",
    "        df['Arrival_Date'] = df[arrival_col].dt.date\n",
    "        print(f\"\\n\u2713 Extracted time components from {arrival_col}\")\n",
    "    else:\n",
    "        print(f\"\\n\u26a0 {arrival_col} is not a datetime column - cannot extract time components\")\n",
    "\n",
    "# Calculate additional flow metrics if we have the time data\n",
    "if arrival_col and triage_start_col and arrival_col in df.columns and triage_start_col in df.columns:\n",
    "    if df[arrival_col].dtype == 'datetime64[ns]' and df[triage_start_col].dtype == 'datetime64[ns]':\n",
    "        df['Wait_To_Triage_Minutes'] = (df[triage_start_col] - df[arrival_col]).dt.total_seconds() / 60\n",
    "        print(f\"\u2713 Calculated wait time to triage: {df['Wait_To_Triage_Minutes'].mean():.2f} minutes (avg)\")\n",
    "\n",
    "if triage_start_col and triage_end_col and triage_start_col in df.columns and triage_end_col in df.columns:\n",
    "    if df[triage_start_col].dtype == 'datetime64[ns]' and df[triage_end_col].dtype == 'datetime64[ns]':\n",
    "        df['Triage_Duration_Minutes'] = (df[triage_end_col] - df[triage_start_col]).dt.total_seconds() / 60\n",
    "        print(f\"\u2713 Calculated triage duration: {df['Triage_Duration_Minutes'].mean():.2f} minutes (avg)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Delay Analysis & Bottleneck Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DELAY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DELAY ANALYSIS & BOTTLENECK IDENTIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define delay thresholds (adjust based on industry standards or your data)\n",
    "# Typical ER benchmarks: < 1 hour = excellent, 1-2 hours = good, > 2 hours = delay\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    df['Delay_Category'] = pd.cut(\n",
    "        df['Length_of_Stay_Hours'],\n",
    "        bins=[0, 1, 2, 4, 8, float('inf')],\n",
    "        labels=['Excellent (<1h)', 'Good (1-2h)', 'Moderate (2-4h)', 'Delayed (4-8h)', 'Severe Delay (>8h)']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"DELAY CATEGORIZATION\")\n",
    "    print(\"-\" * 80)\n",
    "    delay_distribution = df['Delay_Category'].value_counts().sort_index()\n",
    "    display(delay_distribution.to_frame('Count'))\n",
    "    \n",
    "    # Calculate delay percentages\n",
    "    delay_pct = (delay_distribution / len(df) * 100).round(2)\n",
    "    print(\"\\nDelay Distribution (%):\")\n",
    "    for category, pct in delay_pct.items():\n",
    "        print(f\"  {category}: {pct:.1f}%\")\n",
    "        if 'Delay' in str(category) or 'Severe' in str(category):\n",
    "            findings['delays'].append(f\"{pct:.1f}% of patients experience {category}\")\n",
    "    \n",
    "    # Visualize delay distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    delay_distribution.plot(kind='bar', color='coral')\n",
    "    plt.title('Patient Delay Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Delay Category', fontsize=12)\n",
    "    plt.ylabel('Number of Patients', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Identify patients with excessive delays\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    # Define excessive delay threshold (e.g., > 4 hours or 90th percentile)\n",
    "    delay_threshold = df['Length_of_Stay_Hours'].quantile(0.90)\n",
    "    excessive_delays = df[df['Length_of_Stay_Hours'] > delay_threshold].copy()\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"EXCESSIVE DELAYS (> {delay_threshold:.1f} hours / 90th percentile)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Total patients with excessive delays: {len(excessive_delays):,} ({len(excessive_delays)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    findings['bottlenecks'].append(f\"{len(excessive_delays):,} patients ({len(excessive_delays)/len(df)*100:.1f}%) experience delays > {delay_threshold:.1f} hours\")\n",
    "\n",
    "# Analyze delay factors\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"DELAY FACTOR ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare delays across different categories\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    delay_analysis = {}\n",
    "    \n",
    "    # Analyze by categorical variables\n",
    "    for col in flow_cols + ['Arrival_Hour', 'Arrival_DayOfWeek']:\n",
    "        if col in df.columns and df[col].notna().any():\n",
    "            if df[col].nunique() < 20:  # Only for reasonable number of categories\n",
    "                delay_by_category = df.groupby(col)['Length_of_Stay_Hours'].agg(['mean', 'median', 'count'])\n",
    "                delay_by_category = delay_by_category.sort_values('mean', ascending=False)\n",
    "                \n",
    "                # Identify categories with longest delays\n",
    "                worst_category = delay_by_category.index[0]\n",
    "                worst_avg_delay = delay_by_category.loc[worst_category, 'mean']\n",
    "                best_category = delay_by_category.index[-1]\n",
    "                best_avg_delay = delay_by_category.loc[best_category, 'mean']\n",
    "                \n",
    "                if worst_avg_delay > delay_by_category['mean'].mean() * 1.2:  # 20% above average\n",
    "                    findings['delays'].append(\n",
    "                        f\"{col}: {worst_category} has longest delays (avg: {worst_avg_delay:.1f}h) \"\n",
    "                        f\"vs best: {best_category} ({best_avg_delay:.1f}h)\"\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"\\n{col}:\")\n",
    "                    print(f\"  Worst: {worst_category} - {worst_avg_delay:.2f} hours (avg)\")\n",
    "                    print(f\"  Best: {best_category} - {best_avg_delay:.2f} hours (avg)\")\n",
    "                    \n",
    "                    # Visualize\n",
    "                    if len(delay_by_category) <= 15:\n",
    "                        plt.figure(figsize=(12, 6))\n",
    "                        delay_by_category['mean'].plot(kind='bar', color='steelblue')\n",
    "                        plt.axhline(delay_by_category['mean'].mean(), color='red', \n",
    "                                   linestyle='--', label=f'Overall Mean: {delay_by_category[\"mean\"].mean():.2f}h')\n",
    "                        plt.title(f'Average Length of Stay by {col}', fontsize=14, fontweight='bold')\n",
    "                        plt.xlabel(col, fontsize=12)\n",
    "                        plt.ylabel('Average Length of Stay (Hours)', fontsize=12)\n",
    "                        plt.xticks(rotation=45, ha='right')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3, axis='y')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.5: Delay Category, Severity & Patient Satisfaction Relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RELATIONSHIP ANALYSIS: DELAY CATEGORY, SEVERITY & PATIENT SATISFACTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DELAY CATEGORY, SEVERITY & PATIENT SATISFACTION RELATIONSHIPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find patient satisfaction/rating column - more comprehensive search\n",
    "satisfaction_col = None\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower().strip()\n",
    "    # Check for various satisfaction/rating column name patterns\n",
    "    if any(term in col_lower for term in ['satisfaction', 'rating', 'feedback', 'score', 'review', 'rate']):\n",
    "        satisfaction_col = col\n",
    "        break\n",
    "\n",
    "# If not found, try exact matches\n",
    "if satisfaction_col is None:\n",
    "    possible_names = ['Patient Satisfaction', 'Satisfaction', 'Rating', 'Patient_Rating', \n",
    "                     'Feedback', 'Patient_Feedback', 'Score', 'Patient_Score']\n",
    "    for name in possible_names:\n",
    "        if name in df.columns:\n",
    "            satisfaction_col = name\n",
    "            break\n",
    "\n",
    "# Find severity/triage level column - improved detection\n",
    "severity_col = None\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower().strip()\n",
    "    # Look for triage level, severity level, etc.\n",
    "    if ('triage' in col_lower and 'level' in col_lower) or \\\n",
    "       ('severity' in col_lower) or \\\n",
    "       (col_lower == 'triage level') or \\\n",
    "       (col_lower == 'severity level'):\n",
    "        severity_col = col\n",
    "        break\n",
    "\n",
    "# If not found with 'level', try just 'triage'\n",
    "if severity_col is None:\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower().strip()\n",
    "        if 'triage' in col_lower and col_lower != 'triage start' and col_lower != 'triage end':\n",
    "            severity_col = col\n",
    "            break\n",
    "\n",
    "print(f\"\\nIdentified columns:\")\n",
    "print(f\"  Delay Category: {'Delay_Category' if 'Delay_Category' in df.columns else 'Not found'}\")\n",
    "print(f\"  Severity/Triage Level: {severity_col if severity_col else 'Not found'}\")\n",
    "print(f\"  Patient Satisfaction/Rating: {satisfaction_col if satisfaction_col else 'Not found'}\")\n",
    "\n",
    "# Show all column names for debugging\n",
    "if satisfaction_col is None or severity_col is None:\n",
    "    print(\"\\nAll available columns in dataset:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Check if we have the required columns\n",
    "has_delay = 'Delay_Category' in df.columns\n",
    "has_severity = severity_col is not None and severity_col in df.columns\n",
    "has_satisfaction = satisfaction_col is not None and satisfaction_col in df.columns\n",
    "\n",
    "if not has_delay:\n",
    "    print(\"\\n\u26a0 Delay_Category not found. Make sure Section 3 ran successfully.\")\n",
    "if not has_severity:\n",
    "    print(\"\u26a0 Severity/Triage Level column not found.\")\n",
    "if not has_satisfaction:\n",
    "    print(\"\u26a0 Patient Satisfaction/Rating column not found.\")\n",
    "\n",
    "# ============================================================================\n",
    "# CROSS-TABULATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if has_delay and has_severity:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DELAY CATEGORY vs SEVERITY LEVEL - CROSS TABULATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Filter out any NaN values before creating crosstab\n",
    "        df_clean = df[['Delay_Category', severity_col]].dropna()\n",
    "        \n",
    "        if len(df_clean) > 0:\n",
    "            # Create cross-tabulation\n",
    "            delay_severity_crosstab = pd.crosstab(df_clean['Delay_Category'], df_clean[severity_col], margins=True)\n",
    "            print(\"\\nCount Table:\")\n",
    "            display(delay_severity_crosstab)\n",
    "            \n",
    "            # Percentage table (row percentages)\n",
    "            delay_severity_pct = pd.crosstab(df_clean['Delay_Category'], df_clean[severity_col], normalize='index') * 100\n",
    "            delay_severity_pct = delay_severity_pct.round(2)\n",
    "            print(\"\\nPercentage Table (Row % - within each Delay Category):\")\n",
    "            display(delay_severity_pct)\n",
    "            \n",
    "            # Visualize only if we have data\n",
    "            if len(delay_severity_crosstab) > 1 and len(delay_severity_crosstab.columns) > 1:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                \n",
    "                # Count heatmap (exclude margins row/column)\n",
    "                crosstab_data = delay_severity_crosstab.iloc[:-1, :-1]\n",
    "                if crosstab_data.shape[0] > 0 and crosstab_data.shape[1] > 0:\n",
    "                    sns.heatmap(crosstab_data, annot=True, fmt='d', cmap='YlOrRd', \n",
    "                               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "                    axes[0].set_title('Delay Category vs Severity Level (Count)', fontsize=14, fontweight='bold')\n",
    "                    axes[0].set_xlabel('Severity/Triage Level', fontsize=12)\n",
    "                    axes[0].set_ylabel('Delay Category', fontsize=12)\n",
    "                    \n",
    "                    # Percentage heatmap\n",
    "                    sns.heatmap(delay_severity_pct, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "                               ax=axes[1], cbar_kws={'label': 'Percentage (%)'})\n",
    "                    axes[1].set_title('Delay Category vs Severity Level (Row %)', fontsize=14, fontweight='bold')\n",
    "                    axes[1].set_xlabel('Severity/Triage Level', fontsize=12)\n",
    "                    axes[1].set_ylabel('Delay Category', fontsize=12)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                findings['insights'].append(\n",
    "                    f\"Delay-Severity relationship: {len(delay_severity_crosstab)-1} delay categories \u00d7 \"\n",
    "                    f\"{len(delay_severity_crosstab.columns)-1} severity levels\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"\u26a0 Not enough data for visualization\")\n",
    "        else:\n",
    "            print(\"\u26a0 No valid data after removing missing values\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0 Error creating cross-tabulation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# DELAY CATEGORY vs PATIENT SATISFACTION\n",
    "if has_delay and has_satisfaction:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DELAY CATEGORY vs PATIENT SATISFACTION - RELATIONSHIP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Check if satisfaction is numeric or categorical\n",
    "        if df[satisfaction_col].dtype in [np.number]:\n",
    "            # Numeric rating - calculate statistics by delay category\n",
    "            delay_satisfaction_stats = df.groupby('Delay_Category')[satisfaction_col].agg(['mean', 'median', 'count', 'std'])\n",
    "            delay_satisfaction_stats = delay_satisfaction_stats.sort_values('mean', ascending=False)\n",
    "            \n",
    "            print(\"\\nPatient Satisfaction Statistics by Delay Category:\")\n",
    "            display(delay_satisfaction_stats)\n",
    "            \n",
    "            # Visualize\n",
    "            fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "            \n",
    "            # Average satisfaction by delay category\n",
    "            axes[0].bar(range(len(delay_satisfaction_stats)), delay_satisfaction_stats['mean'], \n",
    "                       color='steelblue', alpha=0.7)\n",
    "            axes[0].set_xticks(range(len(delay_satisfaction_stats)))\n",
    "            axes[0].set_xticklabels(delay_satisfaction_stats.index, rotation=45, ha='right')\n",
    "            axes[0].set_ylabel('Average Satisfaction Rating', fontsize=12)\n",
    "            axes[0].set_title('Average Patient Satisfaction by Delay Category', fontsize=14, fontweight='bold')\n",
    "            axes[0].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (idx, row) in enumerate(delay_satisfaction_stats.iterrows()):\n",
    "                axes[0].text(i, row['mean'], f\"{row['mean']:.2f}\", \n",
    "                            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "            \n",
    "            # Box plot\n",
    "            delay_categories = df['Delay_Category'].dropna().unique()\n",
    "            data_for_box = [df[df['Delay_Category'] == cat][satisfaction_col].dropna() \n",
    "                           for cat in delay_categories if len(df[df['Delay_Category'] == cat]) > 0]\n",
    "            \n",
    "            axes[1].boxplot(data_for_box, labels=[cat for cat in delay_categories if len(df[df['Delay_Category'] == cat]) > 0])\n",
    "            axes[1].set_xticklabels([cat for cat in delay_categories if len(df[df['Delay_Category'] == cat]) > 0], \n",
    "                                   rotation=45, ha='right')\n",
    "            axes[1].set_ylabel('Patient Satisfaction Rating', fontsize=12)\n",
    "            axes[1].set_title('Distribution of Satisfaction Ratings by Delay Category', fontsize=14, fontweight='bold')\n",
    "            axes[1].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Correlation between length of stay and satisfaction\n",
    "            if 'Length_of_Stay_Hours' in df.columns:\n",
    "                correlation = df['Length_of_Stay_Hours'].corr(df[satisfaction_col])\n",
    "                print(f\"\\nCorrelation between Length of Stay and Satisfaction: {correlation:.3f}\")\n",
    "                if correlation < -0.2:\n",
    "                    findings['insights'].append(\n",
    "                        f\"Strong negative correlation ({correlation:.3f}) between length of stay and satisfaction - \"\n",
    "                        f\"shorter stays correlate with higher satisfaction\"\n",
    "                    )\n",
    "                elif correlation > 0.2:\n",
    "                    findings['insights'].append(\n",
    "                        f\"Positive correlation ({correlation:.3f}) between length of stay and satisfaction - \"\n",
    "                        f\"longer stays correlate with higher satisfaction (may indicate more serious cases)\"\n",
    "                    )\n",
    "            \n",
    "            # Identify best and worst delay categories for satisfaction\n",
    "            best_delay = delay_satisfaction_stats['mean'].idxmax()\n",
    "            worst_delay = delay_satisfaction_stats['mean'].idxmin()\n",
    "            findings['insights'].append(\n",
    "                f\"Highest satisfaction: {best_delay} (avg: {delay_satisfaction_stats.loc[best_delay, 'mean']:.2f})\"\n",
    "            )\n",
    "            findings['insights'].append(\n",
    "                f\"Lowest satisfaction: {worst_delay} (avg: {delay_satisfaction_stats.loc[worst_delay, 'mean']:.2f})\"\n",
    "            )\n",
    "        else:\n",
    "            # Categorical satisfaction - create cross-tabulation\n",
    "            df_sat_clean = df[['Delay_Category', satisfaction_col]].dropna()\n",
    "            if len(df_sat_clean) > 0:\n",
    "                delay_satisfaction_crosstab = pd.crosstab(df_sat_clean['Delay_Category'], df_sat_clean[satisfaction_col], margins=True)\n",
    "                print(\"\\nCount Table:\")\n",
    "                display(delay_satisfaction_crosstab)\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0 Error analyzing delay-satisfaction relationship: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# SEVERITY vs PATIENT SATISFACTION\n",
    "if has_severity and has_satisfaction:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SEVERITY LEVEL vs PATIENT SATISFACTION - RELATIONSHIP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        if df[satisfaction_col].dtype in [np.number]:\n",
    "            df_sev_sat_clean = df[[severity_col, satisfaction_col]].dropna()\n",
    "            if len(df_sev_sat_clean) > 0:\n",
    "                severity_satisfaction_stats = df_sev_sat_clean.groupby(severity_col)[satisfaction_col].agg(['mean', 'median', 'count', 'std'])\n",
    "                severity_satisfaction_stats = severity_satisfaction_stats.sort_values('mean', ascending=False)\n",
    "                \n",
    "                print(\"\\nPatient Satisfaction Statistics by Severity Level:\")\n",
    "                display(severity_satisfaction_stats)\n",
    "                \n",
    "                # Visualize\n",
    "                if len(severity_satisfaction_stats) > 0:\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    severity_satisfaction_stats['mean'].plot(kind='bar', color='coral', alpha=0.7)\n",
    "                    plt.title('Average Patient Satisfaction by Severity/Triage Level', fontsize=14, fontweight='bold')\n",
    "                    plt.xlabel('Severity/Triage Level', fontsize=12)\n",
    "                    plt.ylabel('Average Satisfaction Rating', fontsize=12)\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                    plt.grid(True, alpha=0.3, axis='y')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "        else:\n",
    "            print(f\"\u26a0 Satisfaction column '{satisfaction_col}' is not numeric\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0 Error analyzing severity-satisfaction relationship: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================================================================\n",
    "# COMPREHENSIVE 3-WAY RELATIONSHIP TABLE\n",
    "# ============================================================================\n",
    "\n",
    "if has_delay and has_severity and has_satisfaction:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPREHENSIVE 3-WAY RELATIONSHIP: DELAY \u00d7 SEVERITY \u00d7 SATISFACTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        if df[satisfaction_col].dtype in [np.number]:\n",
    "            # Filter out missing values\n",
    "            df_3way = df[['Delay_Category', severity_col, satisfaction_col]].dropna()\n",
    "            \n",
    "            if len(df_3way) > 0:\n",
    "                # Create comprehensive pivot table\n",
    "                comprehensive_table = df_3way.groupby(['Delay_Category', severity_col])[satisfaction_col].agg([\n",
    "                    'mean', 'count', 'median'\n",
    "                ]).round(2)\n",
    "                comprehensive_table.columns = ['Avg_Satisfaction', 'Count', 'Median_Satisfaction']\n",
    "                comprehensive_table = comprehensive_table.reset_index()\n",
    "                \n",
    "                # Pivot for better visualization\n",
    "                pivot_table = df_3way.pivot_table(\n",
    "                    values=satisfaction_col,\n",
    "                    index='Delay_Category',\n",
    "                    columns=severity_col,\n",
    "                    aggfunc=['mean', 'count'],\n",
    "                    fill_value=0\n",
    "                )\n",
    "                \n",
    "                print(\"\\nAverage Satisfaction by Delay Category and Severity Level:\")\n",
    "                if 'mean' in pivot_table.columns.levels[0]:\n",
    "                    display(pivot_table['mean'].round(2))\n",
    "                \n",
    "                print(\"\\nPatient Count by Delay Category and Severity Level:\")\n",
    "                if 'count' in pivot_table.columns.levels[0]:\n",
    "                    display(pivot_table['count'])\n",
    "                \n",
    "                # Create heatmap only if we have valid data\n",
    "                if 'mean' in pivot_table.columns.levels[0] and len(pivot_table['mean']) > 0:\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                    \n",
    "                    # Satisfaction heatmap\n",
    "                    mean_data = pivot_table['mean']\n",
    "                    if mean_data.shape[0] > 0 and mean_data.shape[1] > 0:\n",
    "                        sns.heatmap(mean_data, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "                                   center=mean_data.values[mean_data.values > 0].mean() if (mean_data.values > 0).any() else 3, \n",
    "                                   ax=axes[0], cbar_kws={'label': 'Avg Satisfaction'}, \n",
    "                                   vmin=mean_data.values[mean_data.values > 0].min() if (mean_data.values > 0).any() else 1, \n",
    "                                   vmax=mean_data.values.max() if (mean_data.values > 0).any() else 5)\n",
    "                        axes[0].set_title('Average Satisfaction: Delay Category \u00d7 Severity Level', \n",
    "                                         fontsize=14, fontweight='bold')\n",
    "                        axes[0].set_xlabel('Severity/Triage Level', fontsize=12)\n",
    "                        axes[0].set_ylabel('Delay Category', fontsize=12)\n",
    "                        \n",
    "                        # Count heatmap\n",
    "                        count_data = pivot_table['count']\n",
    "                        sns.heatmap(count_data, annot=True, fmt='d', cmap='YlOrRd', \n",
    "                                   ax=axes[1], cbar_kws={'label': 'Patient Count'})\n",
    "                        axes[1].set_title('Patient Count: Delay Category \u00d7 Severity Level', \n",
    "                                         fontsize=14, fontweight='bold')\n",
    "                        axes[1].set_xlabel('Severity/Triage Level', fontsize=12)\n",
    "                        axes[1].set_ylabel('Delay Category', fontsize=12)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                \n",
    "                # Summary insights\n",
    "                print(\"\\n\" + \"-\" * 80)\n",
    "                print(\"KEY INSIGHTS FROM 3-WAY RELATIONSHIP\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                # Find best combination (highest satisfaction) - with error handling\n",
    "                try:\n",
    "                    if len(comprehensive_table) > 0:\n",
    "                        best_idx = comprehensive_table['Avg_Satisfaction'].idxmax()\n",
    "                        best_combo = comprehensive_table.loc[best_idx]\n",
    "                        print(f\"\\nBest combination (Highest Satisfaction):\")\n",
    "                        print(f\"  Delay Category: {best_combo['Delay_Category']}\")\n",
    "                        print(f\"  Severity Level: {best_combo[severity_col]}\")\n",
    "                        print(f\"  Average Satisfaction: {best_combo['Avg_Satisfaction']:.2f}\")\n",
    "                        print(f\"  Patient Count: {int(best_combo['Count'])}\")\n",
    "                        \n",
    "                        # Find worst combination (lowest satisfaction)\n",
    "                        worst_idx = comprehensive_table['Avg_Satisfaction'].idxmin()\n",
    "                        worst_combo = comprehensive_table.loc[worst_idx]\n",
    "                        print(f\"\\nWorst combination (Lowest Satisfaction):\")\n",
    "                        print(f\"  Delay Category: {worst_combo['Delay_Category']}\")\n",
    "                        print(f\"  Severity Level: {worst_combo[severity_col]}\")\n",
    "                        print(f\"  Average Satisfaction: {worst_combo['Avg_Satisfaction']:.2f}\")\n",
    "                        print(f\"  Patient Count: {int(worst_combo['Count'])}\")\n",
    "                        \n",
    "                        findings['insights'].append(\n",
    "                            f\"Best satisfaction: {best_combo['Delay_Category']} + {best_combo[severity_col]} \"\n",
    "                            f\"(avg: {best_combo['Avg_Satisfaction']:.2f})\"\n",
    "                        )\n",
    "                        findings['insights'].append(\n",
    "                            f\"Worst satisfaction: {worst_combo['Delay_Category']} + {worst_combo[severity_col]} \"\n",
    "                            f\"(avg: {worst_combo['Avg_Satisfaction']:.2f})\"\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"\u26a0 Error finding best/worst combinations: {e}\")\n",
    "            else:\n",
    "                print(\"\u26a0 No valid data after removing missing values for 3-way analysis\")\n",
    "        else:\n",
    "            print(f\"\u26a0 Satisfaction column '{satisfaction_col}' is not numeric - cannot create 3-way pivot\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0 Error in 3-way relationship analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Time-Based Patterns & Peak Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TIME-BASED PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TIME-BASED PATTERNS & PEAK ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Hourly patterns\n",
    "if 'Arrival_Hour' in df.columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"HOURLY ARRIVAL PATTERNS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    hourly_arrivals = df.groupby('Arrival_Hour').size()\n",
    "    hourly_delays = df.groupby('Arrival_Hour')['Length_of_Stay_Hours'].mean() if 'Length_of_Stay_Hours' in df.columns else None\n",
    "    \n",
    "    # Visualize hourly arrivals\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Arrivals by hour\n",
    "    axes[0].bar(hourly_arrivals.index, hourly_arrivals.values, color='steelblue', alpha=0.7)\n",
    "    axes[0].set_title('Patient Arrivals by Hour of Day', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Hour of Day', fontsize=12)\n",
    "    axes[0].set_ylabel('Number of Arrivals', fontsize=12)\n",
    "    axes[0].set_xticks(range(0, 24))\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    peak_hour = hourly_arrivals.idxmax()\n",
    "    axes[0].axvline(peak_hour, color='red', linestyle='--', \n",
    "                   label=f'Peak Hour: {peak_hour}:00 ({hourly_arrivals.max()} arrivals)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Average delays by hour (if available)\n",
    "    if hourly_delays is not None:\n",
    "        axes[1].plot(hourly_delays.index, hourly_delays.values, marker='o', \n",
    "                    color='coral', linewidth=2, markersize=8)\n",
    "        axes[1].set_title('Average Length of Stay by Arrival Hour', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Hour of Day', fontsize=12)\n",
    "        axes[1].set_ylabel('Average Length of Stay (Hours)', fontsize=12)\n",
    "        axes[1].set_xticks(range(0, 24))\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        worst_hour = hourly_delays.idxmax()\n",
    "        axes[1].axvline(worst_hour, color='red', linestyle='--', \n",
    "                       label=f'Worst Hour: {worst_hour}:00 (avg: {hourly_delays.max():.1f}h)')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        findings['insights'].append(f\"Peak arrival hour: {peak_hour}:00 with {hourly_arrivals.max()} arrivals\")\n",
    "        findings['delays'].append(f\"Longest delays occur at {worst_hour}:00 (avg: {hourly_delays.max():.1f}h)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Day of week patterns\n",
    "if 'Arrival_DayOfWeek' in df.columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"DAY OF WEEK PATTERNS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df['Day_Name'] = df['Arrival_DayOfWeek'].map(lambda x: day_names[x] if pd.notna(x) else None)\n",
    "    \n",
    "    daily_arrivals = df.groupby('Day_Name').size()\n",
    "    daily_delays = df.groupby('Day_Name')['Length_of_Stay_Hours'].mean() if 'Length_of_Stay_Hours' in df.columns else None\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Arrivals by day\n",
    "    day_order = day_names\n",
    "    daily_arrivals_ordered = daily_arrivals.reindex(day_order)\n",
    "    axes[0].bar(range(len(day_order)), daily_arrivals_ordered.values, color='steelblue', alpha=0.7)\n",
    "    axes[0].set_title('Patient Arrivals by Day of Week', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Day of Week', fontsize=12)\n",
    "    axes[0].set_ylabel('Number of Arrivals', fontsize=12)\n",
    "    axes[0].set_xticks(range(len(day_order)))\n",
    "    axes[0].set_xticklabels(day_order, rotation=45, ha='right')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    busiest_day = daily_arrivals_ordered.idxmax()\n",
    "    axes[0].axvline(daily_arrivals_ordered.idxmax(), color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Delays by day\n",
    "    if daily_delays is not None:\n",
    "        daily_delays_ordered = daily_delays.reindex(day_order)\n",
    "        axes[1].bar(range(len(day_order)), daily_delays_ordered.values, color='coral', alpha=0.7)\n",
    "        axes[1].set_title('Average Length of Stay by Day of Week', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Day of Week', fontsize=12)\n",
    "        axes[1].set_ylabel('Average Length of Stay (Hours)', fontsize=12)\n",
    "        axes[1].set_xticks(range(len(day_order)))\n",
    "        axes[1].set_xticklabels(day_order, rotation=45, ha='right')\n",
    "        axes[1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        worst_day = daily_delays_ordered.idxmax()\n",
    "        findings['delays'].append(f\"Busiest day: {busiest_day} with {daily_arrivals_ordered.max()} arrivals\")\n",
    "        findings['delays'].append(f\"Longest delays on: {worst_day} (avg: {daily_delays_ordered.max():.1f}h)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exit patterns by hour\n",
    "if discharge_col and discharge_col in df.columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"HOURLY EXIT PATTERNS (All Dispositions)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Extract exit hour from discharge/exit time\n",
    "    if df[discharge_col].dtype == 'datetime64[ns]':\n",
    "        df['Exit_Hour'] = df[discharge_col].dt.hour\n",
    "        \n",
    "        # Count exits by hour\n",
    "        hourly_exits = df.groupby('Exit_Hour').size()\n",
    "        \n",
    "        # Compare arrivals vs exits\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 14))\n",
    "        \n",
    "        # Exits by hour\n",
    "        axes[0].bar(hourly_exits.index, hourly_exits.values, color='coral', alpha=0.7)\n",
    "        axes[0].set_title('ER Exits by Hour of Day (All Dispositions)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Hour of Day', fontsize=12)\n",
    "        axes[0].set_ylabel('Number of Exits', fontsize=12)\n",
    "        axes[0].set_xticks(range(0, 24))\n",
    "        axes[0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        peak_exit_hour = hourly_exits.idxmax()\n",
    "        axes[0].axvline(peak_exit_hour, color='red', linestyle='--', \n",
    "                       label=f'Peak Exit Hour: {peak_exit_hour}:00 ({hourly_exits.max()} exits)')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Arrivals by hour (for comparison)\n",
    "        if 'Arrival_Hour' in df.columns:\n",
    "            hourly_arrivals = df.groupby('Arrival_Hour').size()\n",
    "            axes[1].bar(hourly_arrivals.index, hourly_arrivals.values, color='steelblue', alpha=0.7)\n",
    "            axes[1].set_title('ER Arrivals by Hour of Day (for comparison)', fontsize=14, fontweight='bold')\n",
    "            axes[1].set_xlabel('Hour of Day', fontsize=12)\n",
    "            axes[1].set_ylabel('Number of Arrivals', fontsize=12)\n",
    "            axes[1].set_xticks(range(0, 24))\n",
    "            axes[1].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            peak_arrival_hour = hourly_arrivals.idxmax()\n",
    "            axes[1].axvline(peak_arrival_hour, color='red', linestyle='--', \n",
    "                           label=f'Peak Arrival Hour: {peak_arrival_hour}:00 ({hourly_arrivals.max()} arrivals)')\n",
    "            axes[1].legend()\n",
    "            \n",
    "            # Overlay comparison\n",
    "            axes[2].plot(hourly_arrivals.index, hourly_arrivals.values, marker='o', \n",
    "                        color='steelblue', linewidth=2, markersize=8, label='Arrivals', alpha=0.7)\n",
    "            axes[2].plot(hourly_exits.index, hourly_exits.values, marker='s', \n",
    "                        color='coral', linewidth=2, markersize=8, label='Exits', alpha=0.7)\n",
    "            axes[2].set_title('ER Arrivals vs Exits by Hour of Day', fontsize=14, fontweight='bold')\n",
    "            axes[2].set_xlabel('Hour of Day', fontsize=12)\n",
    "            axes[2].set_ylabel('Number of Patients', fontsize=12)\n",
    "            axes[2].set_xticks(range(0, 24))\n",
    "            axes[2].grid(True, alpha=0.3)\n",
    "            axes[2].legend(fontsize=11)\n",
    "            \n",
    "            # Add insights\n",
    "            findings['insights'].append(f\"Peak exit hour: {peak_exit_hour}:00 with {hourly_exits.max()} exits\")\n",
    "            findings['insights'].append(f\"Peak arrival hour: {peak_arrival_hour}:00 with {hourly_arrivals.max()} arrivals\")\n",
    "            \n",
    "            # Identify hours with patient buildup (more arrivals than exits)\n",
    "            hourly_net = hourly_arrivals - hourly_exits\n",
    "            buildup_hours = hourly_net[hourly_net > 0].sort_values(ascending=False)\n",
    "            if len(buildup_hours) > 0:\n",
    "                top_buildup = buildup_hours.head(3)\n",
    "                findings['bottlenecks'].append(\n",
    "                    f\"Hours with most patient buildup: {', '.join([f'{h}:00 (+{v} net)' for h, v in top_buildup.items()])}\"\n",
    "                )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Detailed hourly analysis table\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"DETAILED HOURLY FLOW ANALYSIS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if 'Arrival_Hour' in df.columns:\n",
    "            hourly_analysis = pd.DataFrame({\n",
    "                'Hour': range(0, 24),\n",
    "                'Arrivals': [hourly_arrivals.get(h, 0) for h in range(24)],\n",
    "                'Exits': [hourly_exits.get(h, 0) for h in range(24)]\n",
    "            })\n",
    "            hourly_analysis['Net_Change'] = hourly_analysis['Arrivals'] - hourly_analysis['Exits']\n",
    "            hourly_analysis['Cumulative_Buildup'] = hourly_analysis['Net_Change'].cumsum()\n",
    "            \n",
    "            # Format hour as HH:00\n",
    "            hourly_analysis['Hour'] = hourly_analysis['Hour'].apply(lambda x: f'{x:02d}:00')\n",
    "            \n",
    "            print(\"\\nHourly Patient Flow (Arrivals vs Exits):\")\n",
    "            display(hourly_analysis)\n",
    "            \n",
    "            # Identify critical hours\n",
    "            high_net = hourly_analysis.nlargest(5, 'Net_Change')\n",
    "            print(f\"\\n\u26a0 Top 5 hours with highest patient buildup:\")\n",
    "            for idx, row in high_net.iterrows():\n",
    "                print(f\"  {row['Hour']}: +{row['Net_Change']} patients (Arrivals: {row['Arrivals']}, Exits: {row['Exits']})\")\n",
    "    else:\n",
    "        print(f\"\\n\u26a0 {discharge_col} is not a datetime column - cannot extract exit hour\")\n",
    "else:\n",
    "    print(\"\\n\u26a0 Exit/Discharge time column not found - cannot analyze exit patterns\")\n",
    "\n",
    "# Monthly/Seasonal patterns\n",
    "if 'Arrival_Month' in df.columns:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"MONTHLY/SEASONAL PATTERNS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    monthly_arrivals = df.groupby('Arrival_Month').size()\n",
    "    monthly_delays = df.groupby('Arrival_Month')['Length_of_Stay_Hours'].mean() if 'Length_of_Stay_Hours' in df.columns else None\n",
    "    \n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    if monthly_delays is not None:\n",
    "        ax1 = plt.gca()\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        ax1.bar(monthly_arrivals.index, monthly_arrivals.values, alpha=0.6, color='steelblue', label='Arrivals')\n",
    "        ax1.set_xlabel('Month', fontsize=12)\n",
    "        ax1.set_ylabel('Number of Arrivals', fontsize=12, color='steelblue')\n",
    "        ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "        ax1.set_xticks(range(1, 13))\n",
    "        ax1.set_xticklabels(month_names)\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        ax2.plot(monthly_delays.index, monthly_delays.values, marker='o', \n",
    "                color='coral', linewidth=2, markersize=8, label='Avg Delay')\n",
    "        ax2.set_ylabel('Average Length of Stay (Hours)', fontsize=12, color='coral')\n",
    "        ax2.tick_params(axis='y', labelcolor='coral')\n",
    "        \n",
    "        plt.title('Monthly Arrivals and Average Delays', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        peak_month = monthly_arrivals.idxmax()\n",
    "        worst_month = monthly_delays.idxmax()\n",
    "        findings['insights'].append(f\"Peak month: {month_names[peak_month-1]} with {monthly_arrivals.max()} arrivals\")\n",
    "        findings['delays'].append(f\"Longest delays in: {month_names[worst_month-1]} (avg: {monthly_delays.max():.1f}h)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Staffing Efficiency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAFFING EFFICIENCY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAFFING EFFICIENCY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze staffing impact on throughput and delays\n",
    "if len(staffing_cols) > 0:\n",
    "    print(f\"\\nFound staffing columns: {staffing_cols}\")\n",
    "    \n",
    "    # Analyze relationship between staffing and delays\n",
    "    if 'Length_of_Stay_Hours' in df.columns:\n",
    "        for col in staffing_cols:\n",
    "            if col in df.columns:\n",
    "                if df[col].dtype in [np.number]:\n",
    "                    # Numerical staffing metric\n",
    "                    correlation = df[col].corr(df['Length_of_Stay_Hours'])\n",
    "                    print(f\"\\n{col} correlation with Length of Stay: {correlation:.3f}\")\n",
    "                    \n",
    "                    if abs(correlation) > 0.3:\n",
    "                        findings['insights'].append(\n",
    "                            f\"Staffing metric {col} shows {'negative' if correlation < 0 else 'positive'} \"\n",
    "                            f\"correlation ({correlation:.3f}) with length of stay\"\n",
    "                        )\n",
    "                    \n",
    "                    # Visualize relationship\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    plt.scatter(df[col], df['Length_of_Stay_Hours'], alpha=0.5, s=20)\n",
    "                    plt.xlabel(col, fontsize=12)\n",
    "                    plt.ylabel('Length of Stay (Hours)', fontsize=12)\n",
    "                    plt.title(f'Staffing Impact: {col} vs Length of Stay', fontsize=14, fontweight='bold')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Add trend line\n",
    "                    z = np.polyfit(df[col].dropna(), df.loc[df[col].notna(), 'Length_of_Stay_Hours'], 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    plt.plot(df[col].dropna().sort_values(), \n",
    "                            p(df[col].dropna().sort_values()), \"r--\", alpha=0.8, linewidth=2)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                elif df[col].dtype in ['object', 'category']:\n",
    "                    # Categorical staffing (e.g., staffing level categories)\n",
    "                    if df[col].nunique() < 10:\n",
    "                        staffing_delays = df.groupby(col)['Length_of_Stay_Hours'].agg(['mean', 'median', 'count'])\n",
    "                        staffing_delays = staffing_delays.sort_values('mean', ascending=False)\n",
    "                        \n",
    "                        print(f\"\\n{col} impact on delays:\")\n",
    "                        display(staffing_delays)\n",
    "                        \n",
    "                        # Visualize\n",
    "                        plt.figure(figsize=(12, 6))\n",
    "                        staffing_delays['mean'].plot(kind='bar', color='steelblue')\n",
    "                        plt.title(f'Average Length of Stay by {col}', fontsize=14, fontweight='bold')\n",
    "                        plt.xlabel(col, fontsize=12)\n",
    "                        plt.ylabel('Average Length of Stay (Hours)', fontsize=12)\n",
    "                        plt.xticks(rotation=45, ha='right')\n",
    "                        plt.grid(True, alpha=0.3, axis='y')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        best_staffing = staffing_delays['mean'].idxmin()\n",
    "                        worst_staffing = staffing_delays['mean'].idxmax()\n",
    "                        findings['insights'].append(\n",
    "                            f\"Best performance with {col}={best_staffing} (avg: {staffing_delays.loc[best_staffing, 'mean']:.1f}h) \"\n",
    "                            f\"vs worst: {worst_staffing} ({staffing_delays.loc[worst_staffing, 'mean']:.1f}h)\"\n",
    "                        )\n",
    "else:\n",
    "    print(\"\\n\u26a0 No staffing columns found in dataset.\")\n",
    "    print(\"   If you have staffing data, ensure columns contain 'staff', 'nurse', 'doctor', etc.\")\n",
    "\n",
    "# Analyze patient-to-staff ratios (if we can calculate)\n",
    "# This would require knowing both patient volume and staff counts\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"STAFFING OPTIMIZATION OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Identify peak hours when staffing might be insufficient\n",
    "if 'Arrival_Hour' in df.columns and 'Length_of_Stay_Hours' in df.columns:\n",
    "    hourly_analysis = df.groupby('Arrival_Hour').agg({\n",
    "        'Length_of_Stay_Hours': ['mean', 'count']\n",
    "    }).round(2)\n",
    "    hourly_analysis.columns = ['Avg_Delay', 'Patient_Count']\n",
    "    hourly_analysis = hourly_analysis.sort_values('Avg_Delay', ascending=False)\n",
    "    \n",
    "    # Identify hours with high patient volume AND high delays (staffing stress)\n",
    "    hourly_analysis['Stress_Score'] = (\n",
    "        (hourly_analysis['Patient_Count'] / hourly_analysis['Patient_Count'].max()) * 0.5 +\n",
    "        (hourly_analysis['Avg_Delay'] / hourly_analysis['Avg_Delay'].max()) * 0.5\n",
    "    )\n",
    "    hourly_analysis = hourly_analysis.sort_values('Stress_Score', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 5 hours with highest staffing stress (high volume + high delays):\")\n",
    "    display(hourly_analysis.head(5))\n",
    "    \n",
    "    worst_hours = hourly_analysis.head(3).index.tolist()\n",
    "    findings['bottlenecks'].append(\n",
    "        f\"Highest staffing stress during hours: {worst_hours} \"\n",
    "        f\"(high patient volume + extended delays)\"\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.bar(hourly_analysis.index, hourly_analysis['Stress_Score'], color='coral', alpha=0.7)\n",
    "    ax.set_xlabel('Hour of Day', fontsize=12)\n",
    "    ax.set_ylabel('Staffing Stress Score', fontsize=12)\n",
    "    ax.set_title('Staffing Stress by Hour (Volume + Delay)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(0, 24))\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Throughput Analysis & Processing Times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# THROUGHPUT ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"THROUGHPUT ANALYSIS & PROCESSING TIMES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate throughput metrics\n",
    "if arrival_col and df[arrival_col].notna().any():\n",
    "    # Daily throughput\n",
    "    daily_throughput = df.groupby('Arrival_Date').size()\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"DAILY THROUGHPUT STATISTICS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average daily patients: {daily_throughput.mean():.1f}\")\n",
    "    print(f\"Median daily patients: {daily_throughput.median():.1f}\")\n",
    "    print(f\"Min daily patients: {daily_throughput.min()}\")\n",
    "    print(f\"Max daily patients: {daily_throughput.max()}\")\n",
    "    print(f\"Std deviation: {daily_throughput.std():.1f}\")\n",
    "    \n",
    "    # Visualize daily throughput\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    daily_throughput.plot(kind='line', marker='o', markersize=3, alpha=0.7)\n",
    "    plt.axhline(daily_throughput.mean(), color='red', linestyle='--', \n",
    "               label=f'Average: {daily_throughput.mean():.1f} patients/day', linewidth=2)\n",
    "    plt.title('Daily Patient Throughput', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Number of Patients', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    findings['insights'].append(f\"Average daily throughput: {daily_throughput.mean():.1f} patients (range: {daily_throughput.min()}-{daily_throughput.max()})\")\n",
    "    \n",
    "    # Identify days with unusually high/low throughput\n",
    "    threshold_high = daily_throughput.quantile(0.90)\n",
    "    threshold_low = daily_throughput.quantile(0.10)\n",
    "    \n",
    "    high_volume_days = daily_throughput[daily_throughput > threshold_high]\n",
    "    low_volume_days = daily_throughput[daily_throughput < threshold_low]\n",
    "    \n",
    "    print(f\"\\nHigh volume days (>90th percentile, {threshold_high:.0f} patients): {len(high_volume_days)} days\")\n",
    "    print(f\"Low volume days (<10th percentile, {threshold_low:.0f} patients): {len(low_volume_days)} days\")\n",
    "\n",
    "# Analyze processing efficiency\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    # Calculate efficiency metrics\n",
    "    df['Throughput_Efficiency'] = 1 / df['Length_of_Stay_Hours']  # Patients per hour\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"PROCESSING EFFICIENCY\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average throughput efficiency: {df['Throughput_Efficiency'].mean():.3f} patients/hour\")\n",
    "    print(f\"Median: {df['Throughput_Efficiency'].median():.3f} patients/hour\")\n",
    "    \n",
    "    # Identify factors affecting throughput\n",
    "    efficiency_analysis = {}\n",
    "    \n",
    "    for col in flow_cols[:5]:  # Analyze first 5 flow columns\n",
    "        if col in df.columns and df[col].nunique() < 15:\n",
    "            efficiency_by_cat = df.groupby(col)['Throughput_Efficiency'].mean().sort_values(ascending=False)\n",
    "            efficiency_analysis[col] = efficiency_by_cat\n",
    "            \n",
    "            print(f\"\\n{col} efficiency:\")\n",
    "            print(f\"  Best: {efficiency_by_cat.index[0]} ({efficiency_by_cat.iloc[0]:.3f} patients/hour)\")\n",
    "            print(f\"  Worst: {efficiency_by_cat.index[-1]} ({efficiency_by_cat.iloc[-1]:.3f} patients/hour)\")\n",
    "            \n",
    "            findings['insights'].append(\n",
    "                f\"{col}: Best throughput with {efficiency_by_cat.index[0]} \"\n",
    "                f\"({efficiency_by_cat.iloc[0]:.3f} pts/hr) vs {efficiency_by_cat.index[-1]} \"\n",
    "                f\"({efficiency_by_cat.iloc[-1]:.3f} pts/hr)\"\n",
    "            )\n",
    "\n",
    "# Waiting time analysis (if we have wait time data)\n",
    "wait_time_cols = [col for col in df.columns if 'wait' in col.lower()]\n",
    "if wait_time_cols:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"WAITING TIME ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for col in wait_time_cols:\n",
    "        if df[col].dtype in [np.number]:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "            print(f\"  Median: {df[col].median():.2f}\")\n",
    "            print(f\"  90th percentile: {df[col].quantile(0.90):.2f}\")\n",
    "            \n",
    "            # Identify excessive wait times\n",
    "            wait_threshold = df[col].quantile(0.90)\n",
    "            excessive_waits = df[df[col] > wait_threshold]\n",
    "            print(f\"  Patients with excessive waits (>90th percentile): {len(excessive_waits):,} ({len(excessive_waits)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            findings['delays'].append(\n",
    "                f\"{col}: {len(excessive_waits):,} patients ({len(excessive_waits)/len(df)*100:.1f}%) \"\n",
    "                f\"experience waits > {wait_threshold:.1f} (90th percentile)\"\n",
    "            )\n",
    "            \n",
    "            # Analyze what causes long waits\n",
    "            if len(flow_cols) > 0:\n",
    "                for flow_col in flow_cols[:3]:\n",
    "                    if flow_col in df.columns and df[flow_col].nunique() < 10:\n",
    "                        wait_by_category = df.groupby(flow_col)[col].mean().sort_values(ascending=False)\n",
    "                        worst_category = wait_by_category.index[0]\n",
    "                        findings['bottlenecks'].append(\n",
    "                            f\"Longest {col} occurs for {flow_col}={worst_category} \"\n",
    "                            f\"(avg: {wait_by_category.iloc[0]:.1f})\"\n",
    "                        )\n",
    "else:\n",
    "    print(\"\\n\u26a0 No explicit wait time columns found.\")\n",
    "    print(\"   Consider calculating wait times from time differences if you have multiple time stamps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROOT CAUSE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ROOT CAUSE ANALYSIS - PRIMARY DELAY FACTORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Correlation analysis to identify factors most strongly associated with delays\n",
    "if 'Length_of_Stay_Hours' in df.columns and len(numeric_cols) > 1:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"CORRELATION WITH LENGTH OF STAY\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = df[numeric_cols].corrwith(df['Length_of_Stay_Hours']).abs().sort_values(ascending=False)\n",
    "    correlations = correlations[correlations.index != 'Length_of_Stay_Hours']\n",
    "    \n",
    "    # Get top factors\n",
    "    top_factors = correlations.head(10)\n",
    "    \n",
    "    print(\"\\nTop factors correlated with Length of Stay:\")\n",
    "    for factor, corr in top_factors.items():\n",
    "        actual_corr = df[factor].corr(df['Length_of_Stay_Hours'])\n",
    "        direction = \"positive\" if actual_corr > 0 else \"negative\"\n",
    "        print(f\"  {factor}: {actual_corr:.3f} ({direction} correlation)\")\n",
    "        \n",
    "        if abs(actual_corr) > 0.3:\n",
    "            findings['bottlenecks'].append(\n",
    "                f\"Strong {direction} correlation ({actual_corr:.3f}) between {factor} and length of stay\"\n",
    "            )\n",
    "    \n",
    "    # Visualize top correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_factors.plot(kind='barh', color='steelblue')\n",
    "    plt.title('Top Factors Correlated with Length of Stay', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Absolute Correlation Coefficient', fontsize=12)\n",
    "    plt.ylabel('Factor', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Multivariate analysis - identify combinations of factors\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"MULTIVARIATE DELAY ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare high vs low delay patients\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    delay_threshold = df['Length_of_Stay_Hours'].quantile(0.75)  # Top 25% delays\n",
    "    \n",
    "    high_delay = df[df['Length_of_Stay_Hours'] >= delay_threshold]\n",
    "    low_delay = df[df['Length_of_Stay_Hours'] < delay_threshold]\n",
    "    \n",
    "    print(f\"\\nComparing High Delay (\u2265{delay_threshold:.1f}h, n={len(high_delay):,}) vs Low Delay (<{delay_threshold:.1f}h, n={len(low_delay):,})\")\n",
    "    \n",
    "    # Compare key metrics\n",
    "    comparison_cols = [col for col in numeric_cols if col not in ['Length_of_Stay_Hours', 'Throughput_Efficiency']][:10]\n",
    "    \n",
    "    comparison_data = []\n",
    "    for col in comparison_cols:\n",
    "        high_mean = high_delay[col].mean()\n",
    "        low_mean = low_delay[col].mean()\n",
    "        difference = high_mean - low_mean\n",
    "        pct_change = (difference / low_mean * 100) if low_mean != 0 else 0\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Factor': col,\n",
    "            'High_Delay_Mean': high_mean,\n",
    "            'Low_Delay_Mean': low_mean,\n",
    "            'Difference': difference,\n",
    "            'Pct_Change': pct_change\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df['Abs_Difference'] = comparison_df['Difference'].abs()\n",
    "    comparison_df = comparison_df.sort_values('Abs_Difference', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop Differentiating Factors:\")\n",
    "    display(comparison_df.head(10))\n",
    "    \n",
    "    # Identify key differentiators\n",
    "    top_differentiators = comparison_df.head(5)\n",
    "    for _, row in top_differentiators.iterrows():\n",
    "        findings['bottlenecks'].append(\n",
    "            f\"Key delay factor: {row['Factor']} - High delay patients have \"\n",
    "            f\"{row['High_Delay_Mean']:.2f} vs {row['Low_Delay_Mean']:.2f} \"\n",
    "            f\"(difference: {row['Difference']:.2f}, {row['Pct_Change']:.1f}% higher)\"\n",
    "        )\n",
    "\n",
    "# Categorical factor analysis\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATEGORICAL FACTOR ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    categorical_delay_factors = {}\n",
    "    \n",
    "    for col in flow_cols[:10]:  # Analyze first 10 flow columns\n",
    "        if col in df.columns and df[col].notna().any():\n",
    "            if df[col].nunique() < 20:\n",
    "                cat_delays = df.groupby(col)['Length_of_Stay_Hours'].agg(['mean', 'count'])\n",
    "                cat_delays = cat_delays[cat_delays['count'] >= 10]  # Only categories with sufficient data\n",
    "                cat_delays = cat_delays.sort_values('mean', ascending=False)\n",
    "                \n",
    "                if len(cat_delays) > 1:\n",
    "                    worst_cat = cat_delays.index[0]\n",
    "                    best_cat = cat_delays.index[-1]\n",
    "                    delay_diff = cat_delays.loc[worst_cat, 'mean'] - cat_delays.loc[best_cat, 'mean']\n",
    "                    \n",
    "                    if delay_diff > 1.0:  # More than 1 hour difference\n",
    "                        categorical_delay_factors[col] = {\n",
    "                            'worst': worst_cat,\n",
    "                            'best': best_cat,\n",
    "                            'delay_diff': delay_diff\n",
    "                        }\n",
    "                        \n",
    "                        print(f\"\\n{col}:\")\n",
    "                        print(f\"  Worst: {worst_cat} ({cat_delays.loc[worst_cat, 'mean']:.2f}h)\")\n",
    "                        print(f\"  Best: {best_cat} ({cat_delays.loc[best_cat, 'mean']:.2f}h)\")\n",
    "                        print(f\"  Difference: {delay_diff:.2f} hours\")\n",
    "                        \n",
    "                        findings['bottlenecks'].append(\n",
    "                            f\"{col}: {worst_cat} has {delay_diff:.1f}h longer delays than {best_cat}\"\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Actionable Solutions & Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ACTIONABLE SOLUTIONS & RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ACTIONABLE SOLUTIONS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Generate recommendations based on findings\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRIORITY RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Staffing recommendations\n",
    "if 'Arrival_Hour' in df.columns and 'Length_of_Stay_Hours' in df.columns:\n",
    "    hourly_analysis = df.groupby('Arrival_Hour').agg({\n",
    "        'Length_of_Stay_Hours': 'mean',\n",
    "        'Arrival_Hour': 'count'\n",
    "    })\n",
    "    hourly_analysis.columns = ['Avg_Delay', 'Patient_Count']\n",
    "    \n",
    "    # Identify peak stress hours\n",
    "    stress_hours = hourly_analysis[\n",
    "        (hourly_analysis['Patient_Count'] > hourly_analysis['Patient_Count'].quantile(0.75)) &\n",
    "        (hourly_analysis['Avg_Delay'] > hourly_analysis['Avg_Delay'].quantile(0.75))\n",
    "    ].index.tolist()\n",
    "    \n",
    "    if stress_hours:\n",
    "        rec = f\"\ud83d\udccb STAFFING: Increase staffing during peak stress hours: {stress_hours}. \" \\\n",
    "              f\"These hours show both high patient volume and extended delays.\"\n",
    "        recommendations.append(rec)\n",
    "        print(f\"1. {rec}\")\n",
    "\n",
    "# 2. Day of week recommendations\n",
    "if 'Day_Name' in df.columns and 'Length_of_Stay_Hours' in df.columns:\n",
    "    daily_delays = df.groupby('Day_Name')['Length_of_Stay_Hours'].mean()\n",
    "    worst_day = daily_delays.idxmax()\n",
    "    \n",
    "    if daily_delays[worst_day] > daily_delays.mean() * 1.15:  # 15% above average\n",
    "        rec = f\"\ud83d\udccb SCHEDULING: {worst_day} shows {daily_delays[worst_day]:.1f}h average delays \" \\\n",
    "              f\"({daily_delays.mean():.1f}h overall). Consider increasing resources on {worst_day}s.\"\n",
    "        recommendations.append(rec)\n",
    "        print(f\"2. {rec}\")\n",
    "\n",
    "# 3. Process improvement recommendations\n",
    "if len(findings['bottlenecks']) > 0:\n",
    "    # Identify most common bottleneck\n",
    "    bottleneck_keywords = {}\n",
    "    for bottleneck in findings['bottlenecks']:\n",
    "        # Extract key terms\n",
    "        for word in bottleneck.split():\n",
    "            if word not in ['the', 'a', 'an', 'and', 'or', 'with', 'has', 'have', 'is', 'are']:\n",
    "                bottleneck_keywords[word] = bottleneck_keywords.get(word, 0) + 1\n",
    "    \n",
    "    rec = f\"\ud83d\udccb PROCESS: Address top bottleneck factors identified in analysis. \" \\\n",
    "          f\"Focus on categories showing >1 hour delay differences.\"\n",
    "    recommendations.append(rec)\n",
    "    print(f\"3. {rec}\")\n",
    "\n",
    "# 4. Throughput optimization\n",
    "if 'Throughput_Efficiency' in df.columns:\n",
    "    avg_efficiency = df['Throughput_Efficiency'].mean()\n",
    "    if avg_efficiency < 0.5:  # Less than 0.5 patients per hour\n",
    "        rec = f\"\ud83d\udccb THROUGHPUT: Current efficiency is {avg_efficiency:.3f} patients/hour. \" \\\n",
    "              f\"Target improvement to >0.5 patients/hour through process optimization.\"\n",
    "        recommendations.append(rec)\n",
    "        print(f\"4. {rec}\")\n",
    "\n",
    "# 5. Delay reduction targets\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    current_avg = df['Length_of_Stay_Hours'].mean()\n",
    "    current_median = df['Length_of_Stay_Hours'].median()\n",
    "    p90_delay = df['Length_of_Stay_Hours'].quantile(0.90)\n",
    "    \n",
    "    target_avg = current_avg * 0.85  # 15% reduction target\n",
    "    target_median = current_median * 0.85\n",
    "    \n",
    "    rec = f\"\ud83d\udccb TARGET: Reduce average length of stay from {current_avg:.1f}h to {target_avg:.1f}h \" \\\n",
    "          f\"(15% reduction). Current 90th percentile: {p90_delay:.1f}h.\"\n",
    "    recommendations.append(rec)\n",
    "    print(f\"5. {rec}\")\n",
    "\n",
    "# 6. Resource allocation\n",
    "if 'Arrival_Hour' in df.columns:\n",
    "    hourly_arrivals = df.groupby('Arrival_Hour').size()\n",
    "    peak_hours = hourly_arrivals[hourly_arrivals > hourly_arrivals.quantile(0.80)].index.tolist()\n",
    "    \n",
    "    rec = f\"\ud83d\udccb RESOURCES: Optimize resource allocation for peak arrival hours: {peak_hours}. \" \\\n",
    "          f\"Consider cross-training staff for flexibility during peak times.\"\n",
    "    recommendations.append(rec)\n",
    "    print(f\"6. {rec}\")\n",
    "\n",
    "# Add custom recommendations based on specific findings\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ADDITIONAL RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "additional_recs = [\n",
    "    \"\ud83d\udccb MONITORING: Implement real-time dashboards to track patient flow and identify bottlenecks as they occur\",\n",
    "    \"\ud83d\udccb TRIAGE: Review triage protocols for categories showing longest delays - consider protocol optimization\",\n",
    "    \"\ud83d\udccb CAPACITY: Analyze physical capacity constraints during peak hours - may need additional beds/rooms\",\n",
    "    \"\ud83d\udccb TECHNOLOGY: Consider technology solutions (e.g., automated scheduling, queue management) to improve efficiency\",\n",
    "    \"\ud83d\udccb TRAINING: Provide staff training on efficiency best practices, especially for high-delay categories\"\n",
    "]\n",
    "\n",
    "for rec in additional_recs:\n",
    "    recommendations.append(rec)\n",
    "    print(f\"\u2022 {rec}\")\n",
    "\n",
    "# Store recommendations\n",
    "findings['recommendations'] = recommendations\n",
    "\n",
    "# ============================================================================\n",
    "# IMPACT ESTIMATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTIMATED IMPACT OF RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    current_avg = df['Length_of_Stay_Hours'].mean()\n",
    "    current_p90 = df['Length_of_Stay_Hours'].quantile(0.90)\n",
    "    \n",
    "    # Estimate improvements\n",
    "    improvements = {\n",
    "        \"15% reduction in average LOS\": {\n",
    "            \"current\": current_avg,\n",
    "            \"target\": current_avg * 0.85,\n",
    "            \"savings_per_patient\": current_avg * 0.15,\n",
    "            \"annual_impact\": f\"{(current_avg * 0.15 * len(df) / (len(df) / 365)).sum():.0f} patient-hours saved/year\"\n",
    "        },\n",
    "        \"20% reduction in 90th percentile\": {\n",
    "            \"current\": current_p90,\n",
    "            \"target\": current_p90 * 0.80,\n",
    "            \"savings_per_patient\": current_p90 * 0.20\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPotential Impact:\")\n",
    "    for improvement, metrics in improvements.items():\n",
    "        print(f\"\\n{improvement}:\")\n",
    "        print(f\"  Current: {metrics['current']:.2f} hours\")\n",
    "        print(f\"  Target: {metrics['target']:.2f} hours\")\n",
    "        print(f\"  Savings per patient: {metrics['savings_per_patient']:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Executive Summary & Final Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTIVE SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTIVE SUMMARY - ER OPERATIONS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Generate comprehensive summary\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "summary = f\"\"\"\n",
    "ER OPERATIONS ANALYSIS REPORT\n",
    "Meridian City Hospital\n",
    "Generated: {timestamp}\n",
    "========================================\n",
    "\n",
    "DATASET OVERVIEW\n",
    "----------------\n",
    "Total Records: {df.shape[0]:,}\n",
    "Analysis Period: {df['Arrival_Date'].min() if 'Arrival_Date' in df.columns else 'N/A'} to {df['Arrival_Date'].max() if 'Arrival_Date' in df.columns else 'N/A'}\n",
    "\"\"\"\n",
    "\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    summary += f\"\"\"\n",
    "KEY METRICS\n",
    "-----------\n",
    "Average Length of Stay: {df['Length_of_Stay_Hours'].mean():.2f} hours\n",
    "Median Length of Stay: {df['Length_of_Stay_Hours'].median():.2f} hours\n",
    "90th Percentile: {df['Length_of_Stay_Hours'].quantile(0.90):.2f} hours\n",
    "Maximum: {df['Length_of_Stay_Hours'].max():.2f} hours\n",
    "\n",
    "Delay Distribution:\n",
    "\"\"\"\n",
    "\n",
    "    if 'Delay_Category' in df.columns:\n",
    "        delay_dist = df['Delay_Category'].value_counts()\n",
    "        for category, count in delay_dist.items():\n",
    "            pct = (count / len(df)) * 100\n",
    "            summary += f\"  {category}: {count:,} patients ({pct:.1f}%)\\n\"\n",
    "\n",
    "summary += f\"\"\"\n",
    "PRIMARY FINDINGS\n",
    "----------------\n",
    "\"\"\"\n",
    "\n",
    "summary += \"\\nDELAYS IDENTIFIED:\\n\"\n",
    "for i, delay in enumerate(findings['delays'][:10], 1):\n",
    "    summary += f\"  {i}. {delay}\\n\"\n",
    "\n",
    "summary += \"\\nBOTTLENECKS IDENTIFIED:\\n\"\n",
    "for i, bottleneck in enumerate(findings['bottlenecks'][:10], 1):\n",
    "    summary += f\"  {i}. {bottleneck}\\n\"\n",
    "\n",
    "summary += \"\\nKEY INSIGHTS:\\n\"\n",
    "for i, insight in enumerate(findings['insights'][:10], 1):\n",
    "    summary += f\"  {i}. {insight}\\n\"\n",
    "\n",
    "summary += f\"\"\"\n",
    "PRIORITY RECOMMENDATIONS\n",
    "------------------------\n",
    "\"\"\"\n",
    "\n",
    "for i, rec in enumerate(recommendations[:15], 1):\n",
    "    summary += f\"{i}. {rec}\\n\"\n",
    "\n",
    "summary += f\"\"\"\n",
    "NEXT STEPS\n",
    "----------\n",
    "1. Review recommendations with ER leadership team\n",
    "2. Prioritize recommendations based on impact and feasibility\n",
    "3. Develop implementation plans for top 3-5 recommendations\n",
    "4. Establish baseline metrics and KPIs for tracking improvement\n",
    "5. Implement monitoring dashboards for ongoing performance tracking\n",
    "6. Schedule follow-up analysis in 3-6 months to measure impact\n",
    "\n",
    "EXPECTED OUTCOMES\n",
    "-----------------\n",
    "- Reduced average length of stay by 15-20%\n",
    "- Improved patient satisfaction through reduced wait times\n",
    "- Better staff utilization and efficiency\n",
    "- Enhanced ER throughput capacity\n",
    "- Data-driven operational decision making\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save report to file\n",
    "report_file = 'er_operations_analysis_report.txt'\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\n\u2713 Full report saved to: {report_file}\")\n",
    "\n",
    "# Create summary visualization\n",
    "if 'Length_of_Stay_Hours' in df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Delay distribution\n",
    "    if 'Delay_Category' in df.columns:\n",
    "        delay_dist = df['Delay_Category'].value_counts().sort_index()\n",
    "        axes[0, 0].bar(range(len(delay_dist)), delay_dist.values, color='coral', alpha=0.7)\n",
    "        axes[0, 0].set_title('Delay Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_xticks(range(len(delay_dist)))\n",
    "        axes[0, 0].set_xticklabels(delay_dist.index, rotation=45, ha='right')\n",
    "        axes[0, 0].set_ylabel('Number of Patients')\n",
    "        axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. Hourly patterns\n",
    "    if 'Arrival_Hour' in df.columns:\n",
    "        hourly_delays = df.groupby('Arrival_Hour')['Length_of_Stay_Hours'].mean()\n",
    "        axes[0, 1].plot(hourly_delays.index, hourly_delays.values, marker='o', color='steelblue', linewidth=2)\n",
    "        axes[0, 1].set_title('Average Delay by Hour', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Hour of Day')\n",
    "        axes[0, 1].set_ylabel('Average Length of Stay (Hours)')\n",
    "        axes[0, 1].set_xticks(range(0, 24, 2))\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Day of week patterns\n",
    "    if 'Day_Name' in df.columns:\n",
    "        daily_delays = df.groupby('Day_Name')['Length_of_Stay_Hours'].mean()\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        daily_delays_ordered = daily_delays.reindex([d for d in day_order if d in daily_delays.index])\n",
    "        axes[1, 0].bar(range(len(daily_delays_ordered)), daily_delays_ordered.values, color='steelblue', alpha=0.7)\n",
    "        axes[1, 0].set_title('Average Delay by Day of Week', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].set_xticks(range(len(daily_delays_ordered)))\n",
    "        axes[1, 0].set_xticklabels(daily_delays_ordered.index, rotation=45, ha='right')\n",
    "        axes[1, 0].set_ylabel('Average Length of Stay (Hours)')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Throughput trend\n",
    "    if 'Arrival_Date' in df.columns:\n",
    "        daily_throughput = df.groupby('Arrival_Date').size()\n",
    "        axes[1, 1].plot(daily_throughput.index, daily_throughput.values, alpha=0.7, color='green')\n",
    "        axes[1, 1].axhline(daily_throughput.mean(), color='red', linestyle='--', \n",
    "                          label=f'Average: {daily_throughput.mean():.1f}')\n",
    "        axes[1, 1].set_title('Daily Patient Throughput', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Date')\n",
    "        axes[1, 1].set_ylabel('Number of Patients')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.suptitle('ER Operations Analysis - Key Metrics Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\u2705 ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nKey Deliverables:\")\n",
    "print(\"  1. Detailed analysis with visualizations\")\n",
    "print(\"  2. Executive summary report\")\n",
    "print(\"  3. Priority recommendations\")\n",
    "print(\"  4. Identified bottlenecks and delay causes\")\n",
    "print(\"  5. Actionable solutions for improvement\")\n",
    "print(\"\\nNext: Review findings with team and prioritize implementation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}