{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All packages available!\n"
          ]
        }
      ],
      "source": [
        "import pandas, numpy, matplotlib, seaborn, scipy\n",
        "print(\"âœ“ All packages available!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datathon EDA Template\n",
        "\n",
        "**Team Name:** ACM\n",
        "**Date:** 11/06/2024 \n",
        "**Competition:** Alteryx Datathon \n",
        "**Dataset:** Meridian City Hospital ER \n",
        "\n",
        "---\n",
        "\n",
        "## Team Workflow Strategy\n",
        "\n",
        "**Phase 1 (0-15 min): Together**\n",
        "- Run Sections 0 & 1 as a team\n",
        "- Discuss problem context and target variable\n",
        "- Align on objectives\n",
        "\n",
        "**Phase 2 (15-45 min): Parallel Work**\n",
        "- **Member 1:** Sections 2 & 3 (Data quality and univariate analysis)\n",
        "- **Member 2:** Section 4 (Bivariate relationships)\n",
        "- **Member 3:** Section 5 (Multivariate patterns and modeling prep)\n",
        "\n",
        "**Phase 3 (45-60 min): Together**\n",
        "- Share findings (5 min each)\n",
        "- Section 6: Brainstorm features together\n",
        "- Section 7: Plan modeling strategy\n",
        "- Assign next tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0: Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Section 0: Setup & Imports completed\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Visualization settings\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Initialize findings dictionary for systematic documentation\n",
        "findings = {\n",
        "    'data_quality_issues': [],\n",
        "    'key_insights': [],\n",
        "    'feature_ideas': [],\n",
        "    'questions_for_team': [],\n",
        "    'next_steps': []\n",
        "}\n",
        "\n",
        "print(\"âœ“ Section 0: Setup & Imports completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Load Multiple Datasets & Initial Inspection\n",
        "\n",
        "**Team Activity:** Run together and discuss problem context\n",
        "\n",
        "**Dataset:** Meridian City Hospital ER Data (5 related CSV files)\n",
        "\n",
        "**Approach for Multiple Datasets:**\n",
        "1. Load all datasets first\n",
        "2. Understand relationships between datasets\n",
        "3. Perform EDA on each dataset individually\n",
        "4. Analyze relationships across datasets\n",
        "5. Merge/join datasets if needed for analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading all datasets...\n",
            "================================================================================\n",
            "âœ“ Loaded: Hospital_Facility.csv\n",
            "âœ“ Loaded: Hospital_Outcomes.csv\n",
            "âœ“ Loaded: Hospital_Patients.csv\n",
            "âœ“ Loaded: Hospital_Staffing_EAST_LOCATION.csv\n",
            "âœ“ Loaded: Hospital_Visits.csv\n",
            "\n",
            "âœ“ Successfully loaded 5 datasets\n",
            "\n",
            "================================================================================\n",
            "DATASET OVERVIEW - ALL FILES\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Rows</th>\n",
              "      <th>Columns</th>\n",
              "      <th>Memory (MB)</th>\n",
              "      <th>Numerical Cols</th>\n",
              "      <th>Categorical Cols</th>\n",
              "      <th>Datetime Cols</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>facility</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outcomes</td>\n",
              "      <td>15000</td>\n",
              "      <td>3</td>\n",
              "      <td>1.723758</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>patients</td>\n",
              "      <td>4500</td>\n",
              "      <td>4</td>\n",
              "      <td>0.775288</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>staffing</td>\n",
              "      <td>270</td>\n",
              "      <td>6</td>\n",
              "      <td>0.037127</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>visits</td>\n",
              "      <td>18000</td>\n",
              "      <td>11</td>\n",
              "      <td>11.648685</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset   Rows  Columns  Memory (MB)  Numerical Cols  Categorical Cols  \\\n",
              "0  facility      2        6     0.000433               4                 2   \n",
              "1  outcomes  15000        3     1.723758               1                 2   \n",
              "2  patients   4500        4     0.775288               1                 3   \n",
              "3  staffing    270        6     0.037127               4                 2   \n",
              "4    visits  18000       11    11.648685               0                11   \n",
              "\n",
              "   Datetime Cols  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COLUMN INFORMATION - ALL DATASETS\n",
            "================================================================================\n",
            "\n",
            "FACILITY (6 columns):\n",
            "   1. Hospital ID                    (object)\n",
            "   2. Hospital Name                  (object)\n",
            "   3. Facility Size (Beds)           (int64)\n",
            "   4. ICU Beds                       (int64)\n",
            "   5. Fast Track Beds                (int64)\n",
            "   6. Regular Beds                   (int64)\n",
            "\n",
            "OUTCOMES (3 columns):\n",
            "   1. Visit ID                       (object)\n",
            "   2. Disposition                    (object)\n",
            "   3. Patient Satisfaction           (int64)\n",
            "\n",
            "PATIENTS (4 columns):\n",
            "   1. Patient ID                     (object)\n",
            "   2. Age                            (int64)\n",
            "   3. Gender                         (object)\n",
            "   4. Insurance                      (object)\n",
            "\n",
            "STAFFING (6 columns):\n",
            "   1. Date                           (object)\n",
            "   2. Shift                          (object)\n",
            "   3. Nurses On Duty                 (int64)\n",
            "   4. Doctors On Duty                (int64)\n",
            "   5. Specialists On Call            (int64)\n",
            "   6. Fast Track Beds                (int64)\n",
            "\n",
            "VISITS (11 columns):\n",
            "   1. Visit ID                       (object)\n",
            "   2. Patient ID                     (object)\n",
            "   3. Arrival Time                   (object)\n",
            "   4. Registration Start             (object)\n",
            "   5. Registration End               (object)\n",
            "   6. Triage Start                   (object)\n",
            "   7. Triage End                     (object)\n",
            "   8. Doctor Seen                    (object)\n",
            "   9. Exit Time                      (object)\n",
            "  10. Triage Level                   (object)\n",
            "  11. Hospital ID                    (object)\n",
            "\n",
            "================================================================================\n",
            "FIRST 3 ROWS OF EACH DATASET\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "FACILITY\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hospital ID</th>\n",
              "      <th>Hospital Name</th>\n",
              "      <th>Facility Size (Beds)</th>\n",
              "      <th>ICU Beds</th>\n",
              "      <th>Fast Track Beds</th>\n",
              "      <th>Regular Beds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MC_ER_EAST</td>\n",
              "      <td>Meridian City ER East</td>\n",
              "      <td>100</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MC_ER_WEST</td>\n",
              "      <td>Meridian City ER West</td>\n",
              "      <td>80</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Hospital ID          Hospital Name  Facility Size (Beds)  ICU Beds  \\\n",
              "0  MC_ER_EAST  Meridian City ER East                   100        20   \n",
              "1  MC_ER_WEST  Meridian City ER West                    80        15   \n",
              "\n",
              "   Fast Track Beds  Regular Beds  \n",
              "0               10            70  \n",
              "1                8            55  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape: 2 rows Ã— 6 columns\n",
            "\n",
            "================================================================================\n",
            "OUTCOMES\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Visit ID</th>\n",
              "      <th>Disposition</th>\n",
              "      <th>Patient Satisfaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>V100000</td>\n",
              "      <td>Discharged</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>V100001</td>\n",
              "      <td>Discharged</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>V100002</td>\n",
              "      <td>Discharged</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Visit ID Disposition  Patient Satisfaction\n",
              "0  V100000  Discharged                     4\n",
              "1  V100001  Discharged                     4\n",
              "2  V100002  Discharged                     4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape: 15,000 rows Ã— 3 columns\n",
            "\n",
            "================================================================================\n",
            "PATIENTS\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MC180325-0001</td>\n",
              "      <td>9</td>\n",
              "      <td>Female</td>\n",
              "      <td>Private</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MC180325-0002</td>\n",
              "      <td>77</td>\n",
              "      <td>Female</td>\n",
              "      <td>Private</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MC180325-0003</td>\n",
              "      <td>65</td>\n",
              "      <td>Male</td>\n",
              "      <td>Medicaid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Patient ID  Age  Gender Insurance\n",
              "0  MC180325-0001    9  Female   Private\n",
              "1  MC180325-0002   77  Female   Private\n",
              "2  MC180325-0003   65    Male  Medicaid"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape: 4,500 rows Ã— 4 columns\n",
            "\n",
            "================================================================================\n",
            "STAFFING\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Shift</th>\n",
              "      <th>Nurses On Duty</th>\n",
              "      <th>Doctors On Duty</th>\n",
              "      <th>Specialists On Call</th>\n",
              "      <th>Fast Track Beds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2025</td>\n",
              "      <td>Day</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2025</td>\n",
              "      <td>Evening</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2025</td>\n",
              "      <td>NIGHT</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Shift  Nurses On Duty  Doctors On Duty  Specialists On Call  \\\n",
              "0  1/1/2025      Day               7                4                    3   \n",
              "1  1/1/2025  Evening               7                4                    2   \n",
              "2  1/1/2025    NIGHT               7                2                    3   \n",
              "\n",
              "   Fast Track Beds  \n",
              "0                6  \n",
              "1                3  \n",
              "2                4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape: 270 rows Ã— 6 columns\n",
            "\n",
            "================================================================================\n",
            "VISITS\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Visit ID</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Arrival Time</th>\n",
              "      <th>Registration Start</th>\n",
              "      <th>Registration End</th>\n",
              "      <th>Triage Start</th>\n",
              "      <th>Triage End</th>\n",
              "      <th>Doctor Seen</th>\n",
              "      <th>Exit Time</th>\n",
              "      <th>Triage Level</th>\n",
              "      <th>Hospital ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W112965</td>\n",
              "      <td>MC180325-1393</td>\n",
              "      <td>3/9/2025 3:44</td>\n",
              "      <td>3/9/2025 3:38</td>\n",
              "      <td>Mar 09 2025 03:21</td>\n",
              "      <td>2025-03-09T03:27</td>\n",
              "      <td>3/9/2025 3:40</td>\n",
              "      <td>3/9/2025 4:17</td>\n",
              "      <td>3/9/2025 6:26</td>\n",
              "      <td>moderate</td>\n",
              "      <td>MC_ER_WEST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W113095</td>\n",
              "      <td>MC180325-1007</td>\n",
              "      <td>3/8/2025 4:01</td>\n",
              "      <td>3/8/2025 5:05</td>\n",
              "      <td>Mar 08 2025 04:28</td>\n",
              "      <td>2025-03-08T04:32</td>\n",
              "      <td>3/8/2025 4:55</td>\n",
              "      <td>3/8/2025 4:39</td>\n",
              "      <td>3/8/2025 8:10</td>\n",
              "      <td>2</td>\n",
              "      <td>MC_ER_WEST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W106220</td>\n",
              "      <td>MC180325-1088</td>\n",
              "      <td>2/7/2025 15:22</td>\n",
              "      <td>2/7/2025 15:08</td>\n",
              "      <td>Feb 07 2025 15:54</td>\n",
              "      <td>2025-02-07T16:01</td>\n",
              "      <td>2/7/2025 16:17</td>\n",
              "      <td>2/7/2025 15:58</td>\n",
              "      <td>2/7/2025 19:33</td>\n",
              "      <td>1</td>\n",
              "      <td>MC_ER_WEST</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Visit ID     Patient ID    Arrival Time Registration Start  \\\n",
              "0  W112965  MC180325-1393   3/9/2025 3:44      3/9/2025 3:38   \n",
              "1  W113095  MC180325-1007   3/8/2025 4:01      3/8/2025 5:05   \n",
              "2  W106220  MC180325-1088  2/7/2025 15:22     2/7/2025 15:08   \n",
              "\n",
              "    Registration End      Triage Start      Triage End     Doctor Seen  \\\n",
              "0  Mar 09 2025 03:21  2025-03-09T03:27   3/9/2025 3:40   3/9/2025 4:17   \n",
              "1  Mar 08 2025 04:28  2025-03-08T04:32   3/8/2025 4:55   3/8/2025 4:39   \n",
              "2  Feb 07 2025 15:54  2025-02-07T16:01  2/7/2025 16:17  2/7/2025 15:58   \n",
              "\n",
              "        Exit Time Triage Level Hospital ID  \n",
              "0   3/9/2025 6:26     moderate  MC_ER_WEST  \n",
              "1   3/8/2025 8:10            2  MC_ER_WEST  \n",
              "2  2/7/2025 19:33            1  MC_ER_WEST  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape: 18,000 rows Ã— 11 columns\n",
            "\n",
            "================================================================================\n",
            "IDENTIFYING COMMON COLUMNS (POTENTIAL JOIN KEYS)\n",
            "================================================================================\n",
            "\n",
            "Common columns across datasets:\n",
            "\n",
            "facility <-> staffing:\n",
            "  â€¢ Fast Track Beds\n",
            "\n",
            "facility <-> visits:\n",
            "  â€¢ Hospital ID\n",
            "\n",
            "outcomes <-> visits:\n",
            "  â€¢ Visit ID\n",
            "\n",
            "patients <-> visits:\n",
            "  â€¢ Patient ID\n",
            "\n",
            "âœ“ Section 1: Load Multiple Datasets & Initial Inspection completed\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 1.1 LOAD ALL DATASETS\n",
        "# ============================================================================\n",
        "\n",
        "data_path = 'Meridian_City_Hospital_Data/'\n",
        "\n",
        "# Load all 5 datasets\n",
        "print(\"Loading all datasets...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "# Load each dataset\n",
        "try:\n",
        "    datasets['facility'] = pd.read_csv(data_path + 'Hospital_Facility.csv')\n",
        "    print(\"âœ“ Loaded: Hospital_Facility.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading Hospital_Facility.csv: {e}\")\n",
        "\n",
        "try:\n",
        "    datasets['outcomes'] = pd.read_csv(data_path + 'Hospital_Outcomes.csv')\n",
        "    print(\"âœ“ Loaded: Hospital_Outcomes.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading Hospital_Outcomes.csv: {e}\")\n",
        "\n",
        "try:\n",
        "    datasets['patients'] = pd.read_csv(data_path + 'Hospital_Patients.csv')\n",
        "    print(\"âœ“ Loaded: Hospital_Patients.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading Hospital_Patients.csv: {e}\")\n",
        "\n",
        "try:\n",
        "    datasets['staffing'] = pd.read_csv(data_path + 'Hospital_Staffing_EAST_LOCATION.csv')\n",
        "    print(\"âœ“ Loaded: Hospital_Staffing_EAST_LOCATION.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading Hospital_Staffing_EAST_LOCATION.csv: {e}\")\n",
        "\n",
        "try:\n",
        "    datasets['visits'] = pd.read_csv(data_path + 'Hospital_Visits.csv')\n",
        "    print(\"âœ“ Loaded: Hospital_Visits.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading Hospital_Visits.csv: {e}\")\n",
        "\n",
        "print(f\"\\nâœ“ Successfully loaded {len(datasets)} datasets\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1.2 DATASET OVERVIEW - ALL DATASETS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATASET OVERVIEW - ALL FILES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dataset_summary = []\n",
        "for name, df in datasets.items():\n",
        "    dataset_summary.append({\n",
        "        'Dataset': name,\n",
        "        'Rows': df.shape[0],\n",
        "        'Columns': df.shape[1],\n",
        "        'Memory (MB)': df.memory_usage(deep=True).sum() / 1024**2,\n",
        "        'Numerical Cols': len(df.select_dtypes(include=[np.number]).columns),\n",
        "        'Categorical Cols': len(df.select_dtypes(include=['object', 'category']).columns),\n",
        "        'Datetime Cols': len(df.select_dtypes(include=['datetime64']).columns)\n",
        "    })\n",
        "    \n",
        "    # Document initial observations\n",
        "    findings['key_insights'].append(\n",
        "        f\"{name}: {df.shape[0]:,} rows Ã— {df.shape[1]} columns \"\n",
        "        f\"({df.memory_usage(deep=True).sum() / 1024**2:.2f} MB)\"\n",
        "    )\n",
        "\n",
        "summary_df = pd.DataFrame(dataset_summary)\n",
        "display(summary_df)\n",
        "\n",
        "# ============================================================================\n",
        "# 1.3 COLUMN INFORMATION - ALL DATASETS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COLUMN INFORMATION - ALL DATASETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{name.upper()} ({len(df.columns)} columns):\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        dtype = str(df[col].dtype)\n",
        "        print(f\"  {i:2d}. {col:<30} ({dtype})\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1.4 FIRST FEW ROWS OF EACH DATASET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FIRST 3 ROWS OF EACH DATASET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{name.upper()}\")\n",
        "    print(\"=\"*80)\n",
        "    display(df.head(3))\n",
        "    print(f\"\\nShape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1.5 IDENTIFY COMMON COLUMNS (POTENTIAL JOIN KEYS)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"IDENTIFYING COMMON COLUMNS (POTENTIAL JOIN KEYS)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get all column names from all datasets\n",
        "all_columns = {}\n",
        "for name, df in datasets.items():\n",
        "    all_columns[name] = set(df.columns)\n",
        "\n",
        "# Find common columns\n",
        "print(\"\\nCommon columns across datasets:\")\n",
        "common_columns = {}\n",
        "dataset_names = list(datasets.keys())\n",
        "\n",
        "for i, name1 in enumerate(dataset_names):\n",
        "    for name2 in dataset_names[i+1:]:\n",
        "        common = all_columns[name1] & all_columns[name2]\n",
        "        if common:\n",
        "            key = f\"{name1} <-> {name2}\"\n",
        "            common_columns[key] = common\n",
        "            print(f\"\\n{key}:\")\n",
        "            for col in sorted(common):\n",
        "                print(f\"  â€¢ {col}\")\n",
        "                findings['key_insights'].append(f\"Common column '{col}' found in {name1} and {name2} (potential join key)\")\n",
        "\n",
        "if not common_columns:\n",
        "    print(\"  No common columns found. Datasets may need to be joined differently.\")\n",
        "    findings['questions_for_team'].append(\"How are these datasets related? What are the join keys?\")\n",
        "\n",
        "print(\"\\nâœ“ Section 1: Load Multiple Datasets & Initial Inspection completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.5: Dataset Relationships & Selection Helper\n",
        "\n",
        "**Team Activity:** Understand how datasets relate before deep analysis\n",
        "\n",
        "**Strategy:**\n",
        "- Analyze relationships between datasets\n",
        "- Identify join keys\n",
        "- Select which dataset(s) to analyze in detail\n",
        "- Decide if you need merged datasets for analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATASET RELATIONSHIP ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Analyzing potential relationships...\n",
            "\n",
            "Potential ID/Key columns in each dataset:\n",
            "\n",
            "FACILITY:\n",
            "  â€¢ Hospital ID: 2 unique values / 2 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "  â€¢ Hospital Name: 2 unique values / 2 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "  â€¢ Facility Size (Beds): 2 unique values / 2 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "\n",
            "OUTCOMES:\n",
            "  â€¢ Visit ID: 15,000 unique values / 15,000 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "  â€¢ Patient Satisfaction: 5 unique values / 15,000 total\n",
            "\n",
            "PATIENTS:\n",
            "  â€¢ Patient ID: 4,500 unique values / 4,500 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "\n",
            "VISITS:\n",
            "  â€¢ Visit ID: 18,000 unique values / 18,000 total\n",
            "    âœ“ Primary key candidate (all unique)\n",
            "  â€¢ Patient ID: 4,329 unique values / 18,000 total\n",
            "  â€¢ Hospital ID: 2 unique values / 18,000 total\n",
            "\n",
            "================================================================================\n",
            "DATASET MERGING GUIDANCE\n",
            "================================================================================\n",
            "\n",
            "ðŸ’¡ TIP: Before merging, identify the correct join keys.\n",
            "   Common relationships in hospital data:\n",
            "   - Patients <-> Visits (Patient ID)\n",
            "   - Visits <-> Outcomes (Visit ID)\n",
            "   - Visits <-> Facility (Facility ID)\n",
            "   - Staffing <-> Facility (Location/Facility ID)\n",
            "\n",
            "================================================================================\n",
            "SELECT DATASET FOR DETAILED ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Available datasets:\n",
            "  1. facility: 2 rows Ã— 6 columns\n",
            "  2. outcomes: 15,000 rows Ã— 3 columns\n",
            "  3. patients: 4,500 rows Ã— 4 columns\n",
            "  4. staffing: 270 rows Ã— 6 columns\n",
            "  5. visits: 18,000 rows Ã— 11 columns\n",
            "\n",
            "ðŸ’¡ INSTRUCTIONS:\n",
            "   1. Choose which dataset(s) to analyze in detail\n",
            "   2. Set 'current_dataset' to the dataset name below\n",
            "   3. Sections 2-5 will analyze the selected dataset\n",
            "   4. Repeat for other datasets as needed\n",
            "\n",
            "âœ“ Selected dataset for detailed analysis: visits\n",
            "  Shape: 18,000 rows Ã— 11 columns\n",
            "\n",
            "âœ“ Section 1.5: Dataset Relationships & Selection completed\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 1.5.1 DATASET RELATIONSHIP ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DATASET RELATIONSHIP ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check for potential ID columns that might link datasets\n",
        "print(\"\\nAnalyzing potential relationships...\")\n",
        "\n",
        "# Common ID patterns\n",
        "id_patterns = ['id', 'ID', 'Id', '_id', 'key', 'Key', 'code', 'Code', \n",
        "               'patient', 'Patient', 'visit', 'Visit', 'facility', 'Facility',\n",
        "               'hospital', 'Hospital', 'staff', 'Staff']\n",
        "\n",
        "print(\"\\nPotential ID/Key columns in each dataset:\")\n",
        "for name, df in datasets.items():\n",
        "    potential_ids = [col for col in df.columns if any(pattern in col for pattern in id_patterns)]\n",
        "    if potential_ids:\n",
        "        print(f\"\\n{name.upper()}:\")\n",
        "        for col in potential_ids:\n",
        "            unique_count = df[col].nunique()\n",
        "            total_count = len(df)\n",
        "            print(f\"  â€¢ {col}: {unique_count:,} unique values / {total_count:,} total\")\n",
        "            if unique_count == total_count:\n",
        "                print(f\"    âœ“ Primary key candidate (all unique)\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1.5.2 CREATE MERGED DATASET (OPTIONAL)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATASET MERGING GUIDANCE\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nðŸ’¡ TIP: Before merging, identify the correct join keys.\")\n",
        "print(\"   Common relationships in hospital data:\")\n",
        "print(\"   - Patients <-> Visits (Patient ID)\")\n",
        "print(\"   - Visits <-> Outcomes (Visit ID)\")\n",
        "print(\"   - Visits <-> Facility (Facility ID)\")\n",
        "print(\"   - Staffing <-> Facility (Location/Facility ID)\")\n",
        "\n",
        "# Example merge (uncomment and modify based on your actual join keys):\n",
        "# merged_df = datasets['patients'].merge(datasets['visits'], on='PatientID', how='inner')\n",
        "# print(f\"\\nMerged patients + visits: {merged_df.shape[0]:,} rows Ã— {merged_df.shape[1]} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1.5.3 DATASET SELECTION HELPER\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SELECT DATASET FOR DETAILED ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nAvailable datasets:\")\n",
        "for i, name in enumerate(datasets.keys(), 1):\n",
        "    df = datasets[name]\n",
        "    print(f\"  {i}. {name}: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
        "\n",
        "print(\"\\nðŸ’¡ INSTRUCTIONS:\")\n",
        "print(\"   1. Choose which dataset(s) to analyze in detail\")\n",
        "print(\"   2. Set 'current_dataset' to the dataset name below\")\n",
        "print(\"   3. Sections 2-5 will analyze the selected dataset\")\n",
        "print(\"   4. Repeat for other datasets as needed\")\n",
        "\n",
        "# Set the dataset you want to analyze in detail\n",
        "# Options: 'facility', 'outcomes', 'patients', 'staffing', 'visits'\n",
        "# Or create a merged dataset above and use that\n",
        "\n",
        "current_dataset_name = 'visits'  # CHANGE THIS to analyze a different dataset\n",
        "current_dataset = datasets[current_dataset_name].copy()\n",
        "\n",
        "print(f\"\\nâœ“ Selected dataset for detailed analysis: {current_dataset_name}\")\n",
        "print(f\"  Shape: {current_dataset.shape[0]:,} rows Ã— {current_dataset.shape[1]} columns\")\n",
        "\n",
        "# Create alias 'df' for compatibility with rest of the template\n",
        "df = current_dataset.copy()\n",
        "\n",
        "print(\"\\nâœ“ Section 1.5: Dataset Relationships & Selection completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Comparison: Data Quality Across All Datasets (Optional)\n",
        "\n",
        "Run this cell to quickly compare data quality metrics across all datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "QUICK DATA QUALITY COMPARISON - ALL DATASETS\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Rows</th>\n",
              "      <th>Columns</th>\n",
              "      <th>Missing %</th>\n",
              "      <th>Duplicates</th>\n",
              "      <th>Duplicate %</th>\n",
              "      <th>Memory (MB)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>facility</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outcomes</td>\n",
              "      <td>15000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>1.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>patients</td>\n",
              "      <td>4500</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>staffing</td>\n",
              "      <td>270</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>visits</td>\n",
              "      <td>18000</td>\n",
              "      <td>11</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>11.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset   Rows  Columns Missing %  Duplicates Duplicate % Memory (MB)\n",
              "0  facility      2        6     0.00%           0       0.00%        0.00\n",
              "1  outcomes  15000        3     0.00%           0       0.00%        1.72\n",
              "2  patients   4500        4     0.00%           0       0.00%        0.78\n",
              "3  staffing    270        6     0.00%           0       0.00%        0.04\n",
              "4    visits  18000       11     0.00%           0       0.00%       11.65"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ’¡ Use this to prioritize which datasets need more attention during detailed analysis.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# QUICK DATA QUALITY COMPARISON - ALL DATASETS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUICK DATA QUALITY COMPARISON - ALL DATASETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "quality_comparison = []\n",
        "\n",
        "for name, df_temp in datasets.items():\n",
        "    missing_pct = (df_temp.isnull().sum().sum() / (df_temp.shape[0] * df_temp.shape[1])) * 100\n",
        "    duplicate_count = df_temp.duplicated().sum()\n",
        "    duplicate_pct = (duplicate_count / len(df_temp)) * 100 if len(df_temp) > 0 else 0\n",
        "    \n",
        "    quality_comparison.append({\n",
        "        'Dataset': name,\n",
        "        'Rows': df_temp.shape[0],\n",
        "        'Columns': df_temp.shape[1],\n",
        "        'Missing %': f\"{missing_pct:.2f}%\",\n",
        "        'Duplicates': duplicate_count,\n",
        "        'Duplicate %': f\"{duplicate_pct:.2f}%\",\n",
        "        'Memory (MB)': f\"{df_temp.memory_usage(deep=True).sum() / 1024**2:.2f}\"\n",
        "    })\n",
        "\n",
        "quality_df = pd.DataFrame(quality_comparison)\n",
        "display(quality_df)\n",
        "\n",
        "print(\"\\nðŸ’¡ Use this to prioritize which datasets need more attention during detailed analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Data Quality Assessment\n",
        "\n",
        "**Assigned to: Member 1**  \n",
        "**Time: 15-30 minutes**\n",
        "\n",
        "**Note:** This section analyzes the currently selected dataset (`df`). \n",
        "To analyze a different dataset, go back to Section 1.5 and change `current_dataset_name`.\n",
        "\n",
        "**For Multiple Datasets:** You can modify this section to loop through all datasets if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATA QUALITY ASSESSMENT - VISITS\n",
            "================================================================================\n",
            "Analyzing dataset: visits\n",
            "Shape: 18,000 rows Ã— 11 columns\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2.1 MISSING VALUES ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "âœ“ No missing values found in the dataset\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2.2 DUPLICATE ROWS\n",
            "--------------------------------------------------------------------------------\n",
            "Total duplicate rows: 0 (0.00%)\n",
            "âœ“ No duplicate rows found\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2.3 DATA TYPE VERIFICATION\n",
            "--------------------------------------------------------------------------------\n",
            "Numerical columns: 0\n",
            "Categorical columns: 11\n",
            "Datetime columns: 0\n",
            "\n",
            "Checking for mixed types in object columns...\n",
            "âš  Found 1 columns with mixed types: ['Triage Level']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2.4 CONSTANT COLUMNS\n",
            "--------------------------------------------------------------------------------\n",
            "âœ“ No constant columns found\n",
            "\n",
            "================================================================================\n",
            "DATA QUALITY SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total columns: 11\n",
            "Columns with missing values: 0\n",
            "Duplicate rows: 0\n",
            "Mixed type columns: 1\n",
            "Constant columns: 0\n",
            "Total data quality issues: 1\n",
            "\n",
            "âœ“ Section 2: Data Quality Assessment completed\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(f\"DATA QUALITY ASSESSMENT - {current_dataset_name.upper()}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Analyzing dataset: {current_dataset_name}\")\n",
        "print(f\"Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
        "\n",
        "# 2.1 Missing Values Analysis\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"2.1 MISSING VALUES ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing_data.index,\n",
        "    'Missing Count': missing_data.values,\n",
        "    'Missing Percentage': missing_percent.values\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    display(missing_df)\n",
        "    \n",
        "    # Visualize missing values\n",
        "    plt.figure(figsize=(12, max(6, len(missing_df) * 0.5)))\n",
        "    sns.barplot(data=missing_df, y='Column', x='Missing Percentage', palette='Reds_r')\n",
        "    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
        "    plt.ylabel('Column', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Document findings\n",
        "    for _, row in missing_df.iterrows():\n",
        "        findings['data_quality_issues'].append(\n",
        "            f\"{row['Column']}: {row['Missing Count']:,} missing values ({row['Missing Percentage']:.2f}%)\"\n",
        "        )\n",
        "else:\n",
        "    print(\"âœ“ No missing values found in the dataset\")\n",
        "    findings['key_insights'].append(\"No missing values detected in the dataset\")\n",
        "\n",
        "# 2.2 Duplicate Rows\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"2.2 DUPLICATE ROWS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"Total duplicate rows: {duplicate_count:,} ({duplicate_count/len(df)*100:.2f}%)\")\n",
        "\n",
        "if duplicate_count > 0:\n",
        "    print(\"\\nSample duplicate rows:\")\n",
        "    display(df[df.duplicated(keep=False)].head(10))\n",
        "    findings['data_quality_issues'].append(f\"{duplicate_count:,} duplicate rows found ({duplicate_count/len(df)*100:.2f}%)\")\n",
        "else:\n",
        "    print(\"âœ“ No duplicate rows found\")\n",
        "    findings['key_insights'].append(\"No duplicate rows detected\")\n",
        "\n",
        "# 2.3 Data Type Verification\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"2.3 DATA TYPE VERIFICATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Check for columns that might be incorrectly typed\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
        "\n",
        "print(f\"Numerical columns: {len(numeric_cols)}\")\n",
        "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
        "print(f\"Datetime columns: {len(datetime_cols)}\")\n",
        "\n",
        "# Check for mixed types in object columns\n",
        "print(\"\\nChecking for mixed types in object columns...\")\n",
        "mixed_type_cols = []\n",
        "for col in categorical_cols:\n",
        "    # Try to convert to numeric and see if there are any numeric values\n",
        "    numeric_vals = pd.to_numeric(df[col], errors='coerce')\n",
        "    if numeric_vals.notna().sum() > 0 and numeric_vals.notna().sum() < len(df):\n",
        "        mixed_type_cols.append(col)\n",
        "        findings['data_quality_issues'].append(f\"{col}: Mixed data types detected (numeric and non-numeric)\")\n",
        "\n",
        "if mixed_type_cols:\n",
        "    print(f\"âš  Found {len(mixed_type_cols)} columns with mixed types: {mixed_type_cols}\")\n",
        "else:\n",
        "    print(\"âœ“ No mixed type columns detected\")\n",
        "\n",
        "# 2.4 Constant Columns\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"2.4 CONSTANT COLUMNS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "constant_cols = []\n",
        "for col in df.columns:\n",
        "    if df[col].nunique() <= 1:\n",
        "        constant_cols.append(col)\n",
        "        findings['data_quality_issues'].append(f\"{col}: Constant column (only {df[col].nunique()} unique value)\")\n",
        "\n",
        "if constant_cols:\n",
        "    print(f\"âš  Found {len(constant_cols)} constant columns: {constant_cols}\")\n",
        "else:\n",
        "    print(\"âœ“ No constant columns found\")\n",
        "\n",
        "# 2.5 Data Quality Summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA QUALITY SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal columns: {df.shape[1]}\")\n",
        "print(f\"Columns with missing values: {len(missing_df) if len(missing_df) > 0 else 0}\")\n",
        "print(f\"Duplicate rows: {duplicate_count:,}\")\n",
        "print(f\"Mixed type columns: {len(mixed_type_cols)}\")\n",
        "print(f\"Constant columns: {len(constant_cols)}\")\n",
        "print(f\"Total data quality issues: {len(findings['data_quality_issues'])}\")\n",
        "\n",
        "print(\"\\nâœ“ Section 2: Data Quality Assessment completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Univariate Analysis\n",
        "\n",
        "**Assigned to: Member 1**  \n",
        "**Time: 15-30 minutes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "UNIVARIATE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Numerical columns (0): []\n",
            "Categorical columns (11): ['Visit ID', 'Patient ID', 'Arrival Time', 'Registration Start', 'Registration End', 'Triage Start', 'Triage End', 'Doctor Seen', 'Exit Time', 'Triage Level', 'Hospital ID']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3.4 CATEGORICAL VARIABLE CARDINALITY\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>Unique Values</th>\n",
              "      <th>Most Frequent</th>\n",
              "      <th>Most Frequent Count</th>\n",
              "      <th>Most Frequent %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Visit ID</td>\n",
              "      <td>18000</td>\n",
              "      <td>V100000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.005556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Patient ID</td>\n",
              "      <td>4329</td>\n",
              "      <td>MC180325-0653</td>\n",
              "      <td>15</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arrival Time</td>\n",
              "      <td>16187</td>\n",
              "      <td>2/1/2025 7:34</td>\n",
              "      <td>5</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Registration Start</td>\n",
              "      <td>16127</td>\n",
              "      <td>3/1/2025 11:48</td>\n",
              "      <td>5</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Registration End</td>\n",
              "      <td>14235</td>\n",
              "      <td>Mar 22 2025 10:17</td>\n",
              "      <td>6</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Triage Start</td>\n",
              "      <td>13846</td>\n",
              "      <td>2025-03-12T06:57</td>\n",
              "      <td>6</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Triage End</td>\n",
              "      <td>13723</td>\n",
              "      <td>1/11/2025 6:55</td>\n",
              "      <td>5</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Doctor Seen</td>\n",
              "      <td>16192</td>\n",
              "      <td>1/19/2025 13:45</td>\n",
              "      <td>4</td>\n",
              "      <td>0.022222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Exit Time</td>\n",
              "      <td>16243</td>\n",
              "      <td>1/11/2025 12:37</td>\n",
              "      <td>4</td>\n",
              "      <td>0.022222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Triage Level</td>\n",
              "      <td>12</td>\n",
              "      <td>urgent</td>\n",
              "      <td>2665</td>\n",
              "      <td>14.805556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hospital ID</td>\n",
              "      <td>2</td>\n",
              "      <td>MC_ER_EAST</td>\n",
              "      <td>15000</td>\n",
              "      <td>83.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Column  Unique Values      Most Frequent  Most Frequent Count  \\\n",
              "0             Visit ID          18000            V100000                    1   \n",
              "1           Patient ID           4329      MC180325-0653                   15   \n",
              "2         Arrival Time          16187      2/1/2025 7:34                    5   \n",
              "3   Registration Start          16127     3/1/2025 11:48                    5   \n",
              "4     Registration End          14235  Mar 22 2025 10:17                    6   \n",
              "5         Triage Start          13846   2025-03-12T06:57                    6   \n",
              "6           Triage End          13723     1/11/2025 6:55                    5   \n",
              "7          Doctor Seen          16192    1/19/2025 13:45                    4   \n",
              "8            Exit Time          16243    1/11/2025 12:37                    4   \n",
              "9         Triage Level             12             urgent                 2665   \n",
              "10         Hospital ID              2         MC_ER_EAST                15000   \n",
              "\n",
              "    Most Frequent %  \n",
              "0          0.005556  \n",
              "1          0.083333  \n",
              "2          0.027778  \n",
              "3          0.027778  \n",
              "4          0.033333  \n",
              "5          0.033333  \n",
              "6          0.027778  \n",
              "7          0.022222  \n",
              "8          0.022222  \n",
              "9         14.805556  \n",
              "10        83.333333  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3.6 VALUE COUNTS (CATEGORICAL - TOP 10)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Visit ID:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Visit ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>W112965</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V100981</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W103857</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V112296</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W114978</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V100378</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V113667</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V104269</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V103814</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V111743</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Count\n",
              "Visit ID       \n",
              "W112965       1\n",
              "V100981       1\n",
              "W103857       1\n",
              "V112296       1\n",
              "W114978       1\n",
              "V100378       1\n",
              "V113667       1\n",
              "V104269       1\n",
              "V103814       1\n",
              "V111743       1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Patient ID:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Patient ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MC180325-1063</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-0653</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-1409</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-3615</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-3371</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-4355</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-4268</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-0658</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-1359</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC180325-1240</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Count\n",
              "Patient ID          \n",
              "MC180325-1063     15\n",
              "MC180325-0653     15\n",
              "MC180325-1409     14\n",
              "MC180325-3615     13\n",
              "MC180325-3371     13\n",
              "MC180325-4355     13\n",
              "MC180325-4268     13\n",
              "MC180325-0658     13\n",
              "MC180325-1359     13\n",
              "MC180325-1240     12"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Arrival Time:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arrival Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2/1/2025 7:34</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/2/2025 10:18</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/26/2025 11:24</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/29/2025 11:39</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3/7/2025 10:31</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/5/2025 10:19</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/8/2025 6:48</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3/30/2025 9:46</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/3/2025 10:42</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/14/2025 11:38</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Count\n",
              "Arrival Time          \n",
              "2/1/2025 7:34        5\n",
              "2/2/2025 10:18       5\n",
              "2/26/2025 11:24      4\n",
              "1/29/2025 11:39      4\n",
              "3/7/2025 10:31       4\n",
              "2/5/2025 10:19       4\n",
              "2/8/2025 6:48        4\n",
              "3/30/2025 9:46       3\n",
              "2/3/2025 10:42       3\n",
              "2/14/2025 11:38      3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Registration Start:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Registration Start</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3/1/2025 11:48</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/17/2025 9:46</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/13/2025 11:58</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/7/2025 11:38</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/29/2025 10:00</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/10/2025 9:08</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/10/2025 12:24</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/9/2025 13:30</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2/20/2025 13:19</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1/5/2025 9:14</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Count\n",
              "Registration Start       \n",
              "3/1/2025 11:48          5\n",
              "2/17/2025 9:46          4\n",
              "1/13/2025 11:58         4\n",
              "2/7/2025 11:38          4\n",
              "1/29/2025 10:00         4\n",
              "1/10/2025 9:08          4\n",
              "2/10/2025 12:24         4\n",
              "2/9/2025 13:30          4\n",
              "2/20/2025 13:19         3\n",
              "1/5/2025 9:14           3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Registration End:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Registration End</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mar 22 2025 10:17</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb 14 2025 16:25</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb 09 2025 10:41</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb 10 2025 15:03</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar 07 2025 09:49</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar 18 2025 10:12</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb 27 2025 06:31</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan 07 2025 09:43</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan 12 2025 09:51</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb 25 2025 14:43</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Count\n",
              "Registration End        \n",
              "Mar 22 2025 10:17      6\n",
              "Feb 14 2025 16:25      5\n",
              "Feb 09 2025 10:41      5\n",
              "Feb 10 2025 15:03      4\n",
              "Mar 07 2025 09:49      4\n",
              "Mar 18 2025 10:12      4\n",
              "Feb 27 2025 06:31      4\n",
              "Jan 07 2025 09:43      4\n",
              "Jan 12 2025 09:51      4\n",
              "Feb 25 2025 14:43      4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Section 3: Univariate Analysis completed\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"UNIVARIATE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 3.1 Separate Numerical and Categorical Columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical columns ({len(numeric_cols)}): {numeric_cols}\")\n",
        "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "# 3.2 Descriptive Statistics for Numerical Variables\n",
        "if len(numeric_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"3.2 DESCRIPTIVE STATISTICS (NUMERICAL)\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    desc_stats = df[numeric_cols].describe().T\n",
        "    desc_stats['skewness'] = df[numeric_cols].skew()\n",
        "    desc_stats['kurtosis'] = df[numeric_cols].kurtosis()\n",
        "    desc_stats['missing_count'] = df[numeric_cols].isnull().sum()\n",
        "    desc_stats['missing_pct'] = (desc_stats['missing_count'] / len(df)) * 100\n",
        "    \n",
        "    display(desc_stats)\n",
        "    \n",
        "    # Document insights about distributions\n",
        "    for col in numeric_cols:\n",
        "        skew_val = desc_stats.loc[col, 'skewness']\n",
        "        if abs(skew_val) > 1:\n",
        "            findings['key_insights'].append(\n",
        "                f\"{col}: Highly {'right' if skew_val > 0 else 'left'}-skewed distribution (skewness={skew_val:.2f})\"\n",
        "            )\n",
        "\n",
        "# 3.3 Outlier Detection (IQR Method)\n",
        "if len(numeric_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"3.3 OUTLIER DETECTION (IQR METHOD)\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    outlier_summary = []\n",
        "    \n",
        "    for col in numeric_cols:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        \n",
        "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
        "        outlier_count = len(outliers)\n",
        "        outlier_pct = (outlier_count / len(df)) * 100\n",
        "        \n",
        "        if outlier_count > 0:\n",
        "            outlier_summary.append({\n",
        "                'Column': col,\n",
        "                'Outlier Count': outlier_count,\n",
        "                'Outlier Percentage': outlier_pct,\n",
        "                'Lower Bound': lower_bound,\n",
        "                'Upper Bound': upper_bound\n",
        "            })\n",
        "            \n",
        "            if outlier_pct > 5:  # Flag if more than 5% outliers\n",
        "                findings['data_quality_issues'].append(\n",
        "                    f\"{col}: {outlier_count:,} outliers ({outlier_pct:.2f}%) detected using IQR method\"\n",
        "                )\n",
        "    \n",
        "    if outlier_summary:\n",
        "        outlier_df = pd.DataFrame(outlier_summary)\n",
        "        display(outlier_df)\n",
        "    else:\n",
        "        print(\"âœ“ No significant outliers detected using IQR method\")\n",
        "\n",
        "# 3.4 Categorical Variable Analysis\n",
        "if len(categorical_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"3.4 CATEGORICAL VARIABLE CARDINALITY\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    cat_summary = []\n",
        "    for col in categorical_cols:\n",
        "        unique_count = df[col].nunique()\n",
        "        cat_summary.append({\n",
        "            'Column': col,\n",
        "            'Unique Values': unique_count,\n",
        "            'Most Frequent': df[col].mode()[0] if len(df[col].mode()) > 0 else 'N/A',\n",
        "            'Most Frequent Count': df[col].value_counts().iloc[0] if unique_count > 0 else 0,\n",
        "            'Most Frequent %': (df[col].value_counts().iloc[0] / len(df) * 100) if unique_count > 0 else 0\n",
        "        })\n",
        "        \n",
        "        # Document high cardinality\n",
        "        if unique_count > 50:\n",
        "            findings['key_insights'].append(\n",
        "                f\"{col}: High cardinality categorical variable ({unique_count} unique values)\"\n",
        "            )\n",
        "    \n",
        "    cat_df = pd.DataFrame(cat_summary)\n",
        "    display(cat_df)\n",
        "\n",
        "# 3.5 Distribution Visualizations - Numerical\n",
        "if len(numeric_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"3.5 DISTRIBUTION VISUALIZATIONS (NUMERICAL)\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Calculate grid dimensions\n",
        "    n_cols = min(3, len(numeric_cols))\n",
        "    n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
        "    axes = axes.flatten() if len(numeric_cols) > 1 else [axes]\n",
        "    \n",
        "    for idx, col in enumerate(numeric_cols):\n",
        "        ax = axes[idx]\n",
        "        df[col].hist(bins=50, ax=ax, edgecolor='black', alpha=0.7)\n",
        "        ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel(col, fontsize=10)\n",
        "        ax.set_ylabel('Frequency', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Hide extra subplots\n",
        "    for idx in range(len(numeric_cols), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 3.6 Value Counts - Categorical\n",
        "if len(categorical_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"3.6 VALUE COUNTS (CATEGORICAL - TOP 10)\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    for col in categorical_cols[:5]:  # Limit to first 5 to avoid too much output\n",
        "        print(f\"\\n{col}:\")\n",
        "        value_counts = df[col].value_counts().head(10)\n",
        "        display(value_counts.to_frame('Count'))\n",
        "        \n",
        "        # Visualize top categories\n",
        "        if df[col].nunique() <= 20:  # Only plot if reasonable number of categories\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            value_counts.plot(kind='bar')\n",
        "            plt.title(f'Value Counts: {col}', fontsize=12, fontweight='bold')\n",
        "            plt.xlabel(col, fontsize=10)\n",
        "            plt.ylabel('Count', fontsize=10)\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "print(\"\\nâœ“ Section 3: Univariate Analysis completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Bivariate Analysis\n",
        "\n",
        "**Assigned to: Member 2**  \n",
        "**Time: 15-30 minutes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "BIVARIATE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "4.3 TARGET VARIABLE ANALYSIS: Visit ID\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Target class distribution:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Visit ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>W112965</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V100981</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W103857</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V112296</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W114978</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V109066</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V106788</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V107401</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V113107</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V113497</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Count\n",
              "Visit ID       \n",
              "W112965       1\n",
              "V100981       1\n",
              "W103857       1\n",
              "V112296       1\n",
              "W114978       1\n",
              "...         ...\n",
              "V109066       1\n",
              "V106788       1\n",
              "V107401       1\n",
              "V113107       1\n",
              "V113497       1\n",
              "\n",
              "[18000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, ha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    105\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m--> 106\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Box plots for numerical features by target class\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(numeric_cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[38;5;241m=\u001b[39m_fetch_figure_metadata(figure_manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:182\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    180\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     data \u001b[38;5;241m=\u001b[39m formatter(obj)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:226\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 170\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/backend_bases.py:2164\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/axes/_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3070\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3071\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/axis.py:1388\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[1;32m   1387\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[0;32m-> 1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m   1391\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[1;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/text.py:958\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    956\u001b[0m bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[1;32m    957\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m--> 958\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n\u001b[1;32m    959\u001b[0m bbox \u001b[38;5;241m=\u001b[39m bbox\u001b[38;5;241m.\u001b[39mtranslated(x, y)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/transforms.py:1495\u001b[0m, in \u001b[0;36mTransform.transform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1492\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dims))\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;66;03m# Transform the values\u001b[39;00m\n\u001b[0;32m-> 1495\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_affine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_non_affine(values))\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/transforms.py:2409\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mrename_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_affine\u001b[39m(\u001b[38;5;28mself\u001b[39m, values):\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m-> 2409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_affine()\u001b[38;5;241m.\u001b[39mtransform(values)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/transforms.py:2436\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\u001b[38;5;241m.\u001b[39mget_matrix(),\n\u001b[1;32m   2437\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a\u001b[38;5;241m.\u001b[39mget_affine()\u001b[38;5;241m.\u001b[39mget_matrix()))\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/transforms.py:1903\u001b[0m, in \u001b[0;36mAffine2D.__init__\u001b[0;34m(self, matrix, **kwargs)\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1901\u001b[0m     \u001b[38;5;66;03m# A bit faster than np.identity(3).\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m IdentityTransform\u001b[38;5;241m.\u001b[39m_mtx\n\u001b[0;32m-> 1903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtx \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"BIVARIATE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 4.1 Correlation Matrix\n",
        "if len(numeric_cols) > 1:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"4.1 CORRELATION MATRIX\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    correlation_matrix = df[numeric_cols].corr()\n",
        "    \n",
        "    # Display correlation matrix\n",
        "    display(correlation_matrix)\n",
        "    \n",
        "    # Visualize correlation heatmap\n",
        "    plt.figure(figsize=(max(10, len(numeric_cols)), max(8, len(numeric_cols))))\n",
        "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
        "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title('Correlation Matrix (Numerical Features)', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 4.2 High Correlation Detection\n",
        "if len(numeric_cols) > 1:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"4.2 HIGH CORRELATION PAIRS (|r| > 0.7)\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    high_corr_pairs = []\n",
        "    for i in range(len(correlation_matrix.columns)):\n",
        "        for j in range(i+1, len(correlation_matrix.columns)):\n",
        "            col1 = correlation_matrix.columns[i]\n",
        "            col2 = correlation_matrix.columns[j]\n",
        "            corr_val = correlation_matrix.iloc[i, j]\n",
        "            \n",
        "            if abs(corr_val) > 0.7:\n",
        "                high_corr_pairs.append({\n",
        "                    'Feature 1': col1,\n",
        "                    'Feature 2': col2,\n",
        "                    'Correlation': corr_val\n",
        "                })\n",
        "                findings['key_insights'].append(\n",
        "                    f\"High correlation between {col1} and {col2}: {corr_val:.3f}\"\n",
        "                )\n",
        "    \n",
        "    if high_corr_pairs:\n",
        "        high_corr_df = pd.DataFrame(high_corr_pairs)\n",
        "        display(high_corr_df.sort_values('Correlation', key=abs, ascending=False))\n",
        "    else:\n",
        "        print(\"âœ“ No highly correlated pairs found (|r| > 0.7)\")\n",
        "\n",
        "# 4.3 Target Variable Relationship Analysis\n",
        "# Uncomment and modify if you have a target variable\n",
        "\n",
        "target_col = 'Visit ID'  # SET YOUR TARGET COLUMN HERE\n",
        "\n",
        "if target_col in df.columns:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(f\"4.3 TARGET VARIABLE ANALYSIS: {target_col}\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # If target is numerical\n",
        "    if df[target_col].dtype in [np.number]:\n",
        "        # Correlation with target\n",
        "        target_corr = df[numeric_cols].corrwith(df[target_col]).sort_values(key=abs, ascending=False)\n",
        "        print(\"\\nCorrelation with target:\")\n",
        "        display(target_corr.to_frame('Correlation'))\n",
        "        \n",
        "        # Top correlated features\n",
        "        top_features = target_corr.abs().nlargest(10).index.tolist()\n",
        "        findings['key_insights'].append(f\"Top features correlated with {target_col}: {top_features[:5]}\")\n",
        "        \n",
        "        # Scatter plots for top features\n",
        "        n_top = min(6, len(top_features))\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for idx, feature in enumerate(top_features[:n_top]):\n",
        "            ax = axes[idx]\n",
        "            ax.scatter(df[feature], df[target_col], alpha=0.5, s=20)\n",
        "            ax.set_xlabel(feature, fontsize=10)\n",
        "            ax.set_ylabel(target_col, fontsize=10)\n",
        "            ax.set_title(f'{feature} vs {target_col}\\n(r={target_corr[feature]:.3f})', fontsize=11)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # If target is categorical\n",
        "    elif df[target_col].dtype in ['object', 'category']:\n",
        "        # Class distribution\n",
        "        print(\"\\nTarget class distribution:\")\n",
        "        target_dist = df[target_col].value_counts()\n",
        "        display(target_dist.to_frame('Count'))\n",
        "        \n",
        "        # Visualize class distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        target_dist.plot(kind='bar')\n",
        "        plt.title(f'Distribution of {target_col}', fontsize=12, fontweight='bold')\n",
        "        plt.xlabel(target_col, fontsize=10)\n",
        "        plt.ylabel('Count', fontsize=10)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Box plots for numerical features by target class\n",
        "        if len(numeric_cols) > 0:\n",
        "            n_features = min(6, len(numeric_cols))\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "            axes = axes.flatten()\n",
        "            \n",
        "            for idx, feature in enumerate(numeric_cols[:n_features]):\n",
        "                ax = axes[idx]\n",
        "                df.boxplot(column=feature, by=target_col, ax=ax)\n",
        "                ax.set_title(f'{feature} by {target_col}', fontsize=11)\n",
        "                ax.set_xlabel(target_col, fontsize=10)\n",
        "                ax.set_ylabel(feature, fontsize=10)\n",
        "                plt.suptitle('')  # Remove default title\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(f\"\\nâš  Target column '{target_col}' not found in dataset\")\n",
        "\n",
        "print(\"\\nâœ“ Section 4: Bivariate Analysis completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Multivariate Analysis & Patterns\n",
        "\n",
        "**Assigned to: Member 3**  \n",
        "**Time: 15-30 minutes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTIVARIATE ANALYSIS & PATTERNS\n",
            "================================================================================\n",
            "\n",
            "âœ“ No datetime columns found for time-based analysis\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5.4 CLUSTER IDENTIFICATION PREPARATION\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Review pairplot and correlation matrix for potential clusters or groups.\n",
            "Consider using dimensionality reduction (PCA, t-SNE) if needed.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5.5 MODELING PREPARATION INSIGHTS\n",
            "--------------------------------------------------------------------------------\n",
            "â€¢ Total features available: 11\n",
            "â€¢ Numerical features: 0\n",
            "â€¢ Categorical features: 11\n",
            "â€¢ Data quality issues to address: 1\n",
            "\n",
            "âœ“ Section 5: Multivariate Analysis & Patterns completed\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"MULTIVARIATE ANALYSIS & PATTERNS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 5.1 Pairplot for Pattern Detection\n",
        "if len(numeric_cols) > 1 and len(numeric_cols) <= 8:  # Limit to avoid too many plots\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"5.1 PAIRPLOT (PATTERN DETECTION)\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"\\nGenerating pairplot (this may take a moment)...\")\n",
        "    \n",
        "    # Sample data if too large for pairplot\n",
        "    sample_size = min(1000, len(df))\n",
        "    df_sample = df[numeric_cols].sample(n=sample_size, random_state=42) if len(df) > 1000 else df[numeric_cols]\n",
        "    \n",
        "    # Create pairplot\n",
        "    sns.pairplot(df_sample, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 20})\n",
        "    plt.suptitle('Pairplot of Numerical Features', y=1.02, fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    findings['key_insights'].append(\"Pairplot generated to identify multivariate patterns and clusters\")\n",
        "elif len(numeric_cols) > 8:\n",
        "    print(\"\\nâš  Too many numerical columns for pairplot. Consider selecting key features.\")\n",
        "    findings['questions_for_team'].append(\"Which numerical features should we focus on for multivariate analysis?\")\n",
        "\n",
        "# 5.2 Class Imbalance Detection (if target exists)\n",
        "# Uncomment if you have a target variable\n",
        "# if 'target_col' in locals() and target_col in df.columns:\n",
        "#     if df[target_col].dtype in ['object', 'category']:\n",
        "#         print(\"\\n\" + \"-\" * 80)\n",
        "#         print(\"5.2 CLASS IMBALANCE DETECTION\")\n",
        "#         print(\"-\" * 80)\n",
        "#         \n",
        "#         class_counts = df[target_col].value_counts()\n",
        "#         class_proportions = class_counts / len(df)\n",
        "#         \n",
        "#         print(\"\\nClass distribution:\")\n",
        "#         display(class_proportions.to_frame('Proportion'))\n",
        "#         \n",
        "#         # Check for imbalance (threshold: any class < 10%)\n",
        "#         min_proportion = class_proportions.min()\n",
        "#         if min_proportion < 0.1:\n",
        "#             findings['data_quality_issues'].append(\n",
        "#                 f\"Class imbalance detected: Minority class represents {min_proportion*100:.2f}% of data\"\n",
        "#             )\n",
        "#             findings['next_steps'].append(\"Consider using class balancing techniques (SMOTE, undersampling, etc.)\")\n",
        "\n",
        "# 5.3 Time-based Pattern Analysis\n",
        "datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
        "if len(datetime_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"5.3 TIME-BASED PATTERN ANALYSIS\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    for col in datetime_cols[:2]:  # Limit to first 2 datetime columns\n",
        "        print(f\"\\nAnalyzing {col}...\")\n",
        "        \n",
        "        # Extract time components\n",
        "        df[f'{col}_year'] = pd.to_datetime(df[col]).dt.year\n",
        "        df[f'{col}_month'] = pd.to_datetime(df[col]).dt.month\n",
        "        df[f'{col}_day'] = pd.to_datetime(df[col]).dt.day\n",
        "        df[f'{col}_dayofweek'] = pd.to_datetime(df[col]).dt.dayofweek\n",
        "        \n",
        "        # Time series plot if we have a numerical target or feature\n",
        "        if len(numeric_cols) > 0:\n",
        "            # Plot first numerical column over time\n",
        "            plt.figure(figsize=(14, 6))\n",
        "            time_series = df.groupby(pd.to_datetime(df[col]).dt.date)[numeric_cols[0]].mean()\n",
        "            time_series.plot()\n",
        "            plt.title(f'{numeric_cols[0]} Over Time ({col})', fontsize=12, fontweight='bold')\n",
        "            plt.xlabel('Date', fontsize=10)\n",
        "            plt.ylabel(numeric_cols[0], fontsize=10)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            findings['feature_ideas'].append(f\"Extract time features from {col}: year, month, day, dayofweek, hour, etc.\")\n",
        "else:\n",
        "    print(\"\\nâœ“ No datetime columns found for time-based analysis\")\n",
        "\n",
        "# 5.4 Cluster and Grouping Identification\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"5.4 CLUSTER IDENTIFICATION PREPARATION\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nReview pairplot and correlation matrix for potential clusters or groups.\")\n",
        "print(\"Consider using dimensionality reduction (PCA, t-SNE) if needed.\")\n",
        "\n",
        "if len(numeric_cols) > 2:\n",
        "    findings['questions_for_team'].append(\"Should we apply dimensionality reduction techniques (PCA, t-SNE) for visualization?\")\n",
        "\n",
        "# 5.5 Preparation for Modeling Insights\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"5.5 MODELING PREPARATION INSIGHTS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "modeling_insights = []\n",
        "\n",
        "# Feature count\n",
        "modeling_insights.append(f\"Total features available: {df.shape[1]}\")\n",
        "modeling_insights.append(f\"Numerical features: {len(numeric_cols)}\")\n",
        "modeling_insights.append(f\"Categorical features: {len(categorical_cols)}\")\n",
        "\n",
        "# Data size\n",
        "if df.shape[0] < 1000:\n",
        "    modeling_insights.append(\"Small dataset: Consider simpler models or data augmentation\")\n",
        "elif df.shape[0] > 100000:\n",
        "    modeling_insights.append(\"Large dataset: Can support complex models, consider sampling for faster iteration\")\n",
        "\n",
        "# Missing data impact\n",
        "if len(findings['data_quality_issues']) > 0:\n",
        "    modeling_insights.append(f\"Data quality issues to address: {len(findings['data_quality_issues'])}\")\n",
        "\n",
        "for insight in modeling_insights:\n",
        "    print(f\"â€¢ {insight}\")\n",
        "    findings['next_steps'].append(insight)\n",
        "\n",
        "print(\"\\nâœ“ Section 5: Multivariate Analysis & Patterns completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Feature Engineering Ideas\n",
        "\n",
        "**Team Activity:** Brainstorm together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FEATURE ENGINEERING IDEAS\n",
            "================================================================================\n",
            "\n",
            "Use this section to brainstorm and document feature engineering ideas.\n",
            "Add your ideas to the findings dictionary as you discuss.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6.1 NUMERICAL FEATURE TRANSFORMATIONS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Potential transformations:\n",
            "  â€¢ Polynomial features (xÂ², xÂ³) for non-linear relationships\n",
            "  â€¢ Binning/bucketing for continuous variables\n",
            "  â€¢ Log/Box-Cox transformations for skewed distributions\n",
            "  â€¢ Standardization/Normalization (StandardScaler, MinMaxScaler)\n",
            "  â€¢ Robust scaling for outlier-resistant normalization\n",
            "  â€¢ Power transforms (square root, cube root)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6.2 CATEGORICAL ENCODING STRATEGIES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Potential encoding strategies:\n",
            "  â€¢ One-hot encoding for low cardinality (< 10 unique values)\n",
            "  â€¢ Label encoding for ordinal categories\n",
            "  â€¢ Target encoding for high cardinality categories\n",
            "  â€¢ Frequency encoding (replace with value counts)\n",
            "  â€¢ Binary encoding for very high cardinality\n",
            "  â€¢ Embedding for deep learning models\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6.4 DOMAIN-SPECIFIC FEATURES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Discuss domain knowledge and create relevant features.\n",
            "Examples:\n",
            "  â€¢ Ratio features (e.g., price per unit, density)\n",
            "  â€¢ Interaction features (e.g., product of two features)\n",
            "  â€¢ Aggregate features (e.g., mean, max, min by group)\n",
            "  â€¢ Distance/Similarity features\n",
            "  â€¢ Text features (if applicable): word count, sentiment, etc.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6.5 AGGREGATE & ROLLING WINDOW FEATURES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Potential aggregate features:\n",
            "  â€¢ Group-based aggregations (mean, median, std, min, max, count)\n",
            "  â€¢ Rolling window statistics (moving average, rolling std)\n",
            "  â€¢ Lag features (previous values)\n",
            "  â€¢ Cumulative statistics\n",
            "  â€¢ Rank-based features\n",
            "\n",
            "âœ“ Section 6: Feature Engineering Ideas completed\n",
            "\n",
            "ðŸ’¡ TIP: Document your specific feature engineering ideas in the findings dictionary above.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"FEATURE ENGINEERING IDEAS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nUse this section to brainstorm and document feature engineering ideas.\")\n",
        "print(\"Add your ideas to the findings dictionary as you discuss.\")\n",
        "\n",
        "# 6.1 Numerical Feature Transformations\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"6.1 NUMERICAL FEATURE TRANSFORMATIONS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "numerical_transforms = [\n",
        "    \"Polynomial features (xÂ², xÂ³) for non-linear relationships\",\n",
        "    \"Binning/bucketing for continuous variables\",\n",
        "    \"Log/Box-Cox transformations for skewed distributions\",\n",
        "    \"Standardization/Normalization (StandardScaler, MinMaxScaler)\",\n",
        "    \"Robust scaling for outlier-resistant normalization\",\n",
        "    \"Power transforms (square root, cube root)\"\n",
        "]\n",
        "\n",
        "print(\"\\nPotential transformations:\")\n",
        "for transform in numerical_transforms:\n",
        "    print(f\"  â€¢ {transform}\")\n",
        "\n",
        "# Document specific ideas based on your data\n",
        "for col in numeric_cols[:5]:  # Review first 5 numerical columns\n",
        "    skew_val = df[col].skew()\n",
        "    if abs(skew_val) > 1:\n",
        "        findings['feature_ideas'].append(f\"Apply log/Box-Cox transform to {col} (skewness={skew_val:.2f})\")\n",
        "\n",
        "# 6.2 Categorical Encoding Strategies\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"6.2 CATEGORICAL ENCODING STRATEGIES\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "categorical_encodings = [\n",
        "    \"One-hot encoding for low cardinality (< 10 unique values)\",\n",
        "    \"Label encoding for ordinal categories\",\n",
        "    \"Target encoding for high cardinality categories\",\n",
        "    \"Frequency encoding (replace with value counts)\",\n",
        "    \"Binary encoding for very high cardinality\",\n",
        "    \"Embedding for deep learning models\"\n",
        "]\n",
        "\n",
        "print(\"\\nPotential encoding strategies:\")\n",
        "for encoding in categorical_encodings:\n",
        "    print(f\"  â€¢ {encoding}\")\n",
        "\n",
        "# Document specific ideas based on your data\n",
        "for col in categorical_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    if unique_count < 10:\n",
        "        findings['feature_ideas'].append(f\"One-hot encode {col} ({unique_count} categories)\")\n",
        "    elif unique_count > 50:\n",
        "        findings['feature_ideas'].append(f\"Consider target/frequency encoding for {col} (high cardinality: {unique_count})\")\n",
        "\n",
        "# 6.3 Datetime Feature Extraction\n",
        "if len(datetime_cols) > 0:\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"6.3 DATETIME FEATURE EXTRACTION\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    datetime_features = [\n",
        "        \"Extract: year, month, day, hour, minute, second\",\n",
        "        \"Extract: day of week, day of year, week of year\",\n",
        "        \"Extract: is_weekend, is_month_start, is_month_end\",\n",
        "        \"Extract: quarter, semester\",\n",
        "        \"Time since reference date\",\n",
        "        \"Cyclical encoding (sin/cos) for periodic features\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\nPotential datetime features:\")\n",
        "    for feature in datetime_features:\n",
        "        print(f\"  â€¢ {feature}\")\n",
        "    \n",
        "    for col in datetime_cols:\n",
        "        findings['feature_ideas'].append(f\"Extract time components from {col}: year, month, day, hour, dayofweek, etc.\")\n",
        "\n",
        "# 6.4 Domain-Specific Features\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"6.4 DOMAIN-SPECIFIC FEATURES\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nDiscuss domain knowledge and create relevant features.\")\n",
        "print(\"Examples:\")\n",
        "print(\"  â€¢ Ratio features (e.g., price per unit, density)\")\n",
        "print(\"  â€¢ Interaction features (e.g., product of two features)\")\n",
        "print(\"  â€¢ Aggregate features (e.g., mean, max, min by group)\")\n",
        "print(\"  â€¢ Distance/Similarity features\")\n",
        "print(\"  â€¢ Text features (if applicable): word count, sentiment, etc.\")\n",
        "\n",
        "# 6.5 Aggregate and Rolling Window Features\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"6.5 AGGREGATE & ROLLING WINDOW FEATURES\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "aggregate_features = [\n",
        "    \"Group-based aggregations (mean, median, std, min, max, count)\",\n",
        "    \"Rolling window statistics (moving average, rolling std)\",\n",
        "    \"Lag features (previous values)\",\n",
        "    \"Cumulative statistics\",\n",
        "    \"Rank-based features\"\n",
        "]\n",
        "\n",
        "print(\"\\nPotential aggregate features:\")\n",
        "for feature in aggregate_features:\n",
        "    print(f\"  â€¢ {feature}\")\n",
        "\n",
        "print(\"\\nâœ“ Section 6: Feature Engineering Ideas completed\")\n",
        "print(\"\\nðŸ’¡ TIP: Document your specific feature engineering ideas in the findings dictionary above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Summary & Action Items\n",
        "\n",
        "**Team Activity:** Review together and plan next steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"SUMMARY & ACTION ITEMS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 7.1 Data Quality Issues Summary\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.1 DATA QUALITY ISSUES\")\n",
        "print(\"-\" * 80)\n",
        "if len(findings['data_quality_issues']) > 0:\n",
        "    for i, issue in enumerate(findings['data_quality_issues'], 1):\n",
        "        print(f\"  {i}. {issue}\")\n",
        "else:\n",
        "    print(\"  âœ“ No major data quality issues identified\")\n",
        "\n",
        "# 7.2 Key Insights Summary\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.2 KEY INSIGHTS\")\n",
        "print(\"-\" * 80)\n",
        "if len(findings['key_insights']) > 0:\n",
        "    for i, insight in enumerate(findings['key_insights'], 1):\n",
        "        print(f\"  {i}. {insight}\")\n",
        "else:\n",
        "    print(\"  (No insights documented yet)\")\n",
        "\n",
        "# 7.3 Feature Engineering Ideas Summary\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.3 FEATURE ENGINEERING IDEAS\")\n",
        "print(\"-\" * 80)\n",
        "if len(findings['feature_ideas']) > 0:\n",
        "    for i, idea in enumerate(findings['feature_ideas'], 1):\n",
        "        print(f\"  {i}. {idea}\")\n",
        "else:\n",
        "    print(\"  (No feature ideas documented yet)\")\n",
        "\n",
        "# 7.4 Questions for Team Discussion\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.4 QUESTIONS FOR TEAM DISCUSSION\")\n",
        "print(\"-\" * 80)\n",
        "if len(findings['questions_for_team']) > 0:\n",
        "    for i, question in enumerate(findings['questions_for_team'], 1):\n",
        "        print(f\"  {i}. {question}\")\n",
        "else:\n",
        "    print(\"  (No questions documented yet)\")\n",
        "\n",
        "# 7.5 Next Steps\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.5 NEXT STEPS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "next_steps_default = [\n",
        "    \"Address data quality issues (missing values, duplicates, outliers)\",\n",
        "    \"Implement feature engineering based on insights\",\n",
        "    \"Split data into train/validation/test sets\",\n",
        "    \"Select baseline models to try\",\n",
        "    \"Set up cross-validation strategy\",\n",
        "    \"Define evaluation metrics\",\n",
        "    \"Create modeling pipeline\"\n",
        "]\n",
        "\n",
        "all_next_steps = findings['next_steps'] + next_steps_default\n",
        "for i, step in enumerate(all_next_steps, 1):\n",
        "    print(f\"  {i}. {step}\")\n",
        "\n",
        "# 7.6 Export Findings to Text File\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"7.6 EXPORTING FINDINGS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "export_content = f\"\"\"\n",
        "EDA FINDINGS REPORT\n",
        "===================\n",
        "Generated: {timestamp}\n",
        "Dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\n",
        "\n",
        "DATA QUALITY ISSUES\n",
        "-------------------\n",
        "\"\"\"\n",
        "\n",
        "if len(findings['data_quality_issues']) > 0:\n",
        "    for i, issue in enumerate(findings['data_quality_issues'], 1):\n",
        "        export_content += f\"{i}. {issue}\\n\"\n",
        "else:\n",
        "    export_content += \"No major data quality issues identified.\\n\"\n",
        "\n",
        "export_content += f\"\\nKEY INSIGHTS\\n\"\n",
        "export_content += f\"{'=' * 20}\\n\"\n",
        "if len(findings['key_insights']) > 0:\n",
        "    for i, insight in enumerate(findings['key_insights'], 1):\n",
        "        export_content += f\"{i}. {insight}\\n\"\n",
        "else:\n",
        "    export_content += \"No insights documented.\\n\"\n",
        "\n",
        "export_content += f\"\\nFEATURE ENGINEERING IDEAS\\n\"\n",
        "export_content += f\"{'=' * 20}\\n\"\n",
        "if len(findings['feature_ideas']) > 0:\n",
        "    for i, idea in enumerate(findings['feature_ideas'], 1):\n",
        "        export_content += f\"{i}. {idea}\\n\"\n",
        "else:\n",
        "    export_content += \"No feature ideas documented.\\n\"\n",
        "\n",
        "export_content += f\"\\nQUESTIONS FOR TEAM DISCUSSION\\n\"\n",
        "export_content += f\"{'=' * 20}\\n\"\n",
        "if len(findings['questions_for_team']) > 0:\n",
        "    for i, question in enumerate(findings['questions_for_team'], 1):\n",
        "        export_content += f\"{i}. {question}\\n\"\n",
        "else:\n",
        "    export_content += \"No questions documented.\\n\"\n",
        "\n",
        "export_content += f\"\\nNEXT STEPS\\n\"\n",
        "export_content += f\"{'=' * 20}\\n\"\n",
        "for i, step in enumerate(all_next_steps, 1):\n",
        "    export_content += f\"{i}. {step}\\n\"\n",
        "\n",
        "# Write to file\n",
        "output_file = 'eda_findings.txt'\n",
        "with open(output_file, 'w') as f:\n",
        "    f.write(export_content)\n",
        "\n",
        "print(f\"\\nâœ“ Findings exported to: {output_file}\")\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EDA COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nNext: Review findings with team and proceed to feature engineering and modeling.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
